{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567eda11",
   "metadata": {},
   "source": [
    "### Imports for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab4bfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 20:25:27.983067: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-01 20:25:28.007154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote_url:  http://localhost:8080/?start=2025-03-10&end=2025-11-01\n",
      "Archivo CSV crudo ya existe en data/training.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 20:25:28.499925: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "from IPython import display\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "import sys\n",
    "FUENTES_DIR = \"/lib\"\n",
    "sys.path.append(FUENTES_DIR)\n",
    "\n",
    "DATOS_DIR = \"data/\"\n",
    "import os\n",
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "# Asegurar carpeta de datos\n",
    "os.makedirs(DATOS_DIR, exist_ok=True)\n",
    "\n",
    "# Parámetros de periodo: primer día de marzo 2025 hasta hoy\n",
    "START_DATE = \"2025-03-10\"\n",
    "END_DATE = date.today().isoformat()\n",
    "\n",
    "# Ruta local para guardar el CSV crudo\n",
    "raw_csv_path = os.path.join(DATOS_DIR, 'training.csv')\n",
    "\n",
    "# URL remota a consultar\n",
    "remote_url = f\"http://localhost:8080/?start={START_DATE}&end={END_DATE}\"\n",
    "\n",
    "# Flags: forzar descarga o re-procesado (poner True para forzar)\n",
    "FORCE_DOWNLOAD = False\n",
    "FORCE_REPROCESS = False\n",
    "\n",
    "if FORCE_DOWNLOAD and os.path.exists(raw_csv_path):\n",
    "    os.remove(raw_csv_path)\n",
    "\n",
    "print(\"remote_url: \", remote_url)\n",
    "\n",
    "if not os.path.exists(raw_csv_path):\n",
    "    print(f\"Descargando datos de {remote_url} ...\")\n",
    "    try:\n",
    "        resp = requests.get(remote_url, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        with open(raw_csv_path, 'wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print(f\"Guardado CSV en {raw_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error descargando datos desde localhost:\", e)\n",
    "        raise\n",
    "else:\n",
    "    print(f\"Archivo CSV crudo ya existe en {raw_csv_path}\")\n",
    "\n",
    "data = pd.read_csv(raw_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b761c7",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79a2254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2025-03-10 03:00:00+00:00\n",
      "1   2025-03-10 03:05:00+00:00\n",
      "2   2025-03-10 03:10:00+00:00\n",
      "3   2025-03-10 03:15:00+00:00\n",
      "4   2025-03-10 03:20:00+00:00\n",
      "Name: date, dtype: datetime64[ns, UTC]\n",
      "0   2025-03-10 09:45:51+00:00\n",
      "1   2025-03-10 09:45:51+00:00\n",
      "2   2025-03-10 09:45:51+00:00\n",
      "3   2025-03-10 09:45:51+00:00\n",
      "4   2025-03-10 09:45:51+00:00\n",
      "Name: sunrise_dt, dtype: datetime64[ns, UTC]\n",
      "0   2025-03-10 22:18:04+00:00\n",
      "1   2025-03-10 22:18:04+00:00\n",
      "2   2025-03-10 22:18:04+00:00\n",
      "3   2025-03-10 22:18:04+00:00\n",
      "4   2025-03-10 22:18:04+00:00\n",
      "Name: sunset_dt, dtype: datetime64[ns, UTC]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "daylight\n",
       "1    31727\n",
       "0    27912\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from lib.preprocessing import preprocess_data\n",
    "\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Separar features y labels\n",
    "X = data.drop(columns=[\"consumption\"])\n",
    "T = data[\"consumption\"]\n",
    "\n",
    "data['daylight'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0be291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.normalization import normalize_data\n",
    "\n",
    "X_train, X_test, T_train, T_test = normalize_data(X, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7007d2",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "153a3aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateo/temp/str/venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/mateo/temp/str/venv/lib/python3.13/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762039528.873290  682746 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7249 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Modelo MLP con LeakyReLU y He initialization para capas ocultas\n",
    "model = Sequential([\n",
    "    Dense(64, kernel_initializer='he_normal', input_dim=X_train.shape[1]),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dense(32, kernel_initializer='he_normal'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dense(16, kernel_initializer='he_normal'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dense(1, activation='linear')  # salida lineal para regresión\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106589a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320ac68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando en GPU.\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 20:25:29.512617: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f230800bf90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-01 20:25:29.512628: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2025-11-01 20:25:29.522408: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-01 20:25:29.573679: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 304/1491\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 34278510.3289 - mae: 5679.9061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762039530.056657  682878 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6529594.0000 - mae: 1669.1589 - val_loss: 739359.2500 - val_mae: 687.7680\n",
      "Epoch 2/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6529594.0000 - mae: 1669.1589 - val_loss: 739359.2500 - val_mae: 687.7680\n",
      "Epoch 2/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 619249.7500 - mae: 630.0375 - val_loss: 540706.8125 - val_mae: 586.8127\n",
      "Epoch 3/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 619249.7500 - mae: 630.0375 - val_loss: 540706.8125 - val_mae: 586.8127\n",
      "Epoch 3/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 485608.5312 - mae: 555.4780 - val_loss: 452278.4688 - val_mae: 533.0674\n",
      "Epoch 4/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 485608.5312 - mae: 555.4780 - val_loss: 452278.4688 - val_mae: 533.0674\n",
      "Epoch 4/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 417226.7188 - mae: 511.8675 - val_loss: 396996.5625 - val_mae: 498.7900\n",
      "Epoch 5/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 417226.7188 - mae: 511.8675 - val_loss: 396996.5625 - val_mae: 498.7900\n",
      "Epoch 5/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 373770.0312 - mae: 481.9064 - val_loss: 359382.0625 - val_mae: 471.2821\n",
      "Epoch 6/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 373770.0312 - mae: 481.9064 - val_loss: 359382.0625 - val_mae: 471.2821\n",
      "Epoch 6/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 343104.7500 - mae: 459.6423 - val_loss: 336748.8438 - val_mae: 454.3271\n",
      "Epoch 7/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 343104.7500 - mae: 459.6423 - val_loss: 336748.8438 - val_mae: 454.3271\n",
      "Epoch 7/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 324318.6562 - mae: 445.2867 - val_loss: 322064.9062 - val_mae: 444.3853\n",
      "Epoch 8/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 324318.6562 - mae: 445.2867 - val_loss: 322064.9062 - val_mae: 444.3853\n",
      "Epoch 8/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 309970.7812 - mae: 433.6353 - val_loss: 308835.0938 - val_mae: 434.9116\n",
      "Epoch 9/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 309970.7812 - mae: 433.6353 - val_loss: 308835.0938 - val_mae: 434.9116\n",
      "Epoch 9/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 298083.7812 - mae: 424.1234 - val_loss: 298144.8750 - val_mae: 423.0174\n",
      "Epoch 10/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 298083.7812 - mae: 424.1234 - val_loss: 298144.8750 - val_mae: 423.0174\n",
      "Epoch 10/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 276127.0625 - mae: 407.5041 - val_loss: 258958.6406 - val_mae: 393.7195\n",
      "Epoch 11/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 276127.0625 - mae: 407.5041 - val_loss: 258958.6406 - val_mae: 393.7195\n",
      "Epoch 11/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 230684.8750 - mae: 373.7348 - val_loss: 210175.5000 - val_mae: 357.9316\n",
      "Epoch 12/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 230684.8750 - mae: 373.7348 - val_loss: 210175.5000 - val_mae: 357.9316\n",
      "Epoch 12/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 188934.2812 - mae: 340.5720 - val_loss: 178932.4688 - val_mae: 333.2230\n",
      "Epoch 13/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 188934.2812 - mae: 340.5720 - val_loss: 178932.4688 - val_mae: 333.2230\n",
      "Epoch 13/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 170386.5156 - mae: 323.7431 - val_loss: 166516.5625 - val_mae: 321.9721\n",
      "Epoch 14/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 170386.5156 - mae: 323.7431 - val_loss: 166516.5625 - val_mae: 321.9721\n",
      "Epoch 14/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 160862.6875 - mae: 314.4000 - val_loss: 158842.8281 - val_mae: 313.9393\n",
      "Epoch 15/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 160862.6875 - mae: 314.4000 - val_loss: 158842.8281 - val_mae: 313.9393\n",
      "Epoch 15/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 154820.3438 - mae: 307.8974 - val_loss: 157189.7344 - val_mae: 310.9100\n",
      "Epoch 16/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 154820.3438 - mae: 307.8974 - val_loss: 157189.7344 - val_mae: 310.9100\n",
      "Epoch 16/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 149905.7969 - mae: 302.7060 - val_loss: 150210.5469 - val_mae: 304.3230\n",
      "Epoch 17/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 149905.7969 - mae: 302.7060 - val_loss: 150210.5469 - val_mae: 304.3230\n",
      "Epoch 17/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 145851.7031 - mae: 298.4647 - val_loss: 148502.7344 - val_mae: 303.6752\n",
      "Epoch 18/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 145851.7031 - mae: 298.4647 - val_loss: 148502.7344 - val_mae: 303.6752\n",
      "Epoch 18/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 142559.0312 - mae: 295.0748 - val_loss: 143573.3125 - val_mae: 297.2810\n",
      "Epoch 19/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 142559.0312 - mae: 295.0748 - val_loss: 143573.3125 - val_mae: 297.2810\n",
      "Epoch 19/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 139836.8281 - mae: 292.0555 - val_loss: 139545.4062 - val_mae: 293.7128\n",
      "Epoch 20/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 139836.8281 - mae: 292.0555 - val_loss: 139545.4062 - val_mae: 293.7128\n",
      "Epoch 20/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 136832.2188 - mae: 288.6301 - val_loss: 139821.4688 - val_mae: 291.8618\n",
      "Epoch 21/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 136832.2188 - mae: 288.6301 - val_loss: 139821.4688 - val_mae: 291.8618\n",
      "Epoch 21/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 134301.5938 - mae: 286.1686 - val_loss: 138901.2656 - val_mae: 293.4996\n",
      "Epoch 22/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 134301.5938 - mae: 286.1686 - val_loss: 138901.2656 - val_mae: 293.4996\n",
      "Epoch 22/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 132129.1875 - mae: 283.4093 - val_loss: 133489.1406 - val_mae: 285.8372\n",
      "Epoch 23/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 132129.1875 - mae: 283.4093 - val_loss: 133489.1406 - val_mae: 285.8372\n",
      "Epoch 23/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 129705.1328 - mae: 280.7715 - val_loss: 139023.4531 - val_mae: 293.6961\n",
      "Epoch 24/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 129705.1328 - mae: 280.7715 - val_loss: 139023.4531 - val_mae: 293.6961\n",
      "Epoch 24/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 127483.2891 - mae: 277.8895 - val_loss: 131192.3750 - val_mae: 283.2735\n",
      "Epoch 25/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 127483.2891 - mae: 277.8895 - val_loss: 131192.3750 - val_mae: 283.2735\n",
      "Epoch 25/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 125886.6875 - mae: 276.0625 - val_loss: 129899.5391 - val_mae: 280.2904\n",
      "Epoch 26/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 125886.6875 - mae: 276.0625 - val_loss: 129899.5391 - val_mae: 280.2904\n",
      "Epoch 26/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 123738.4688 - mae: 273.3835 - val_loss: 130084.6250 - val_mae: 283.7421\n",
      "Epoch 27/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 123738.4688 - mae: 273.3835 - val_loss: 130084.6250 - val_mae: 283.7421\n",
      "Epoch 27/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 121839.6875 - mae: 271.3130 - val_loss: 124924.7344 - val_mae: 277.1222\n",
      "Epoch 28/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 121839.6875 - mae: 271.3130 - val_loss: 124924.7344 - val_mae: 277.1222\n",
      "Epoch 28/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 120180.0547 - mae: 269.3559 - val_loss: 122675.3984 - val_mae: 273.6494\n",
      "Epoch 29/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 120180.0547 - mae: 269.3559 - val_loss: 122675.3984 - val_mae: 273.6494\n",
      "Epoch 29/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 118642.0781 - mae: 267.4385 - val_loss: 121452.6484 - val_mae: 272.7814\n",
      "Epoch 30/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 118642.0781 - mae: 267.4385 - val_loss: 121452.6484 - val_mae: 272.7814\n",
      "Epoch 30/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 117363.9609 - mae: 265.7740 - val_loss: 121753.6328 - val_mae: 271.2637\n",
      "Epoch 31/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 117363.9609 - mae: 265.7740 - val_loss: 121753.6328 - val_mae: 271.2637\n",
      "Epoch 31/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 114506.7188 - mae: 262.2881 - val_loss: 118154.9531 - val_mae: 269.2007\n",
      "Epoch 32/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 114506.7188 - mae: 262.2881 - val_loss: 118154.9531 - val_mae: 269.2007\n",
      "Epoch 32/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 107474.0625 - mae: 253.7185 - val_loss: 108814.1094 - val_mae: 257.1187\n",
      "Epoch 33/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 107474.0625 - mae: 253.7185 - val_loss: 108814.1094 - val_mae: 257.1187\n",
      "Epoch 33/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 99394.6875 - mae: 243.0722 - val_loss: 99462.7500 - val_mae: 244.7850\n",
      "Epoch 34/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 99394.6875 - mae: 243.0722 - val_loss: 99462.7500 - val_mae: 244.7850\n",
      "Epoch 34/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 92267.9375 - mae: 233.3257 - val_loss: 91015.3828 - val_mae: 231.8194\n",
      "Epoch 35/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 92267.9375 - mae: 233.3257 - val_loss: 91015.3828 - val_mae: 231.8194\n",
      "Epoch 35/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 86320.5781 - mae: 224.7427 - val_loss: 85013.7656 - val_mae: 223.1499\n",
      "Epoch 36/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 86320.5781 - mae: 224.7427 - val_loss: 85013.7656 - val_mae: 223.1499\n",
      "Epoch 36/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 81236.1250 - mae: 217.6272 - val_loss: 83961.9609 - val_mae: 222.1908\n",
      "Epoch 37/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 81236.1250 - mae: 217.6272 - val_loss: 83961.9609 - val_mae: 222.1908\n",
      "Epoch 37/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 77237.6484 - mae: 211.9012 - val_loss: 78698.3984 - val_mae: 214.7327\n",
      "Epoch 38/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 77237.6484 - mae: 211.9012 - val_loss: 78698.3984 - val_mae: 214.7327\n",
      "Epoch 38/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 74134.7656 - mae: 207.2881 - val_loss: 76104.4219 - val_mae: 210.5791\n",
      "Epoch 39/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 74134.7656 - mae: 207.2881 - val_loss: 76104.4219 - val_mae: 210.5791\n",
      "Epoch 39/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 71604.2578 - mae: 203.5725 - val_loss: 72781.5938 - val_mae: 206.3366\n",
      "Epoch 40/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 71604.2578 - mae: 203.5725 - val_loss: 72781.5938 - val_mae: 206.3366\n",
      "Epoch 40/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 69446.4922 - mae: 200.4805 - val_loss: 70588.7891 - val_mae: 201.9892\n",
      "Epoch 41/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 69446.4922 - mae: 200.4805 - val_loss: 70588.7891 - val_mae: 201.9892\n",
      "Epoch 41/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 67650.7891 - mae: 197.9249 - val_loss: 69304.5625 - val_mae: 201.3901\n",
      "Epoch 42/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 67650.7891 - mae: 197.9249 - val_loss: 69304.5625 - val_mae: 201.3901\n",
      "Epoch 42/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 65816.3203 - mae: 195.1619 - val_loss: 67282.1641 - val_mae: 197.0648\n",
      "Epoch 43/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 65816.3203 - mae: 195.1619 - val_loss: 67282.1641 - val_mae: 197.0648\n",
      "Epoch 43/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 64148.9805 - mae: 192.0447 - val_loss: 66020.9922 - val_mae: 194.9157\n",
      "Epoch 44/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 64148.9805 - mae: 192.0447 - val_loss: 66020.9922 - val_mae: 194.9157\n",
      "Epoch 44/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 62405.0859 - mae: 190.1954 - val_loss: 62237.1016 - val_mae: 190.0541\n",
      "Epoch 45/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 62405.0859 - mae: 190.1954 - val_loss: 62237.1016 - val_mae: 190.0541\n",
      "Epoch 45/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 61076.2148 - mae: 187.7794 - val_loss: 62375.3672 - val_mae: 189.6199\n",
      "Epoch 46/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 61076.2148 - mae: 187.7794 - val_loss: 62375.3672 - val_mae: 189.6199\n",
      "Epoch 46/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 60114.7578 - mae: 186.4120 - val_loss: 62580.9961 - val_mae: 191.1804\n",
      "Epoch 47/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 60114.7578 - mae: 186.4120 - val_loss: 62580.9961 - val_mae: 191.1804\n",
      "Epoch 47/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 58810.5273 - mae: 184.7275 - val_loss: 63123.8594 - val_mae: 192.6376\n",
      "Epoch 48/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 58810.5273 - mae: 184.7275 - val_loss: 63123.8594 - val_mae: 192.6376\n",
      "Epoch 48/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 58121.8789 - mae: 183.4880 - val_loss: 59206.4453 - val_mae: 184.6131\n",
      "Epoch 49/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 58121.8789 - mae: 183.4880 - val_loss: 59206.4453 - val_mae: 184.6131\n",
      "Epoch 49/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 57018.3789 - mae: 181.9025 - val_loss: 61058.7266 - val_mae: 187.2892\n",
      "Epoch 50/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 57018.3789 - mae: 181.9025 - val_loss: 61058.7266 - val_mae: 187.2892\n",
      "Epoch 50/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 56164.7930 - mae: 180.3184 - val_loss: 56998.3242 - val_mae: 182.4786\n",
      "Epoch 51/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 56164.7930 - mae: 180.3184 - val_loss: 56998.3242 - val_mae: 182.4786\n",
      "Epoch 51/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 55641.0859 - mae: 179.5403 - val_loss: 57036.4531 - val_mae: 181.1667\n",
      "Epoch 52/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 55641.0859 - mae: 179.5403 - val_loss: 57036.4531 - val_mae: 181.1667\n",
      "Epoch 52/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 55132.0352 - mae: 179.0197 - val_loss: 59536.5000 - val_mae: 188.3314\n",
      "Epoch 53/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 55132.0352 - mae: 179.0197 - val_loss: 59536.5000 - val_mae: 188.3314\n",
      "Epoch 53/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 54718.2070 - mae: 178.0228 - val_loss: 57438.3516 - val_mae: 181.4590\n",
      "Epoch 54/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 54718.2070 - mae: 178.0228 - val_loss: 57438.3516 - val_mae: 181.4590\n",
      "Epoch 54/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 53771.3047 - mae: 176.5552 - val_loss: 54546.0273 - val_mae: 178.9655\n",
      "Epoch 55/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 53771.3047 - mae: 176.5552 - val_loss: 54546.0273 - val_mae: 178.9655\n",
      "Epoch 55/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 53157.0195 - mae: 175.6601 - val_loss: 55401.0586 - val_mae: 180.6785\n",
      "Epoch 56/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 53157.0195 - mae: 175.6601 - val_loss: 55401.0586 - val_mae: 180.6785\n",
      "Epoch 56/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 52806.7773 - mae: 175.3289 - val_loss: 55247.1641 - val_mae: 180.2357\n",
      "Epoch 57/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 52806.7773 - mae: 175.3289 - val_loss: 55247.1641 - val_mae: 180.2357\n",
      "Epoch 57/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 52230.4922 - mae: 173.7468 - val_loss: 53823.3359 - val_mae: 178.6792\n",
      "Epoch 58/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 52230.4922 - mae: 173.7468 - val_loss: 53823.3359 - val_mae: 178.6792\n",
      "Epoch 58/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 51410.7734 - mae: 173.0383 - val_loss: 51694.0781 - val_mae: 172.9728\n",
      "Epoch 59/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 51410.7734 - mae: 173.0383 - val_loss: 51694.0781 - val_mae: 172.9728\n",
      "Epoch 59/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 51027.2969 - mae: 172.4737 - val_loss: 53120.3477 - val_mae: 177.1478\n",
      "Epoch 60/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 51027.2969 - mae: 172.4737 - val_loss: 53120.3477 - val_mae: 177.1478\n",
      "Epoch 60/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 50541.4062 - mae: 171.4124 - val_loss: 52738.6875 - val_mae: 176.5360\n",
      "Epoch 61/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 50541.4062 - mae: 171.4124 - val_loss: 52738.6875 - val_mae: 176.5360\n",
      "Epoch 61/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 50344.2070 - mae: 171.4685 - val_loss: 52660.4258 - val_mae: 177.0026\n",
      "Epoch 62/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 50344.2070 - mae: 171.4685 - val_loss: 52660.4258 - val_mae: 177.0026\n",
      "Epoch 62/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 50014.9883 - mae: 170.8916 - val_loss: 51186.3281 - val_mae: 173.8198\n",
      "Epoch 63/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 50014.9883 - mae: 170.8916 - val_loss: 51186.3281 - val_mae: 173.8198\n",
      "Epoch 63/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 49817.1211 - mae: 170.7909 - val_loss: 50198.2461 - val_mae: 171.5801\n",
      "Epoch 64/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 49817.1211 - mae: 170.7909 - val_loss: 50198.2461 - val_mae: 171.5801\n",
      "Epoch 64/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 49669.2109 - mae: 170.3285 - val_loss: 53855.2070 - val_mae: 177.5014\n",
      "Epoch 65/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 49669.2109 - mae: 170.3285 - val_loss: 53855.2070 - val_mae: 177.5014\n",
      "Epoch 65/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 49175.5781 - mae: 169.7237 - val_loss: 50872.4844 - val_mae: 173.3094\n",
      "Epoch 66/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 49175.5781 - mae: 169.7237 - val_loss: 50872.4844 - val_mae: 173.3094\n",
      "Epoch 66/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 49112.7305 - mae: 169.9043 - val_loss: 54342.1797 - val_mae: 181.3914\n",
      "Epoch 67/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 49112.7305 - mae: 169.9043 - val_loss: 54342.1797 - val_mae: 181.3914\n",
      "Epoch 67/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 48901.6133 - mae: 169.2122 - val_loss: 51299.2305 - val_mae: 174.7279\n",
      "Epoch 68/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 48901.6133 - mae: 169.2122 - val_loss: 51299.2305 - val_mae: 174.7279\n",
      "Epoch 68/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 48151.9023 - mae: 167.7065 - val_loss: 48601.8281 - val_mae: 169.6062\n",
      "Epoch 69/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 48151.9023 - mae: 167.7065 - val_loss: 48601.8281 - val_mae: 169.6062\n",
      "Epoch 69/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 48351.7109 - mae: 168.2424 - val_loss: 49212.5117 - val_mae: 171.5072\n",
      "Epoch 70/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 48351.7109 - mae: 168.2424 - val_loss: 49212.5117 - val_mae: 171.5072\n",
      "Epoch 70/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 47889.6094 - mae: 167.6004 - val_loss: 49610.9766 - val_mae: 171.6924\n",
      "Epoch 71/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 47889.6094 - mae: 167.6004 - val_loss: 49610.9766 - val_mae: 171.6924\n",
      "Epoch 71/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 47938.8359 - mae: 167.5217 - val_loss: 50388.4570 - val_mae: 173.6570\n",
      "Epoch 72/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 47938.8359 - mae: 167.5217 - val_loss: 50388.4570 - val_mae: 173.6570\n",
      "Epoch 72/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 47390.5742 - mae: 166.8005 - val_loss: 48058.1562 - val_mae: 168.2696\n",
      "Epoch 73/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 47390.5742 - mae: 166.8005 - val_loss: 48058.1562 - val_mae: 168.2696\n",
      "Epoch 73/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 47532.3164 - mae: 166.4547 - val_loss: 50800.5312 - val_mae: 173.9776\n",
      "Epoch 74/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 47532.3164 - mae: 166.4547 - val_loss: 50800.5312 - val_mae: 173.9776\n",
      "Epoch 74/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 47079.6406 - mae: 166.0557 - val_loss: 52480.1484 - val_mae: 177.0412\n",
      "Epoch 75/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 47079.6406 - mae: 166.0557 - val_loss: 52480.1484 - val_mae: 177.0412\n",
      "Epoch 75/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 46789.9883 - mae: 165.5342 - val_loss: 48085.5742 - val_mae: 169.1927\n",
      "Epoch 76/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 46789.9883 - mae: 165.5342 - val_loss: 48085.5742 - val_mae: 169.1927\n",
      "Epoch 76/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 46613.2266 - mae: 165.3429 - val_loss: 50264.6641 - val_mae: 174.4974\n",
      "Epoch 77/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 46613.2266 - mae: 165.3429 - val_loss: 50264.6641 - val_mae: 174.4974\n",
      "Epoch 77/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 46481.6602 - mae: 164.8866 - val_loss: 47339.2305 - val_mae: 167.5511\n",
      "Epoch 78/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 46481.6602 - mae: 164.8866 - val_loss: 47339.2305 - val_mae: 167.5511\n",
      "Epoch 78/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 46334.5352 - mae: 164.6955 - val_loss: 48455.0859 - val_mae: 170.3996\n",
      "Epoch 79/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 46334.5352 - mae: 164.6955 - val_loss: 48455.0859 - val_mae: 170.3996\n",
      "Epoch 79/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 45829.3711 - mae: 163.9762 - val_loss: 46507.5234 - val_mae: 165.8116\n",
      "Epoch 80/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 45829.3711 - mae: 163.9762 - val_loss: 46507.5234 - val_mae: 165.8116\n",
      "Epoch 80/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 45732.0547 - mae: 163.6642 - val_loss: 46359.6523 - val_mae: 165.4267\n",
      "Epoch 81/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 45732.0547 - mae: 163.6642 - val_loss: 46359.6523 - val_mae: 165.4267\n",
      "Epoch 81/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 45609.2617 - mae: 163.3825 - val_loss: 45210.8711 - val_mae: 163.1751\n",
      "Epoch 82/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 45609.2617 - mae: 163.3825 - val_loss: 45210.8711 - val_mae: 163.1751\n",
      "Epoch 82/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 45580.9805 - mae: 163.3629 - val_loss: 47320.2109 - val_mae: 166.6858\n",
      "Epoch 83/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 45580.9805 - mae: 163.3629 - val_loss: 47320.2109 - val_mae: 166.6858\n",
      "Epoch 83/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 44901.4727 - mae: 161.9056 - val_loss: 45948.5977 - val_mae: 164.6493\n",
      "Epoch 84/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 44901.4727 - mae: 161.9056 - val_loss: 45948.5977 - val_mae: 164.6493\n",
      "Epoch 84/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 45347.6016 - mae: 162.8836 - val_loss: 45340.7734 - val_mae: 163.3302\n",
      "Epoch 85/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 45347.6016 - mae: 162.8836 - val_loss: 45340.7734 - val_mae: 163.3302\n",
      "Epoch 85/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 44968.4141 - mae: 161.8599 - val_loss: 44439.5547 - val_mae: 161.9147\n",
      "Epoch 86/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 44968.4141 - mae: 161.8599 - val_loss: 44439.5547 - val_mae: 161.9147\n",
      "Epoch 86/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 44819.6016 - mae: 161.6151 - val_loss: 50150.8633 - val_mae: 171.4826\n",
      "Epoch 87/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 44819.6016 - mae: 161.6151 - val_loss: 50150.8633 - val_mae: 171.4826\n",
      "Epoch 87/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 44754.2227 - mae: 162.0335 - val_loss: 45120.5469 - val_mae: 164.0131\n",
      "Epoch 88/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 44754.2227 - mae: 162.0335 - val_loss: 45120.5469 - val_mae: 164.0131\n",
      "Epoch 88/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 44276.1094 - mae: 160.8737 - val_loss: 44938.9492 - val_mae: 162.0317\n",
      "Epoch 89/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 44276.1094 - mae: 160.8737 - val_loss: 44938.9492 - val_mae: 162.0317\n",
      "Epoch 89/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 44225.0000 - mae: 160.7362 - val_loss: 45973.2031 - val_mae: 165.6335\n",
      "Epoch 90/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 44225.0000 - mae: 160.7362 - val_loss: 45973.2031 - val_mae: 165.6335\n",
      "Epoch 90/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 44095.0938 - mae: 160.8015 - val_loss: 45898.9258 - val_mae: 165.0644\n",
      "Epoch 91/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 44095.0938 - mae: 160.8015 - val_loss: 45898.9258 - val_mae: 165.0644\n",
      "Epoch 91/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 44061.7461 - mae: 160.6022 - val_loss: 44892.6289 - val_mae: 162.7277\n",
      "Epoch 92/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 44061.7461 - mae: 160.6022 - val_loss: 44892.6289 - val_mae: 162.7277\n",
      "Epoch 92/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 43667.3906 - mae: 159.5345 - val_loss: 44153.0078 - val_mae: 160.5605\n",
      "Epoch 93/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 43667.3906 - mae: 159.5345 - val_loss: 44153.0078 - val_mae: 160.5605\n",
      "Epoch 93/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 43766.0039 - mae: 159.8460 - val_loss: 44247.1797 - val_mae: 162.0434\n",
      "Epoch 94/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 43766.0039 - mae: 159.8460 - val_loss: 44247.1797 - val_mae: 162.0434\n",
      "Epoch 94/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 43473.7305 - mae: 159.2682 - val_loss: 47912.5781 - val_mae: 171.6862\n",
      "Epoch 95/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 43473.7305 - mae: 159.2682 - val_loss: 47912.5781 - val_mae: 171.6862\n",
      "Epoch 95/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 43623.3516 - mae: 159.7878 - val_loss: 42835.5469 - val_mae: 159.0229\n",
      "Epoch 96/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 43623.3516 - mae: 159.7878 - val_loss: 42835.5469 - val_mae: 159.0229\n",
      "Epoch 96/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 43371.8320 - mae: 159.2891 - val_loss: 43896.3711 - val_mae: 161.8139\n",
      "Epoch 97/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 43371.8320 - mae: 159.2891 - val_loss: 43896.3711 - val_mae: 161.8139\n",
      "Epoch 97/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 43056.6094 - mae: 158.5573 - val_loss: 44470.8438 - val_mae: 163.5489\n",
      "Epoch 98/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 43056.6094 - mae: 158.5573 - val_loss: 44470.8438 - val_mae: 163.5489\n",
      "Epoch 98/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 43179.3438 - mae: 159.0648 - val_loss: 42545.2969 - val_mae: 158.4042\n",
      "Epoch 99/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 43179.3438 - mae: 159.0648 - val_loss: 42545.2969 - val_mae: 158.4042\n",
      "Epoch 99/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 43140.7422 - mae: 158.5820 - val_loss: 45955.3320 - val_mae: 166.1817\n",
      "Epoch 100/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 43140.7422 - mae: 158.5820 - val_loss: 45955.3320 - val_mae: 166.1817\n",
      "Epoch 100/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 43111.2500 - mae: 158.5061 - val_loss: 43919.6680 - val_mae: 159.7665\n",
      "Epoch 101/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 43111.2500 - mae: 158.5061 - val_loss: 43919.6680 - val_mae: 159.7665\n",
      "Epoch 101/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 42692.2305 - mae: 157.7440 - val_loss: 42930.6055 - val_mae: 160.2553\n",
      "Epoch 102/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 42692.2305 - mae: 157.7440 - val_loss: 42930.6055 - val_mae: 160.2553\n",
      "Epoch 102/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 42807.0898 - mae: 158.0172 - val_loss: 43219.6094 - val_mae: 160.0224\n",
      "Epoch 103/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 42807.0898 - mae: 158.0172 - val_loss: 43219.6094 - val_mae: 160.0224\n",
      "Epoch 103/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 42752.6289 - mae: 157.9742 - val_loss: 46083.0469 - val_mae: 165.4594\n",
      "Epoch 104/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 42752.6289 - mae: 157.9742 - val_loss: 46083.0469 - val_mae: 165.4594\n",
      "Epoch 104/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 42658.3320 - mae: 157.8747 - val_loss: 44612.7656 - val_mae: 161.6574\n",
      "Epoch 105/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 42658.3320 - mae: 157.8747 - val_loss: 44612.7656 - val_mae: 161.6574\n",
      "Epoch 105/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 42595.3242 - mae: 157.6252 - val_loss: 46620.5391 - val_mae: 167.8625\n",
      "Epoch 106/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 42595.3242 - mae: 157.6252 - val_loss: 46620.5391 - val_mae: 167.8625\n",
      "Epoch 106/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 42244.8398 - mae: 157.1709 - val_loss: 44400.5586 - val_mae: 161.9382\n",
      "Epoch 107/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 42244.8398 - mae: 157.1709 - val_loss: 44400.5586 - val_mae: 161.9382\n",
      "Epoch 107/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 42320.9336 - mae: 157.1391 - val_loss: 44431.6055 - val_mae: 163.1373\n",
      "Epoch 108/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 42320.9336 - mae: 157.1391 - val_loss: 44431.6055 - val_mae: 163.1373\n",
      "Epoch 108/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 42146.7305 - mae: 156.4694 - val_loss: 44131.5234 - val_mae: 161.4963\n",
      "Epoch 109/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 42146.7305 - mae: 156.4694 - val_loss: 44131.5234 - val_mae: 161.4963\n",
      "Epoch 109/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 41620.1953 - mae: 155.9678 - val_loss: 45627.1992 - val_mae: 165.0266\n",
      "Epoch 110/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 41620.1953 - mae: 155.9678 - val_loss: 45627.1992 - val_mae: 165.0266\n",
      "Epoch 110/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 41939.1523 - mae: 156.1521 - val_loss: 43340.7109 - val_mae: 159.7898\n",
      "Epoch 111/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 41939.1523 - mae: 156.1521 - val_loss: 43340.7109 - val_mae: 159.7898\n",
      "Epoch 111/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 41851.6367 - mae: 156.3533 - val_loss: 43730.0352 - val_mae: 159.9692\n",
      "Epoch 112/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 41851.6367 - mae: 156.3533 - val_loss: 43730.0352 - val_mae: 159.9692\n",
      "Epoch 112/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 41539.0938 - mae: 155.6387 - val_loss: 47445.2148 - val_mae: 166.5443\n",
      "Epoch 113/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 41539.0938 - mae: 155.6387 - val_loss: 47445.2148 - val_mae: 166.5443\n",
      "Epoch 113/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 41597.4297 - mae: 155.6428 - val_loss: 43064.9531 - val_mae: 159.5006\n",
      "Epoch 114/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 41597.4297 - mae: 155.6428 - val_loss: 43064.9531 - val_mae: 159.5006\n",
      "Epoch 114/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 41201.2539 - mae: 154.7527 - val_loss: 42812.4336 - val_mae: 160.2653\n",
      "Epoch 115/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 41201.2539 - mae: 154.7527 - val_loss: 42812.4336 - val_mae: 160.2653\n",
      "Epoch 115/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 41261.9531 - mae: 155.3303 - val_loss: 41635.7773 - val_mae: 156.3440\n",
      "Epoch 116/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 41261.9531 - mae: 155.3303 - val_loss: 41635.7773 - val_mae: 156.3440\n",
      "Epoch 116/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 41479.3359 - mae: 155.4261 - val_loss: 41728.1328 - val_mae: 157.0124\n",
      "Epoch 117/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 41479.3359 - mae: 155.4261 - val_loss: 41728.1328 - val_mae: 157.0124\n",
      "Epoch 117/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 40985.6445 - mae: 154.6472 - val_loss: 42457.5312 - val_mae: 157.2145\n",
      "Epoch 118/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 40985.6445 - mae: 154.6472 - val_loss: 42457.5312 - val_mae: 157.2145\n",
      "Epoch 118/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 41015.7344 - mae: 154.5525 - val_loss: 40686.4141 - val_mae: 154.9469\n",
      "Epoch 119/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 41015.7344 - mae: 154.5525 - val_loss: 40686.4141 - val_mae: 154.9469\n",
      "Epoch 119/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 40967.4180 - mae: 154.6604 - val_loss: 41279.7656 - val_mae: 156.8322\n",
      "Epoch 120/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 40967.4180 - mae: 154.6604 - val_loss: 41279.7656 - val_mae: 156.8322\n",
      "Epoch 120/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 40951.6406 - mae: 154.5371 - val_loss: 44603.6289 - val_mae: 163.4510\n",
      "Epoch 121/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 40951.6406 - mae: 154.5371 - val_loss: 44603.6289 - val_mae: 163.4510\n",
      "Epoch 121/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 41039.3086 - mae: 154.9608 - val_loss: 40795.4336 - val_mae: 156.1515\n",
      "Epoch 122/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 41039.3086 - mae: 154.9608 - val_loss: 40795.4336 - val_mae: 156.1515\n",
      "Epoch 122/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 40649.1953 - mae: 154.0362 - val_loss: 42083.1328 - val_mae: 158.8674\n",
      "Epoch 123/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 40649.1953 - mae: 154.0362 - val_loss: 42083.1328 - val_mae: 158.8674\n",
      "Epoch 123/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 40677.3398 - mae: 154.3657 - val_loss: 41521.2734 - val_mae: 157.3834\n",
      "Epoch 124/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 40677.3398 - mae: 154.3657 - val_loss: 41521.2734 - val_mae: 157.3834\n",
      "Epoch 124/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 40789.3047 - mae: 154.1700 - val_loss: 40855.9688 - val_mae: 154.4815\n",
      "Epoch 125/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 40789.3047 - mae: 154.1700 - val_loss: 40855.9688 - val_mae: 154.4815\n",
      "Epoch 125/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 40495.8789 - mae: 153.9311 - val_loss: 41302.5039 - val_mae: 155.5642\n",
      "Epoch 126/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 40495.8789 - mae: 153.9311 - val_loss: 41302.5039 - val_mae: 155.5642\n",
      "Epoch 126/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 40436.0859 - mae: 153.5891 - val_loss: 42631.1367 - val_mae: 159.9623\n",
      "Epoch 127/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 40436.0859 - mae: 153.5891 - val_loss: 42631.1367 - val_mae: 159.9623\n",
      "Epoch 127/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 40414.8672 - mae: 153.3981 - val_loss: 41581.3477 - val_mae: 157.9025\n",
      "Epoch 128/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 40414.8672 - mae: 153.3981 - val_loss: 41581.3477 - val_mae: 157.9025\n",
      "Epoch 128/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 40384.3789 - mae: 153.5749 - val_loss: 41078.1094 - val_mae: 156.0213\n",
      "Epoch 129/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 40384.3789 - mae: 153.5749 - val_loss: 41078.1094 - val_mae: 156.0213\n",
      "Epoch 129/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 40316.1875 - mae: 153.1170 - val_loss: 42630.3047 - val_mae: 158.7264\n",
      "Epoch 130/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 40316.1875 - mae: 153.1170 - val_loss: 42630.3047 - val_mae: 158.7264\n",
      "Epoch 130/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 40120.7188 - mae: 152.8720 - val_loss: 41209.9727 - val_mae: 156.3422\n",
      "Epoch 131/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 40120.7188 - mae: 152.8720 - val_loss: 41209.9727 - val_mae: 156.3422\n",
      "Epoch 131/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 40040.2891 - mae: 152.8839 - val_loss: 40549.9453 - val_mae: 155.6347\n",
      "Epoch 132/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 40040.2891 - mae: 152.8839 - val_loss: 40549.9453 - val_mae: 155.6347\n",
      "Epoch 132/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 40312.7656 - mae: 153.0458 - val_loss: 43510.1016 - val_mae: 158.3067\n",
      "Epoch 133/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 40312.7656 - mae: 153.0458 - val_loss: 43510.1016 - val_mae: 158.3067\n",
      "Epoch 133/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 40062.4609 - mae: 153.0300 - val_loss: 40533.4844 - val_mae: 154.0084\n",
      "Epoch 134/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 40062.4609 - mae: 153.0300 - val_loss: 40533.4844 - val_mae: 154.0084\n",
      "Epoch 134/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 40001.1133 - mae: 152.7256 - val_loss: 39670.2266 - val_mae: 151.6075\n",
      "Epoch 135/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 40001.1133 - mae: 152.7256 - val_loss: 39670.2266 - val_mae: 151.6075\n",
      "Epoch 135/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 39830.4883 - mae: 152.4639 - val_loss: 42734.3789 - val_mae: 160.3162\n",
      "Epoch 136/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 39830.4883 - mae: 152.4639 - val_loss: 42734.3789 - val_mae: 160.3162\n",
      "Epoch 136/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 39642.2461 - mae: 151.7291 - val_loss: 39420.9414 - val_mae: 150.6348\n",
      "Epoch 137/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 39642.2461 - mae: 151.7291 - val_loss: 39420.9414 - val_mae: 150.6348\n",
      "Epoch 137/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 39665.6641 - mae: 151.9720 - val_loss: 43545.2891 - val_mae: 160.3696\n",
      "Epoch 138/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 39665.6641 - mae: 151.9720 - val_loss: 43545.2891 - val_mae: 160.3696\n",
      "Epoch 138/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 39284.1055 - mae: 150.9009 - val_loss: 46291.7930 - val_mae: 165.6848\n",
      "Epoch 139/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 39284.1055 - mae: 150.9009 - val_loss: 46291.7930 - val_mae: 165.6848\n",
      "Epoch 139/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 38929.1094 - mae: 150.5403 - val_loss: 40029.2227 - val_mae: 153.0628\n",
      "Epoch 140/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 38929.1094 - mae: 150.5403 - val_loss: 40029.2227 - val_mae: 153.0628\n",
      "Epoch 140/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 39261.6758 - mae: 150.9315 - val_loss: 37998.4922 - val_mae: 147.6390\n",
      "Epoch 141/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 39261.6758 - mae: 150.9315 - val_loss: 37998.4922 - val_mae: 147.6390\n",
      "Epoch 141/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 38571.0117 - mae: 149.9710 - val_loss: 38941.8711 - val_mae: 151.8007\n",
      "Epoch 142/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 38571.0117 - mae: 149.9710 - val_loss: 38941.8711 - val_mae: 151.8007\n",
      "Epoch 142/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 38388.1758 - mae: 149.5353 - val_loss: 38009.3867 - val_mae: 148.8553\n",
      "Epoch 143/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 38388.1758 - mae: 149.5353 - val_loss: 38009.3867 - val_mae: 148.8553\n",
      "Epoch 143/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 38215.7266 - mae: 149.0329 - val_loss: 42473.0352 - val_mae: 160.3887\n",
      "Epoch 144/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 38215.7266 - mae: 149.0329 - val_loss: 42473.0352 - val_mae: 160.3887\n",
      "Epoch 144/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 38216.2812 - mae: 149.1167 - val_loss: 38775.6836 - val_mae: 151.7765\n",
      "Epoch 145/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 38216.2812 - mae: 149.1167 - val_loss: 38775.6836 - val_mae: 151.7765\n",
      "Epoch 145/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 37939.3398 - mae: 148.5765 - val_loss: 38421.3867 - val_mae: 149.7765\n",
      "Epoch 146/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 37939.3398 - mae: 148.5765 - val_loss: 38421.3867 - val_mae: 149.7765\n",
      "Epoch 146/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 37927.9141 - mae: 148.6308 - val_loss: 40508.0156 - val_mae: 154.7697\n",
      "Epoch 147/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 37927.9141 - mae: 148.6308 - val_loss: 40508.0156 - val_mae: 154.7697\n",
      "Epoch 147/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 37819.0820 - mae: 148.4343 - val_loss: 37527.4375 - val_mae: 148.0864\n",
      "Epoch 148/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 37819.0820 - mae: 148.4343 - val_loss: 37527.4375 - val_mae: 148.0864\n",
      "Epoch 148/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 37562.3359 - mae: 147.4601 - val_loss: 40254.0625 - val_mae: 154.4241\n",
      "Epoch 149/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 37562.3359 - mae: 147.4601 - val_loss: 40254.0625 - val_mae: 154.4241\n",
      "Epoch 149/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 37514.7188 - mae: 147.7126 - val_loss: 38308.6055 - val_mae: 149.8029\n",
      "Epoch 150/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 37514.7188 - mae: 147.7126 - val_loss: 38308.6055 - val_mae: 149.8029\n",
      "Epoch 150/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 37350.4219 - mae: 147.2793 - val_loss: 38971.6875 - val_mae: 151.6331\n",
      "Epoch 151/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 37350.4219 - mae: 147.2793 - val_loss: 38971.6875 - val_mae: 151.6331\n",
      "Epoch 151/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 37372.9727 - mae: 147.5788 - val_loss: 41772.5078 - val_mae: 155.4034\n",
      "Epoch 152/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 37372.9727 - mae: 147.5788 - val_loss: 41772.5078 - val_mae: 155.4034\n",
      "Epoch 152/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 37196.0859 - mae: 146.8563 - val_loss: 37193.9414 - val_mae: 147.6678\n",
      "Epoch 153/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 37196.0859 - mae: 146.8563 - val_loss: 37193.9414 - val_mae: 147.6678\n",
      "Epoch 153/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 37288.0742 - mae: 147.2132 - val_loss: 37090.7539 - val_mae: 147.4968\n",
      "Epoch 154/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 37288.0742 - mae: 147.2132 - val_loss: 37090.7539 - val_mae: 147.4968\n",
      "Epoch 154/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 37256.4141 - mae: 146.9752 - val_loss: 37797.8125 - val_mae: 149.1676\n",
      "Epoch 155/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 37256.4141 - mae: 146.9752 - val_loss: 37797.8125 - val_mae: 149.1676\n",
      "Epoch 155/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 36884.9102 - mae: 146.4783 - val_loss: 36078.8633 - val_mae: 145.0479\n",
      "Epoch 156/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 36884.9102 - mae: 146.4783 - val_loss: 36078.8633 - val_mae: 145.0479\n",
      "Epoch 156/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 37166.4609 - mae: 146.7372 - val_loss: 38826.7070 - val_mae: 151.0172\n",
      "Epoch 157/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 37166.4609 - mae: 146.7372 - val_loss: 38826.7070 - val_mae: 151.0172\n",
      "Epoch 157/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 36850.4375 - mae: 146.3327 - val_loss: 36432.5938 - val_mae: 145.6489\n",
      "Epoch 158/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 36850.4375 - mae: 146.3327 - val_loss: 36432.5938 - val_mae: 145.6489\n",
      "Epoch 158/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 36836.4492 - mae: 146.0674 - val_loss: 36770.0859 - val_mae: 147.3204\n",
      "Epoch 159/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 36836.4492 - mae: 146.0674 - val_loss: 36770.0859 - val_mae: 147.3204\n",
      "Epoch 159/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 36257.8828 - mae: 145.0128 - val_loss: 40722.9844 - val_mae: 155.3264\n",
      "Epoch 160/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 36257.8828 - mae: 145.0128 - val_loss: 40722.9844 - val_mae: 155.3264\n",
      "Epoch 160/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 36635.2031 - mae: 145.7356 - val_loss: 36563.4609 - val_mae: 146.8962\n",
      "Epoch 161/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 36635.2031 - mae: 145.7356 - val_loss: 36563.4609 - val_mae: 146.8962\n",
      "Epoch 161/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 36301.9453 - mae: 145.0633 - val_loss: 36976.9336 - val_mae: 147.3566\n",
      "Epoch 162/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 36301.9453 - mae: 145.0633 - val_loss: 36976.9336 - val_mae: 147.3566\n",
      "Epoch 162/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 36382.1797 - mae: 145.4827 - val_loss: 37188.1250 - val_mae: 148.4761\n",
      "Epoch 163/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 36382.1797 - mae: 145.4827 - val_loss: 37188.1250 - val_mae: 148.4761\n",
      "Epoch 163/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 36212.9570 - mae: 145.1296 - val_loss: 37484.0117 - val_mae: 149.2120\n",
      "Epoch 164/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 36212.9570 - mae: 145.1296 - val_loss: 37484.0117 - val_mae: 149.2120\n",
      "Epoch 164/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 36078.6328 - mae: 144.6643 - val_loss: 36372.5703 - val_mae: 147.3527\n",
      "Epoch 165/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 36078.6328 - mae: 144.6643 - val_loss: 36372.5703 - val_mae: 147.3527\n",
      "Epoch 165/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 36021.7344 - mae: 144.6000 - val_loss: 37334.9219 - val_mae: 147.3304\n",
      "Epoch 166/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 36021.7344 - mae: 144.6000 - val_loss: 37334.9219 - val_mae: 147.3304\n",
      "Epoch 166/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 36229.8516 - mae: 145.1147 - val_loss: 37706.2070 - val_mae: 146.2451\n",
      "Epoch 167/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 36229.8516 - mae: 145.1147 - val_loss: 37706.2070 - val_mae: 146.2451\n",
      "Epoch 167/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 35800.3789 - mae: 144.0296 - val_loss: 36064.3594 - val_mae: 145.5602\n",
      "Epoch 168/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 35800.3789 - mae: 144.0296 - val_loss: 36064.3594 - val_mae: 145.5602\n",
      "Epoch 168/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 35910.9805 - mae: 144.3392 - val_loss: 39189.9766 - val_mae: 151.1781\n",
      "Epoch 169/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 35910.9805 - mae: 144.3392 - val_loss: 39189.9766 - val_mae: 151.1781\n",
      "Epoch 169/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 35942.7969 - mae: 144.6084 - val_loss: 37317.6992 - val_mae: 148.9053\n",
      "Epoch 170/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 35942.7969 - mae: 144.6084 - val_loss: 37317.6992 - val_mae: 148.9053\n",
      "Epoch 170/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 35598.4648 - mae: 143.9810 - val_loss: 37919.6758 - val_mae: 149.6125\n",
      "Epoch 171/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 35598.4648 - mae: 143.9810 - val_loss: 37919.6758 - val_mae: 149.6125\n",
      "Epoch 171/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 35576.8711 - mae: 143.5476 - val_loss: 37238.7148 - val_mae: 147.1872\n",
      "Epoch 172/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 35576.8711 - mae: 143.5476 - val_loss: 37238.7148 - val_mae: 147.1872\n",
      "Epoch 172/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 35300.1992 - mae: 143.1192 - val_loss: 36651.9961 - val_mae: 147.0052\n",
      "Epoch 173/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 35300.1992 - mae: 143.1192 - val_loss: 36651.9961 - val_mae: 147.0052\n",
      "Epoch 173/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 35520.4062 - mae: 143.6654 - val_loss: 35004.7305 - val_mae: 142.6000\n",
      "Epoch 174/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 35520.4062 - mae: 143.6654 - val_loss: 35004.7305 - val_mae: 142.6000\n",
      "Epoch 174/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 35617.4648 - mae: 143.7214 - val_loss: 36503.2500 - val_mae: 146.6726\n",
      "Epoch 175/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 35617.4648 - mae: 143.7214 - val_loss: 36503.2500 - val_mae: 146.6726\n",
      "Epoch 175/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 35523.2305 - mae: 143.5288 - val_loss: 38446.7109 - val_mae: 151.5343\n",
      "Epoch 176/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 35523.2305 - mae: 143.5288 - val_loss: 38446.7109 - val_mae: 151.5343\n",
      "Epoch 176/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 35379.2578 - mae: 143.3333 - val_loss: 36036.6992 - val_mae: 143.9503\n",
      "Epoch 177/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 35379.2578 - mae: 143.3333 - val_loss: 36036.6992 - val_mae: 143.9503\n",
      "Epoch 177/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 35352.8867 - mae: 142.8792 - val_loss: 37844.2617 - val_mae: 148.7258\n",
      "Epoch 178/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 35352.8867 - mae: 142.8792 - val_loss: 37844.2617 - val_mae: 148.7258\n",
      "Epoch 178/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 35062.6289 - mae: 142.1552 - val_loss: 34343.0117 - val_mae: 140.9755\n",
      "Epoch 179/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 35062.6289 - mae: 142.1552 - val_loss: 34343.0117 - val_mae: 140.9755\n",
      "Epoch 179/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 35349.4180 - mae: 142.9091 - val_loss: 35491.8906 - val_mae: 144.0846\n",
      "Epoch 180/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 35349.4180 - mae: 142.9091 - val_loss: 35491.8906 - val_mae: 144.0846\n",
      "Epoch 180/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 35101.7422 - mae: 142.3712 - val_loss: 35664.8320 - val_mae: 145.8108\n",
      "Epoch 181/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 35101.7422 - mae: 142.3712 - val_loss: 35664.8320 - val_mae: 145.8108\n",
      "Epoch 181/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 35266.6719 - mae: 142.6505 - val_loss: 37723.9062 - val_mae: 148.9344\n",
      "Epoch 182/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 35266.6719 - mae: 142.6505 - val_loss: 37723.9062 - val_mae: 148.9344\n",
      "Epoch 182/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 34742.8438 - mae: 141.8513 - val_loss: 36684.2617 - val_mae: 146.3956\n",
      "Epoch 183/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 34742.8438 - mae: 141.8513 - val_loss: 36684.2617 - val_mae: 146.3956\n",
      "Epoch 183/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 35158.2617 - mae: 142.2908 - val_loss: 35644.7227 - val_mae: 144.5301\n",
      "Epoch 184/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 35158.2617 - mae: 142.2908 - val_loss: 35644.7227 - val_mae: 144.5301\n",
      "Epoch 184/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 34821.6445 - mae: 142.0258 - val_loss: 36193.1484 - val_mae: 146.1136\n",
      "Epoch 185/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 34821.6445 - mae: 142.0258 - val_loss: 36193.1484 - val_mae: 146.1136\n",
      "Epoch 185/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 34697.0898 - mae: 141.5462 - val_loss: 37893.6836 - val_mae: 147.3093\n",
      "Epoch 186/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 34697.0898 - mae: 141.5462 - val_loss: 37893.6836 - val_mae: 147.3093\n",
      "Epoch 186/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 34596.3047 - mae: 141.4965 - val_loss: 35333.0508 - val_mae: 143.6100\n",
      "Epoch 187/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 34596.3047 - mae: 141.4965 - val_loss: 35333.0508 - val_mae: 143.6100\n",
      "Epoch 187/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 34636.7891 - mae: 141.3598 - val_loss: 34672.0547 - val_mae: 141.8413\n",
      "Epoch 188/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 34636.7891 - mae: 141.3598 - val_loss: 34672.0547 - val_mae: 141.8413\n",
      "Epoch 188/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 34469.3750 - mae: 140.9756 - val_loss: 35386.4805 - val_mae: 144.4023\n",
      "Epoch 189/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 34469.3750 - mae: 140.9756 - val_loss: 35386.4805 - val_mae: 144.4023\n",
      "Epoch 189/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 34802.6016 - mae: 141.3014 - val_loss: 34864.5391 - val_mae: 142.9081\n",
      "Epoch 190/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 34802.6016 - mae: 141.3014 - val_loss: 34864.5391 - val_mae: 142.9081\n",
      "Epoch 190/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 34380.4453 - mae: 141.0016 - val_loss: 34434.5078 - val_mae: 140.9711\n",
      "Epoch 191/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 34380.4453 - mae: 141.0016 - val_loss: 34434.5078 - val_mae: 140.9711\n",
      "Epoch 191/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 34328.3945 - mae: 140.5282 - val_loss: 37042.3867 - val_mae: 148.1909\n",
      "Epoch 192/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 34328.3945 - mae: 140.5282 - val_loss: 37042.3867 - val_mae: 148.1909\n",
      "Epoch 192/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 34464.2188 - mae: 140.9402 - val_loss: 33709.9453 - val_mae: 140.1969\n",
      "Epoch 193/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 34464.2188 - mae: 140.9402 - val_loss: 33709.9453 - val_mae: 140.1969\n",
      "Epoch 193/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 34026.7969 - mae: 139.8861 - val_loss: 34642.0273 - val_mae: 142.3760\n",
      "Epoch 194/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 34026.7969 - mae: 139.8861 - val_loss: 34642.0273 - val_mae: 142.3760\n",
      "Epoch 194/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 34080.9922 - mae: 140.3849 - val_loss: 36295.4961 - val_mae: 145.2050\n",
      "Epoch 195/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 34080.9922 - mae: 140.3849 - val_loss: 36295.4961 - val_mae: 145.2050\n",
      "Epoch 195/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 34300.9219 - mae: 140.5980 - val_loss: 34581.6875 - val_mae: 141.0679\n",
      "Epoch 196/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 34300.9219 - mae: 140.5980 - val_loss: 34581.6875 - val_mae: 141.0679\n",
      "Epoch 196/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 33953.1719 - mae: 139.7119 - val_loss: 34728.6719 - val_mae: 141.7335\n",
      "Epoch 197/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 33953.1719 - mae: 139.7119 - val_loss: 34728.6719 - val_mae: 141.7335\n",
      "Epoch 197/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 34076.6172 - mae: 140.0634 - val_loss: 35149.5977 - val_mae: 143.2610\n",
      "Epoch 198/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 34076.6172 - mae: 140.0634 - val_loss: 35149.5977 - val_mae: 143.2610\n",
      "Epoch 198/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 33735.1367 - mae: 139.5083 - val_loss: 33445.3281 - val_mae: 139.5686\n",
      "Epoch 199/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 33735.1367 - mae: 139.5083 - val_loss: 33445.3281 - val_mae: 139.5686\n",
      "Epoch 199/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 33791.4922 - mae: 139.6591 - val_loss: 34293.2539 - val_mae: 141.2588\n",
      "Epoch 200/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 33791.4922 - mae: 139.6591 - val_loss: 34293.2539 - val_mae: 141.2588\n",
      "Epoch 200/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 33696.4102 - mae: 139.4270 - val_loss: 35606.6758 - val_mae: 142.7537\n",
      "Epoch 201/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 33696.4102 - mae: 139.4270 - val_loss: 35606.6758 - val_mae: 142.7537\n",
      "Epoch 201/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 33640.2891 - mae: 139.2970 - val_loss: 35360.0312 - val_mae: 144.1053\n",
      "Epoch 202/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 33640.2891 - mae: 139.2970 - val_loss: 35360.0312 - val_mae: 144.1053\n",
      "Epoch 202/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 33689.4531 - mae: 139.2445 - val_loss: 35323.4102 - val_mae: 143.8435\n",
      "Epoch 203/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 33689.4531 - mae: 139.2445 - val_loss: 35323.4102 - val_mae: 143.8435\n",
      "Epoch 203/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 33686.9102 - mae: 139.6090 - val_loss: 33612.8359 - val_mae: 139.1961\n",
      "Epoch 204/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 33686.9102 - mae: 139.6090 - val_loss: 33612.8359 - val_mae: 139.1961\n",
      "Epoch 204/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 33698.3008 - mae: 139.4913 - val_loss: 35280.4219 - val_mae: 144.4809\n",
      "Epoch 205/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 33698.3008 - mae: 139.4913 - val_loss: 35280.4219 - val_mae: 144.4809\n",
      "Epoch 205/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 33452.4297 - mae: 138.7995 - val_loss: 35773.4531 - val_mae: 145.5450\n",
      "Epoch 206/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 33452.4297 - mae: 138.7995 - val_loss: 35773.4531 - val_mae: 145.5450\n",
      "Epoch 206/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 33512.1016 - mae: 139.0781 - val_loss: 35636.6172 - val_mae: 145.5392\n",
      "Epoch 207/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 33512.1016 - mae: 139.0781 - val_loss: 35636.6172 - val_mae: 145.5392\n",
      "Epoch 207/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 33325.2422 - mae: 138.4339 - val_loss: 36039.7969 - val_mae: 146.4740\n",
      "Epoch 208/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 33325.2422 - mae: 138.4339 - val_loss: 36039.7969 - val_mae: 146.4740\n",
      "Epoch 208/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 33556.5117 - mae: 139.1726 - val_loss: 33559.0391 - val_mae: 139.8945\n",
      "Epoch 209/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 33556.5117 - mae: 139.1726 - val_loss: 33559.0391 - val_mae: 139.8945\n",
      "Epoch 209/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 33572.7773 - mae: 139.0855 - val_loss: 33863.5938 - val_mae: 140.4065\n",
      "Epoch 210/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 33572.7773 - mae: 139.0855 - val_loss: 33863.5938 - val_mae: 140.4065\n",
      "Epoch 210/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 33287.0859 - mae: 138.1474 - val_loss: 36042.3516 - val_mae: 146.0669\n",
      "Epoch 211/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 33287.0859 - mae: 138.1474 - val_loss: 36042.3516 - val_mae: 146.0669\n",
      "Epoch 211/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 33082.3555 - mae: 138.1762 - val_loss: 34428.2812 - val_mae: 142.1915\n",
      "Epoch 212/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 33082.3555 - mae: 138.1762 - val_loss: 34428.2812 - val_mae: 142.1915\n",
      "Epoch 212/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 33193.6875 - mae: 138.1807 - val_loss: 34325.9727 - val_mae: 141.4779\n",
      "Epoch 213/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 33193.6875 - mae: 138.1807 - val_loss: 34325.9727 - val_mae: 141.4779\n",
      "Epoch 213/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 33401.6289 - mae: 138.5701 - val_loss: 33152.1211 - val_mae: 139.0943\n",
      "Epoch 214/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 33401.6289 - mae: 138.5701 - val_loss: 33152.1211 - val_mae: 139.0943\n",
      "Epoch 214/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 32978.7539 - mae: 137.8718 - val_loss: 34124.3242 - val_mae: 139.8592\n",
      "Epoch 215/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 32978.7539 - mae: 137.8718 - val_loss: 34124.3242 - val_mae: 139.8592\n",
      "Epoch 215/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 33136.6836 - mae: 138.0232 - val_loss: 34614.1914 - val_mae: 142.1367\n",
      "Epoch 216/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 33136.6836 - mae: 138.0232 - val_loss: 34614.1914 - val_mae: 142.1367\n",
      "Epoch 216/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 33052.1992 - mae: 138.0342 - val_loss: 34406.9805 - val_mae: 141.8060\n",
      "Epoch 217/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 33052.1992 - mae: 138.0342 - val_loss: 34406.9805 - val_mae: 141.8060\n",
      "Epoch 217/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 32919.7383 - mae: 137.7275 - val_loss: 33684.1250 - val_mae: 141.3596\n",
      "Epoch 218/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 32919.7383 - mae: 137.7275 - val_loss: 33684.1250 - val_mae: 141.3596\n",
      "Epoch 218/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 32805.7852 - mae: 137.7056 - val_loss: 34053.5312 - val_mae: 140.6642\n",
      "Epoch 219/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 32805.7852 - mae: 137.7056 - val_loss: 34053.5312 - val_mae: 140.6642\n",
      "Epoch 219/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 32765.1211 - mae: 137.6609 - val_loss: 33783.8945 - val_mae: 140.2518\n",
      "Epoch 220/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 32765.1211 - mae: 137.6609 - val_loss: 33783.8945 - val_mae: 140.2518\n",
      "Epoch 220/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 32534.9844 - mae: 136.9259 - val_loss: 32579.5488 - val_mae: 137.8896\n",
      "Epoch 221/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 32534.9844 - mae: 136.9259 - val_loss: 32579.5488 - val_mae: 137.8896\n",
      "Epoch 221/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 32609.1426 - mae: 137.1119 - val_loss: 32661.2734 - val_mae: 137.7042\n",
      "Epoch 222/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 32609.1426 - mae: 137.1119 - val_loss: 32661.2734 - val_mae: 137.7042\n",
      "Epoch 222/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 32555.6406 - mae: 137.2966 - val_loss: 33199.4609 - val_mae: 138.3928\n",
      "Epoch 223/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 32555.6406 - mae: 137.2966 - val_loss: 33199.4609 - val_mae: 138.3928\n",
      "Epoch 223/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 32696.3535 - mae: 136.8543 - val_loss: 32738.5801 - val_mae: 137.5477\n",
      "Epoch 224/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 32696.3535 - mae: 136.8543 - val_loss: 32738.5801 - val_mae: 137.5477\n",
      "Epoch 224/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 32585.5195 - mae: 137.1644 - val_loss: 32554.3867 - val_mae: 136.3922\n",
      "Epoch 225/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 32585.5195 - mae: 137.1644 - val_loss: 32554.3867 - val_mae: 136.3922\n",
      "Epoch 225/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 32502.4141 - mae: 137.1853 - val_loss: 33087.8438 - val_mae: 139.0634\n",
      "Epoch 226/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 32502.4141 - mae: 137.1853 - val_loss: 33087.8438 - val_mae: 139.0634\n",
      "Epoch 226/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 32287.4727 - mae: 136.3594 - val_loss: 32493.0488 - val_mae: 136.4729\n",
      "Epoch 227/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 32287.4727 - mae: 136.3594 - val_loss: 32493.0488 - val_mae: 136.4729\n",
      "Epoch 227/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 32327.7578 - mae: 136.6188 - val_loss: 33044.4727 - val_mae: 139.2177\n",
      "Epoch 228/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 32327.7578 - mae: 136.6188 - val_loss: 33044.4727 - val_mae: 139.2177\n",
      "Epoch 228/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 32234.2656 - mae: 136.4046 - val_loss: 32488.8613 - val_mae: 137.9996\n",
      "Epoch 229/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 32234.2656 - mae: 136.4046 - val_loss: 32488.8613 - val_mae: 137.9996\n",
      "Epoch 229/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 32247.7910 - mae: 136.4958 - val_loss: 32370.8203 - val_mae: 136.6831\n",
      "Epoch 230/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 32247.7910 - mae: 136.4958 - val_loss: 32370.8203 - val_mae: 136.6831\n",
      "Epoch 230/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 32243.5723 - mae: 136.2638 - val_loss: 32367.9062 - val_mae: 137.4536\n",
      "Epoch 231/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 32243.5723 - mae: 136.2638 - val_loss: 32367.9062 - val_mae: 137.4536\n",
      "Epoch 231/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 32375.4023 - mae: 136.6374 - val_loss: 31325.5391 - val_mae: 134.9590\n",
      "Epoch 232/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 32375.4023 - mae: 136.6374 - val_loss: 31325.5391 - val_mae: 134.9590\n",
      "Epoch 232/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 31868.8164 - mae: 135.7708 - val_loss: 33234.5781 - val_mae: 139.0007\n",
      "Epoch 233/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 31868.8164 - mae: 135.7708 - val_loss: 33234.5781 - val_mae: 139.0007\n",
      "Epoch 233/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 32167.3594 - mae: 136.2241 - val_loss: 34232.4297 - val_mae: 143.1950\n",
      "Epoch 234/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 32167.3594 - mae: 136.2241 - val_loss: 34232.4297 - val_mae: 143.1950\n",
      "Epoch 234/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 32003.7930 - mae: 135.8279 - val_loss: 31202.9277 - val_mae: 133.8603\n",
      "Epoch 235/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 32003.7930 - mae: 135.8279 - val_loss: 31202.9277 - val_mae: 133.8603\n",
      "Epoch 235/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 31682.6816 - mae: 134.7947 - val_loss: 33686.1289 - val_mae: 140.7582\n",
      "Epoch 236/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 31682.6816 - mae: 134.7947 - val_loss: 33686.1289 - val_mae: 140.7582\n",
      "Epoch 236/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 32082.0469 - mae: 135.9975 - val_loss: 31108.0293 - val_mae: 134.2161\n",
      "Epoch 237/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 32082.0469 - mae: 135.9975 - val_loss: 31108.0293 - val_mae: 134.2161\n",
      "Epoch 237/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 31700.1836 - mae: 134.9866 - val_loss: 33279.0469 - val_mae: 137.7053\n",
      "Epoch 238/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 31700.1836 - mae: 134.9866 - val_loss: 33279.0469 - val_mae: 137.7053\n",
      "Epoch 238/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 32031.9316 - mae: 135.9908 - val_loss: 32832.5195 - val_mae: 138.6027\n",
      "Epoch 239/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 32031.9316 - mae: 135.9908 - val_loss: 32832.5195 - val_mae: 138.6027\n",
      "Epoch 239/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31612.6172 - mae: 135.0399 - val_loss: 33864.9023 - val_mae: 141.3380\n",
      "Epoch 240/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31612.6172 - mae: 135.0399 - val_loss: 33864.9023 - val_mae: 141.3380\n",
      "Epoch 240/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 31820.0762 - mae: 135.1562 - val_loss: 33892.3047 - val_mae: 139.9415\n",
      "Epoch 241/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 31820.0762 - mae: 135.1562 - val_loss: 33892.3047 - val_mae: 139.9415\n",
      "Epoch 241/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 31703.1055 - mae: 134.9223 - val_loss: 32945.9414 - val_mae: 138.6263\n",
      "Epoch 242/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 31703.1055 - mae: 134.9223 - val_loss: 32945.9414 - val_mae: 138.6263\n",
      "Epoch 242/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 31519.1934 - mae: 134.5918 - val_loss: 35316.8008 - val_mae: 143.9095\n",
      "Epoch 243/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 31519.1934 - mae: 134.5918 - val_loss: 35316.8008 - val_mae: 143.9095\n",
      "Epoch 243/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 31609.9551 - mae: 135.0535 - val_loss: 31964.5195 - val_mae: 136.4393\n",
      "Epoch 244/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 31609.9551 - mae: 135.0535 - val_loss: 31964.5195 - val_mae: 136.4393\n",
      "Epoch 244/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 31690.8691 - mae: 135.0793 - val_loss: 31795.0176 - val_mae: 135.1165\n",
      "Epoch 245/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 31690.8691 - mae: 135.0793 - val_loss: 31795.0176 - val_mae: 135.1165\n",
      "Epoch 245/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31812.2988 - mae: 135.2599 - val_loss: 34266.1367 - val_mae: 140.9925\n",
      "Epoch 246/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31812.2988 - mae: 135.2599 - val_loss: 34266.1367 - val_mae: 140.9925\n",
      "Epoch 246/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31528.1328 - mae: 134.6567 - val_loss: 31694.2129 - val_mae: 136.5730\n",
      "Epoch 247/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31528.1328 - mae: 134.6567 - val_loss: 31694.2129 - val_mae: 136.5730\n",
      "Epoch 247/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 31505.7246 - mae: 134.8319 - val_loss: 38249.8867 - val_mae: 151.5896\n",
      "Epoch 248/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 31505.7246 - mae: 134.8319 - val_loss: 38249.8867 - val_mae: 151.5896\n",
      "Epoch 248/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 31515.0723 - mae: 134.8640 - val_loss: 32583.0957 - val_mae: 137.9465\n",
      "Epoch 249/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 31515.0723 - mae: 134.8640 - val_loss: 32583.0957 - val_mae: 137.9465\n",
      "Epoch 249/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 31284.4043 - mae: 134.1971 - val_loss: 31593.4707 - val_mae: 135.1443\n",
      "Epoch 250/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 31284.4043 - mae: 134.1971 - val_loss: 31593.4707 - val_mae: 135.1443\n",
      "Epoch 250/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 31583.7695 - mae: 135.1817 - val_loss: 30665.9316 - val_mae: 133.3584\n",
      "Epoch 251/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 31583.7695 - mae: 135.1817 - val_loss: 30665.9316 - val_mae: 133.3584\n",
      "Epoch 251/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 31167.4844 - mae: 133.8337 - val_loss: 32997.5977 - val_mae: 138.4216\n",
      "Epoch 252/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 31167.4844 - mae: 133.8337 - val_loss: 32997.5977 - val_mae: 138.4216\n",
      "Epoch 252/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 31193.0137 - mae: 134.2053 - val_loss: 31644.4590 - val_mae: 134.5680\n",
      "Epoch 253/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 31193.0137 - mae: 134.2053 - val_loss: 31644.4590 - val_mae: 134.5680\n",
      "Epoch 253/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 30959.3418 - mae: 133.2820 - val_loss: 31396.5586 - val_mae: 135.7521\n",
      "Epoch 254/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 30959.3418 - mae: 133.2820 - val_loss: 31396.5586 - val_mae: 135.7521\n",
      "Epoch 254/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 31247.2383 - mae: 134.0077 - val_loss: 30981.6074 - val_mae: 134.1761\n",
      "Epoch 255/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 31247.2383 - mae: 134.0077 - val_loss: 30981.6074 - val_mae: 134.1761\n",
      "Epoch 255/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 31166.3105 - mae: 133.7012 - val_loss: 30931.4199 - val_mae: 134.0596\n",
      "Epoch 256/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 31166.3105 - mae: 133.7012 - val_loss: 30931.4199 - val_mae: 134.0596\n",
      "Epoch 256/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 31009.4609 - mae: 133.3503 - val_loss: 32534.6738 - val_mae: 137.2200\n",
      "Epoch 257/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 31009.4609 - mae: 133.3503 - val_loss: 32534.6738 - val_mae: 137.2200\n",
      "Epoch 257/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 31305.3398 - mae: 134.0740 - val_loss: 32726.5781 - val_mae: 137.9290\n",
      "Epoch 258/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 31305.3398 - mae: 134.0740 - val_loss: 32726.5781 - val_mae: 137.9290\n",
      "Epoch 258/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31040.4863 - mae: 133.5305 - val_loss: 34306.2461 - val_mae: 142.5223\n",
      "Epoch 259/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 31040.4863 - mae: 133.5305 - val_loss: 34306.2461 - val_mae: 142.5223\n",
      "Epoch 259/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 30949.3535 - mae: 133.2275 - val_loss: 30884.0879 - val_mae: 133.3991\n",
      "Epoch 260/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 30949.3535 - mae: 133.2275 - val_loss: 30884.0879 - val_mae: 133.3991\n",
      "Epoch 260/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 30899.2441 - mae: 132.9962 - val_loss: 35408.6914 - val_mae: 147.0015\n",
      "Epoch 261/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 30899.2441 - mae: 132.9962 - val_loss: 35408.6914 - val_mae: 147.0015\n",
      "Epoch 261/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 30839.6973 - mae: 133.3512 - val_loss: 31080.4023 - val_mae: 133.5107\n",
      "Epoch 262/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 30839.6973 - mae: 133.3512 - val_loss: 31080.4023 - val_mae: 133.5107\n",
      "Epoch 262/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 30904.4297 - mae: 133.3355 - val_loss: 31684.5898 - val_mae: 136.0066\n",
      "Epoch 263/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 30904.4297 - mae: 133.3355 - val_loss: 31684.5898 - val_mae: 136.0066\n",
      "Epoch 263/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 31060.1367 - mae: 133.7023 - val_loss: 30262.7598 - val_mae: 131.3713\n",
      "Epoch 264/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 31060.1367 - mae: 133.7023 - val_loss: 30262.7598 - val_mae: 131.3713\n",
      "Epoch 264/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 30778.8281 - mae: 132.7590 - val_loss: 31112.3750 - val_mae: 134.3311\n",
      "Epoch 265/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 30778.8281 - mae: 132.7590 - val_loss: 31112.3750 - val_mae: 134.3311\n",
      "Epoch 265/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 30672.0449 - mae: 132.5346 - val_loss: 35413.4727 - val_mae: 140.7677\n",
      "Epoch 266/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 30672.0449 - mae: 132.5346 - val_loss: 35413.4727 - val_mae: 140.7677\n",
      "Epoch 266/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 30767.9473 - mae: 132.9976 - val_loss: 30630.1426 - val_mae: 134.1322\n",
      "Epoch 267/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 30767.9473 - mae: 132.9976 - val_loss: 30630.1426 - val_mae: 134.1322\n",
      "Epoch 267/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 30931.3223 - mae: 133.2091 - val_loss: 32304.8281 - val_mae: 137.2342\n",
      "Epoch 268/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 30931.3223 - mae: 133.2091 - val_loss: 32304.8281 - val_mae: 137.2342\n",
      "Epoch 268/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 30562.6641 - mae: 132.6330 - val_loss: 33329.4883 - val_mae: 138.9912\n",
      "Epoch 269/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 30562.6641 - mae: 132.6330 - val_loss: 33329.4883 - val_mae: 138.9912\n",
      "Epoch 269/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 30897.4414 - mae: 132.7789 - val_loss: 30405.2441 - val_mae: 132.7638\n",
      "Epoch 270/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 30897.4414 - mae: 132.7789 - val_loss: 30405.2441 - val_mae: 132.7638\n",
      "Epoch 270/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 30647.1562 - mae: 132.6772 - val_loss: 31555.0391 - val_mae: 135.3937\n",
      "Epoch 271/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 30647.1562 - mae: 132.6772 - val_loss: 31555.0391 - val_mae: 135.3937\n",
      "Epoch 271/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 30764.6348 - mae: 132.8912 - val_loss: 31360.1387 - val_mae: 135.2048\n",
      "Epoch 272/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 30764.6348 - mae: 132.8912 - val_loss: 31360.1387 - val_mae: 135.2048\n",
      "Epoch 272/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 30483.5586 - mae: 132.1563 - val_loss: 31102.1973 - val_mae: 134.5463\n",
      "Epoch 273/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 30483.5586 - mae: 132.1563 - val_loss: 31102.1973 - val_mae: 134.5463\n",
      "Epoch 273/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 30568.1855 - mae: 132.3779 - val_loss: 30564.1953 - val_mae: 132.5535\n",
      "Epoch 274/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 30568.1855 - mae: 132.3779 - val_loss: 30564.1953 - val_mae: 132.5535\n",
      "Epoch 274/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 30594.7363 - mae: 132.4515 - val_loss: 30215.0879 - val_mae: 132.2120\n",
      "Epoch 275/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 30594.7363 - mae: 132.4515 - val_loss: 30215.0879 - val_mae: 132.2120\n",
      "Epoch 275/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 30429.7188 - mae: 131.9594 - val_loss: 32173.7109 - val_mae: 136.5372\n",
      "Epoch 276/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 30429.7188 - mae: 131.9594 - val_loss: 32173.7109 - val_mae: 136.5372\n",
      "Epoch 276/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 30625.7871 - mae: 132.5262 - val_loss: 30610.2168 - val_mae: 133.4089\n",
      "Epoch 277/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 30625.7871 - mae: 132.5262 - val_loss: 30610.2168 - val_mae: 133.4089\n",
      "Epoch 277/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 30322.8672 - mae: 132.1004 - val_loss: 29843.6680 - val_mae: 131.4143\n",
      "Epoch 278/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 30322.8672 - mae: 132.1004 - val_loss: 29843.6680 - val_mae: 131.4143\n",
      "Epoch 278/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 30376.1855 - mae: 131.8589 - val_loss: 35115.0430 - val_mae: 143.8599\n",
      "Epoch 279/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 30376.1855 - mae: 131.8589 - val_loss: 35115.0430 - val_mae: 143.8599\n",
      "Epoch 279/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 30327.8984 - mae: 131.8149 - val_loss: 32840.9531 - val_mae: 139.3231\n",
      "Epoch 280/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 30327.8984 - mae: 131.8149 - val_loss: 32840.9531 - val_mae: 139.3231\n",
      "Epoch 280/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 30338.8789 - mae: 131.6969 - val_loss: 30210.6562 - val_mae: 132.8915\n",
      "Epoch 281/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 30338.8789 - mae: 131.6969 - val_loss: 30210.6562 - val_mae: 132.8915\n",
      "Epoch 281/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 30247.4961 - mae: 131.4573 - val_loss: 30291.9570 - val_mae: 132.4007\n",
      "Epoch 282/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 30247.4961 - mae: 131.4573 - val_loss: 30291.9570 - val_mae: 132.4007\n",
      "Epoch 282/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 30131.8613 - mae: 131.2967 - val_loss: 30271.6270 - val_mae: 132.0381\n",
      "Epoch 283/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 30131.8613 - mae: 131.2967 - val_loss: 30271.6270 - val_mae: 132.0381\n",
      "Epoch 283/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 30409.5918 - mae: 132.1929 - val_loss: 32532.7891 - val_mae: 138.5698\n",
      "Epoch 284/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 30409.5918 - mae: 132.1929 - val_loss: 32532.7891 - val_mae: 138.5698\n",
      "Epoch 284/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 30224.6309 - mae: 131.4654 - val_loss: 30202.1191 - val_mae: 132.0456\n",
      "Epoch 285/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 30224.6309 - mae: 131.4654 - val_loss: 30202.1191 - val_mae: 132.0456\n",
      "Epoch 285/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 30073.7246 - mae: 131.1449 - val_loss: 30453.3438 - val_mae: 132.4745\n",
      "Epoch 286/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 30073.7246 - mae: 131.1449 - val_loss: 30453.3438 - val_mae: 132.4745\n",
      "Epoch 286/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 30211.4199 - mae: 131.8428 - val_loss: 31533.4414 - val_mae: 135.4047\n",
      "Epoch 287/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 30211.4199 - mae: 131.8428 - val_loss: 31533.4414 - val_mae: 135.4047\n",
      "Epoch 287/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 30140.7520 - mae: 131.4236 - val_loss: 30875.3027 - val_mae: 133.2247\n",
      "Epoch 288/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 30140.7520 - mae: 131.4236 - val_loss: 30875.3027 - val_mae: 133.2247\n",
      "Epoch 288/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 30289.4023 - mae: 131.7830 - val_loss: 30032.6484 - val_mae: 131.0628\n",
      "Epoch 289/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 30289.4023 - mae: 131.7830 - val_loss: 30032.6484 - val_mae: 131.0628\n",
      "Epoch 289/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 29902.1797 - mae: 130.7742 - val_loss: 31522.3711 - val_mae: 136.4557\n",
      "Epoch 290/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 29902.1797 - mae: 130.7742 - val_loss: 31522.3711 - val_mae: 136.4557\n",
      "Epoch 290/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 29947.2832 - mae: 131.0687 - val_loss: 30605.7539 - val_mae: 132.8568\n",
      "Epoch 291/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 29947.2832 - mae: 131.0687 - val_loss: 30605.7539 - val_mae: 132.8568\n",
      "Epoch 291/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 29777.0645 - mae: 130.7439 - val_loss: 30018.9180 - val_mae: 130.8568\n",
      "Epoch 292/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 29777.0645 - mae: 130.7439 - val_loss: 30018.9180 - val_mae: 130.8568\n",
      "Epoch 292/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29835.1719 - mae: 130.8243 - val_loss: 31332.0801 - val_mae: 134.4108\n",
      "Epoch 293/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29835.1719 - mae: 130.8243 - val_loss: 31332.0801 - val_mae: 134.4108\n",
      "Epoch 293/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 29924.7188 - mae: 130.9745 - val_loss: 29999.8223 - val_mae: 131.1224\n",
      "Epoch 294/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 29924.7188 - mae: 130.9745 - val_loss: 29999.8223 - val_mae: 131.1224\n",
      "Epoch 294/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 29821.5371 - mae: 130.8611 - val_loss: 32061.6367 - val_mae: 137.3829\n",
      "Epoch 295/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 29821.5371 - mae: 130.8611 - val_loss: 32061.6367 - val_mae: 137.3829\n",
      "Epoch 295/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 30116.8086 - mae: 131.3461 - val_loss: 30833.6289 - val_mae: 134.4177\n",
      "Epoch 296/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 30116.8086 - mae: 131.3461 - val_loss: 30833.6289 - val_mae: 134.4177\n",
      "Epoch 296/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 29865.6055 - mae: 130.6967 - val_loss: 28824.5332 - val_mae: 128.5443\n",
      "Epoch 297/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 29865.6055 - mae: 130.6967 - val_loss: 28824.5332 - val_mae: 128.5443\n",
      "Epoch 297/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 29667.9023 - mae: 130.5876 - val_loss: 36243.0156 - val_mae: 146.6645\n",
      "Epoch 298/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 29667.9023 - mae: 130.5876 - val_loss: 36243.0156 - val_mae: 146.6645\n",
      "Epoch 298/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 29795.1172 - mae: 130.7266 - val_loss: 32360.6191 - val_mae: 138.1248\n",
      "Epoch 299/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 29795.1172 - mae: 130.7266 - val_loss: 32360.6191 - val_mae: 138.1248\n",
      "Epoch 299/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 29840.1621 - mae: 130.9080 - val_loss: 30696.5684 - val_mae: 133.2882\n",
      "Epoch 300/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 29840.1621 - mae: 130.9080 - val_loss: 30696.5684 - val_mae: 133.2882\n",
      "Epoch 300/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 29844.5430 - mae: 130.9031 - val_loss: 28906.1914 - val_mae: 129.0469\n",
      "Epoch 301/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 29844.5430 - mae: 130.9031 - val_loss: 28906.1914 - val_mae: 129.0469\n",
      "Epoch 301/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29690.9316 - mae: 130.3850 - val_loss: 29020.5371 - val_mae: 129.6729\n",
      "Epoch 302/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29690.9316 - mae: 130.3850 - val_loss: 29020.5371 - val_mae: 129.6729\n",
      "Epoch 302/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 29706.5254 - mae: 130.1751 - val_loss: 29769.1777 - val_mae: 130.0525\n",
      "Epoch 303/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 29706.5254 - mae: 130.1751 - val_loss: 29769.1777 - val_mae: 130.0525\n",
      "Epoch 303/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 29397.9980 - mae: 129.8183 - val_loss: 30510.2402 - val_mae: 131.9332\n",
      "Epoch 304/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 29397.9980 - mae: 129.8183 - val_loss: 30510.2402 - val_mae: 131.9332\n",
      "Epoch 304/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 29781.5977 - mae: 130.7448 - val_loss: 30793.5156 - val_mae: 133.9466\n",
      "Epoch 305/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 29781.5977 - mae: 130.7448 - val_loss: 30793.5156 - val_mae: 133.9466\n",
      "Epoch 305/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29335.6250 - mae: 129.6697 - val_loss: 29239.6055 - val_mae: 130.0836\n",
      "Epoch 306/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29335.6250 - mae: 129.6697 - val_loss: 29239.6055 - val_mae: 130.0836\n",
      "Epoch 306/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 29480.7637 - mae: 130.1180 - val_loss: 28840.6543 - val_mae: 128.7769\n",
      "Epoch 307/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 29480.7637 - mae: 130.1180 - val_loss: 28840.6543 - val_mae: 128.7769\n",
      "Epoch 307/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 29801.8086 - mae: 130.3882 - val_loss: 31109.5645 - val_mae: 135.0564\n",
      "Epoch 308/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 29801.8086 - mae: 130.3882 - val_loss: 31109.5645 - val_mae: 135.0564\n",
      "Epoch 308/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29380.3242 - mae: 129.8688 - val_loss: 29327.9277 - val_mae: 130.0116\n",
      "Epoch 309/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29380.3242 - mae: 129.8688 - val_loss: 29327.9277 - val_mae: 130.0116\n",
      "Epoch 309/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29513.9082 - mae: 130.0702 - val_loss: 31342.3047 - val_mae: 134.9743\n",
      "Epoch 310/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29513.9082 - mae: 130.0702 - val_loss: 31342.3047 - val_mae: 134.9743\n",
      "Epoch 310/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 29371.2656 - mae: 129.5278 - val_loss: 29392.1211 - val_mae: 130.5063\n",
      "Epoch 311/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 29371.2656 - mae: 129.5278 - val_loss: 29392.1211 - val_mae: 130.5063\n",
      "Epoch 311/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 29325.3691 - mae: 129.5988 - val_loss: 31430.1465 - val_mae: 135.7694\n",
      "Epoch 312/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 29325.3691 - mae: 129.5988 - val_loss: 31430.1465 - val_mae: 135.7694\n",
      "Epoch 312/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 29304.2012 - mae: 129.6185 - val_loss: 29821.4570 - val_mae: 131.0226\n",
      "Epoch 313/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 29304.2012 - mae: 129.6185 - val_loss: 29821.4570 - val_mae: 131.0226\n",
      "Epoch 313/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 29511.5273 - mae: 130.2576 - val_loss: 30429.5527 - val_mae: 132.3271\n",
      "Epoch 314/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 29511.5273 - mae: 130.2576 - val_loss: 30429.5527 - val_mae: 132.3271\n",
      "Epoch 314/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 29325.3984 - mae: 129.6690 - val_loss: 28955.4023 - val_mae: 129.3911\n",
      "Epoch 315/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 29325.3984 - mae: 129.6690 - val_loss: 28955.4023 - val_mae: 129.3911\n",
      "Epoch 315/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29104.5645 - mae: 128.9875 - val_loss: 28877.4355 - val_mae: 128.6135\n",
      "Epoch 316/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29104.5645 - mae: 128.9875 - val_loss: 28877.4355 - val_mae: 128.6135\n",
      "Epoch 316/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29160.3691 - mae: 129.3954 - val_loss: 32364.0664 - val_mae: 136.6952\n",
      "Epoch 317/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 29160.3691 - mae: 129.3954 - val_loss: 32364.0664 - val_mae: 136.6952\n",
      "Epoch 317/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 29289.7324 - mae: 129.0660 - val_loss: 28274.2188 - val_mae: 127.4834\n",
      "Epoch 318/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 29289.7324 - mae: 129.0660 - val_loss: 28274.2188 - val_mae: 127.4834\n",
      "Epoch 318/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 29099.4082 - mae: 129.0943 - val_loss: 28418.3633 - val_mae: 127.4855\n",
      "Epoch 319/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 29099.4082 - mae: 129.0943 - val_loss: 28418.3633 - val_mae: 127.4855\n",
      "Epoch 319/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 29152.3242 - mae: 129.3236 - val_loss: 29687.5020 - val_mae: 131.2509\n",
      "Epoch 320/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 29152.3242 - mae: 129.3236 - val_loss: 29687.5020 - val_mae: 131.2509\n",
      "Epoch 320/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 29097.7559 - mae: 128.9951 - val_loss: 30251.5781 - val_mae: 132.4598\n",
      "Epoch 321/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 29097.7559 - mae: 128.9951 - val_loss: 30251.5781 - val_mae: 132.4598\n",
      "Epoch 321/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 29304.2949 - mae: 129.4769 - val_loss: 29389.8828 - val_mae: 130.8005\n",
      "Epoch 322/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 29304.2949 - mae: 129.4769 - val_loss: 29389.8828 - val_mae: 130.8005\n",
      "Epoch 322/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 28977.9941 - mae: 128.7844 - val_loss: 28767.3672 - val_mae: 128.9558\n",
      "Epoch 323/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 28977.9941 - mae: 128.7844 - val_loss: 28767.3672 - val_mae: 128.9558\n",
      "Epoch 323/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 29166.6934 - mae: 129.0932 - val_loss: 29132.0723 - val_mae: 130.0031\n",
      "Epoch 324/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 29166.6934 - mae: 129.0932 - val_loss: 29132.0723 - val_mae: 130.0031\n",
      "Epoch 324/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 29240.6406 - mae: 129.3498 - val_loss: 29896.1934 - val_mae: 131.9219\n",
      "Epoch 325/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 29240.6406 - mae: 129.3498 - val_loss: 29896.1934 - val_mae: 131.9219\n",
      "Epoch 325/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 29149.2227 - mae: 128.9366 - val_loss: 29311.6816 - val_mae: 129.1952\n",
      "Epoch 326/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 29149.2227 - mae: 128.9366 - val_loss: 29311.6816 - val_mae: 129.1952\n",
      "Epoch 326/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 29038.1602 - mae: 129.2048 - val_loss: 30423.3086 - val_mae: 133.7987\n",
      "Epoch 327/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 29038.1602 - mae: 129.2048 - val_loss: 30423.3086 - val_mae: 133.7987\n",
      "Epoch 327/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 29124.4062 - mae: 129.0977 - val_loss: 29971.0254 - val_mae: 131.2753\n",
      "Epoch 328/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 29124.4062 - mae: 129.0977 - val_loss: 29971.0254 - val_mae: 131.2753\n",
      "Epoch 328/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29008.9062 - mae: 129.0849 - val_loss: 30028.0059 - val_mae: 132.5002\n",
      "Epoch 329/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 29008.9062 - mae: 129.0849 - val_loss: 30028.0059 - val_mae: 132.5002\n",
      "Epoch 329/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 29303.5059 - mae: 129.2785 - val_loss: 28743.9941 - val_mae: 127.8858\n",
      "Epoch 330/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 29303.5059 - mae: 129.2785 - val_loss: 28743.9941 - val_mae: 127.8858\n",
      "Epoch 330/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 28934.6914 - mae: 128.5157 - val_loss: 28896.7051 - val_mae: 128.6707\n",
      "Epoch 331/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 28934.6914 - mae: 128.5157 - val_loss: 28896.7051 - val_mae: 128.6707\n",
      "Epoch 331/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28922.6562 - mae: 128.6285 - val_loss: 30968.4180 - val_mae: 134.1236\n",
      "Epoch 332/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28922.6562 - mae: 128.6285 - val_loss: 30968.4180 - val_mae: 134.1236\n",
      "Epoch 332/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28756.2305 - mae: 128.0723 - val_loss: 29988.3184 - val_mae: 131.1788\n",
      "Epoch 333/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28756.2305 - mae: 128.0723 - val_loss: 29988.3184 - val_mae: 131.1788\n",
      "Epoch 333/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 29069.4258 - mae: 129.0013 - val_loss: 29348.7852 - val_mae: 130.0100\n",
      "Epoch 334/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 29069.4258 - mae: 129.0013 - val_loss: 29348.7852 - val_mae: 130.0100\n",
      "Epoch 334/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 29066.5059 - mae: 128.7734 - val_loss: 29981.8320 - val_mae: 132.3292\n",
      "Epoch 335/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 29066.5059 - mae: 128.7734 - val_loss: 29981.8320 - val_mae: 132.3292\n",
      "Epoch 335/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28738.6328 - mae: 128.4142 - val_loss: 28992.5098 - val_mae: 129.2953\n",
      "Epoch 336/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28738.6328 - mae: 128.4142 - val_loss: 28992.5098 - val_mae: 129.2953\n",
      "Epoch 336/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28790.5508 - mae: 128.0725 - val_loss: 28245.5352 - val_mae: 126.7623\n",
      "Epoch 337/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28790.5508 - mae: 128.0725 - val_loss: 28245.5352 - val_mae: 126.7623\n",
      "Epoch 337/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 28860.8164 - mae: 128.4466 - val_loss: 37112.7773 - val_mae: 149.2589\n",
      "Epoch 338/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 28860.8164 - mae: 128.4466 - val_loss: 37112.7773 - val_mae: 149.2589\n",
      "Epoch 338/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 28834.6719 - mae: 128.3951 - val_loss: 31646.7148 - val_mae: 134.2946\n",
      "Epoch 339/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 28834.6719 - mae: 128.3951 - val_loss: 31646.7148 - val_mae: 134.2946\n",
      "Epoch 339/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 28911.7207 - mae: 128.5081 - val_loss: 28947.2754 - val_mae: 129.7390\n",
      "Epoch 340/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 28911.7207 - mae: 128.5081 - val_loss: 28947.2754 - val_mae: 129.7390\n",
      "Epoch 340/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 28816.7793 - mae: 128.4333 - val_loss: 28931.4102 - val_mae: 128.3016\n",
      "Epoch 341/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 28816.7793 - mae: 128.4333 - val_loss: 28931.4102 - val_mae: 128.3016\n",
      "Epoch 341/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28949.2988 - mae: 128.7364 - val_loss: 28444.9570 - val_mae: 127.8642\n",
      "Epoch 342/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28949.2988 - mae: 128.7364 - val_loss: 28444.9570 - val_mae: 127.8642\n",
      "Epoch 342/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 28725.9648 - mae: 128.3479 - val_loss: 30225.2715 - val_mae: 133.1302\n",
      "Epoch 343/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 28725.9648 - mae: 128.3479 - val_loss: 30225.2715 - val_mae: 133.1302\n",
      "Epoch 343/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 28819.5527 - mae: 128.3411 - val_loss: 31575.3457 - val_mae: 133.6745\n",
      "Epoch 344/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 28819.5527 - mae: 128.3411 - val_loss: 31575.3457 - val_mae: 133.6745\n",
      "Epoch 344/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28653.5000 - mae: 127.9102 - val_loss: 27789.8750 - val_mae: 125.7563\n",
      "Epoch 345/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28653.5000 - mae: 127.9102 - val_loss: 27789.8750 - val_mae: 125.7563\n",
      "Epoch 345/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 28711.8691 - mae: 127.9836 - val_loss: 29035.9844 - val_mae: 129.9462\n",
      "Epoch 346/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 28711.8691 - mae: 127.9836 - val_loss: 29035.9844 - val_mae: 129.9462\n",
      "Epoch 346/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 28902.4785 - mae: 128.2342 - val_loss: 28625.4883 - val_mae: 128.2468\n",
      "Epoch 347/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 28902.4785 - mae: 128.2342 - val_loss: 28625.4883 - val_mae: 128.2468\n",
      "Epoch 347/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28703.3496 - mae: 128.2028 - val_loss: 29026.7148 - val_mae: 129.9059\n",
      "Epoch 348/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 28703.3496 - mae: 128.2028 - val_loss: 29026.7148 - val_mae: 129.9059\n",
      "Epoch 348/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 28666.0117 - mae: 127.6199 - val_loss: 30597.2910 - val_mae: 133.2219\n",
      "Epoch 349/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 28666.0117 - mae: 127.6199 - val_loss: 30597.2910 - val_mae: 133.2219\n",
      "Epoch 349/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 28555.2891 - mae: 127.6636 - val_loss: 29219.5918 - val_mae: 129.9676\n",
      "Epoch 350/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 28555.2891 - mae: 127.6636 - val_loss: 29219.5918 - val_mae: 129.9676\n",
      "Epoch 350/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28643.5137 - mae: 127.8148 - val_loss: 27690.4707 - val_mae: 125.9360\n",
      "Epoch 351/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28643.5137 - mae: 127.8148 - val_loss: 27690.4707 - val_mae: 125.9360\n",
      "Epoch 351/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28462.0566 - mae: 127.4824 - val_loss: 28202.4355 - val_mae: 127.6880\n",
      "Epoch 352/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28462.0566 - mae: 127.4824 - val_loss: 28202.4355 - val_mae: 127.6880\n",
      "Epoch 352/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28663.0664 - mae: 128.0931 - val_loss: 29280.2246 - val_mae: 130.1635\n",
      "Epoch 353/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 28663.0664 - mae: 128.0931 - val_loss: 29280.2246 - val_mae: 130.1635\n",
      "Epoch 353/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 28505.4473 - mae: 127.5942 - val_loss: 30735.1797 - val_mae: 133.5569\n",
      "Epoch 354/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 28505.4473 - mae: 127.5942 - val_loss: 30735.1797 - val_mae: 133.5569\n",
      "Epoch 354/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28597.8711 - mae: 127.6848 - val_loss: 29374.0625 - val_mae: 131.4227\n",
      "Epoch 355/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28597.8711 - mae: 127.6848 - val_loss: 29374.0625 - val_mae: 131.4227\n",
      "Epoch 355/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 28631.9043 - mae: 127.7617 - val_loss: 28351.5977 - val_mae: 128.0133\n",
      "Epoch 356/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 28631.9043 - mae: 127.7617 - val_loss: 28351.5977 - val_mae: 128.0133\n",
      "Epoch 356/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 28462.8984 - mae: 127.5031 - val_loss: 30246.4688 - val_mae: 133.6125\n",
      "Epoch 357/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 28462.8984 - mae: 127.5031 - val_loss: 30246.4688 - val_mae: 133.6125\n",
      "Epoch 357/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 28425.9453 - mae: 127.6380 - val_loss: 28631.7500 - val_mae: 127.7400\n",
      "Epoch 358/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 28425.9453 - mae: 127.6380 - val_loss: 28631.7500 - val_mae: 127.7400\n",
      "Epoch 358/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 28280.8125 - mae: 127.0970 - val_loss: 29844.3867 - val_mae: 131.7372\n",
      "Epoch 359/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 28280.8125 - mae: 127.0970 - val_loss: 29844.3867 - val_mae: 131.7372\n",
      "Epoch 359/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28566.1523 - mae: 127.8984 - val_loss: 28042.3496 - val_mae: 126.7648\n",
      "Epoch 360/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 28566.1523 - mae: 127.8984 - val_loss: 28042.3496 - val_mae: 126.7648\n",
      "Epoch 360/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 28404.6270 - mae: 127.1451 - val_loss: 29135.9707 - val_mae: 130.2429\n",
      "Epoch 361/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 28404.6270 - mae: 127.1451 - val_loss: 29135.9707 - val_mae: 130.2429\n",
      "Epoch 361/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 28404.9355 - mae: 127.0863 - val_loss: 29685.8945 - val_mae: 130.5047\n",
      "Epoch 362/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 28404.9355 - mae: 127.0863 - val_loss: 29685.8945 - val_mae: 130.5047\n",
      "Epoch 362/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 28363.9668 - mae: 127.1160 - val_loss: 27781.0840 - val_mae: 126.1518\n",
      "Epoch 363/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 28363.9668 - mae: 127.1160 - val_loss: 27781.0840 - val_mae: 126.1518\n",
      "Epoch 363/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 28406.6074 - mae: 127.3341 - val_loss: 27936.7949 - val_mae: 126.7049\n",
      "Epoch 364/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 28406.6074 - mae: 127.3341 - val_loss: 27936.7949 - val_mae: 126.7049\n",
      "Epoch 364/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 28332.3184 - mae: 126.7713 - val_loss: 28502.8457 - val_mae: 128.1364\n",
      "Epoch 365/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 28332.3184 - mae: 126.7713 - val_loss: 28502.8457 - val_mae: 128.1364\n",
      "Epoch 365/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 28239.3145 - mae: 126.7580 - val_loss: 27757.5605 - val_mae: 125.6436\n",
      "Epoch 366/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 28239.3145 - mae: 126.7580 - val_loss: 27757.5605 - val_mae: 125.6436\n",
      "Epoch 366/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 28320.5957 - mae: 126.6713 - val_loss: 27231.3613 - val_mae: 125.1485\n",
      "Epoch 367/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 28320.5957 - mae: 126.6713 - val_loss: 27231.3613 - val_mae: 125.1485\n",
      "Epoch 367/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 28306.9727 - mae: 127.1713 - val_loss: 29254.7051 - val_mae: 129.7748\n",
      "Epoch 368/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 28306.9727 - mae: 127.1713 - val_loss: 29254.7051 - val_mae: 129.7748\n",
      "Epoch 368/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 28078.3398 - mae: 126.5008 - val_loss: 27488.5527 - val_mae: 125.1811\n",
      "Epoch 369/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 28078.3398 - mae: 126.5008 - val_loss: 27488.5527 - val_mae: 125.1811\n",
      "Epoch 369/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 28154.2109 - mae: 126.4234 - val_loss: 27399.1816 - val_mae: 125.4352\n",
      "Epoch 370/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 28154.2109 - mae: 126.4234 - val_loss: 27399.1816 - val_mae: 125.4352\n",
      "Epoch 370/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 28227.0137 - mae: 126.8677 - val_loss: 28113.1562 - val_mae: 126.1187\n",
      "Epoch 371/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 28227.0137 - mae: 126.8677 - val_loss: 28113.1562 - val_mae: 126.1187\n",
      "Epoch 371/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 28140.2598 - mae: 126.6449 - val_loss: 30371.4043 - val_mae: 133.0353\n",
      "Epoch 372/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 28140.2598 - mae: 126.6449 - val_loss: 30371.4043 - val_mae: 133.0353\n",
      "Epoch 372/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 28046.1602 - mae: 126.0890 - val_loss: 27601.5723 - val_mae: 125.6400\n",
      "Epoch 373/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 28046.1602 - mae: 126.0890 - val_loss: 27601.5723 - val_mae: 125.6400\n",
      "Epoch 373/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 28131.8242 - mae: 126.5480 - val_loss: 28271.3047 - val_mae: 127.5354\n",
      "Epoch 374/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 28131.8242 - mae: 126.5480 - val_loss: 28271.3047 - val_mae: 127.5354\n",
      "Epoch 374/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 28187.3789 - mae: 126.7608 - val_loss: 31661.6387 - val_mae: 136.6358\n",
      "Epoch 375/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 28187.3789 - mae: 126.7608 - val_loss: 31661.6387 - val_mae: 136.6358\n",
      "Epoch 375/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 28050.0469 - mae: 126.7009 - val_loss: 29089.2930 - val_mae: 128.1215\n",
      "Epoch 376/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 28050.0469 - mae: 126.7009 - val_loss: 29089.2930 - val_mae: 128.1215\n",
      "Epoch 376/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 27944.4551 - mae: 126.3096 - val_loss: 31117.8008 - val_mae: 136.4623\n",
      "Epoch 377/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 27944.4551 - mae: 126.3096 - val_loss: 31117.8008 - val_mae: 136.4623\n",
      "Epoch 377/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 27735.2539 - mae: 125.6837 - val_loss: 27423.1406 - val_mae: 124.8035\n",
      "Epoch 378/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 27735.2539 - mae: 125.6837 - val_loss: 27423.1406 - val_mae: 124.8035\n",
      "Epoch 378/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 27929.8418 - mae: 126.2369 - val_loss: 28772.2207 - val_mae: 129.0876\n",
      "Epoch 379/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 27929.8418 - mae: 126.2369 - val_loss: 28772.2207 - val_mae: 129.0876\n",
      "Epoch 379/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 28102.6387 - mae: 126.2500 - val_loss: 27843.9082 - val_mae: 125.8555\n",
      "Epoch 380/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 28102.6387 - mae: 126.2500 - val_loss: 27843.9082 - val_mae: 125.8555\n",
      "Epoch 380/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 27554.1660 - mae: 125.0441 - val_loss: 28872.6309 - val_mae: 129.4308\n",
      "Epoch 381/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 27554.1660 - mae: 125.0441 - val_loss: 28872.6309 - val_mae: 129.4308\n",
      "Epoch 381/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 27869.1484 - mae: 125.7756 - val_loss: 27359.1680 - val_mae: 124.8433\n",
      "Epoch 382/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 27869.1484 - mae: 125.7756 - val_loss: 27359.1680 - val_mae: 124.8433\n",
      "Epoch 382/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 27778.8340 - mae: 125.5836 - val_loss: 27752.5371 - val_mae: 124.9677\n",
      "Epoch 383/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 27778.8340 - mae: 125.5836 - val_loss: 27752.5371 - val_mae: 124.9677\n",
      "Epoch 383/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 27604.3457 - mae: 125.1599 - val_loss: 28253.1055 - val_mae: 127.4954\n",
      "Epoch 384/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 27604.3457 - mae: 125.1599 - val_loss: 28253.1055 - val_mae: 127.4954\n",
      "Epoch 384/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 27715.7031 - mae: 125.5425 - val_loss: 26712.7812 - val_mae: 123.1001\n",
      "Epoch 385/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 27715.7031 - mae: 125.5425 - val_loss: 26712.7812 - val_mae: 123.1001\n",
      "Epoch 385/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 27937.7285 - mae: 126.1574 - val_loss: 27246.8066 - val_mae: 125.2835\n",
      "Epoch 386/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 27937.7285 - mae: 126.1574 - val_loss: 27246.8066 - val_mae: 125.2835\n",
      "Epoch 386/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 27671.8574 - mae: 125.5898 - val_loss: 29920.6465 - val_mae: 132.6160\n",
      "Epoch 387/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 27671.8574 - mae: 125.5898 - val_loss: 29920.6465 - val_mae: 132.6160\n",
      "Epoch 387/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 27493.8809 - mae: 125.1125 - val_loss: 26882.6504 - val_mae: 123.7681\n",
      "Epoch 388/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 27493.8809 - mae: 125.1125 - val_loss: 26882.6504 - val_mae: 123.7681\n",
      "Epoch 388/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 27638.9238 - mae: 125.4245 - val_loss: 27412.9355 - val_mae: 125.6066\n",
      "Epoch 389/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 27638.9238 - mae: 125.4245 - val_loss: 27412.9355 - val_mae: 125.6066\n",
      "Epoch 389/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 27517.9941 - mae: 125.2796 - val_loss: 26631.6191 - val_mae: 122.9505\n",
      "Epoch 390/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 27517.9941 - mae: 125.2796 - val_loss: 26631.6191 - val_mae: 122.9505\n",
      "Epoch 390/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 27392.0020 - mae: 124.7217 - val_loss: 30701.6738 - val_mae: 133.5896\n",
      "Epoch 391/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 27392.0020 - mae: 124.7217 - val_loss: 30701.6738 - val_mae: 133.5896\n",
      "Epoch 391/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 27427.5312 - mae: 125.0573 - val_loss: 27084.8320 - val_mae: 124.4287\n",
      "Epoch 392/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 27427.5312 - mae: 125.0573 - val_loss: 27084.8320 - val_mae: 124.4287\n",
      "Epoch 392/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 27462.0566 - mae: 124.9692 - val_loss: 28270.1543 - val_mae: 128.2305\n",
      "Epoch 393/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 27462.0566 - mae: 124.9692 - val_loss: 28270.1543 - val_mae: 128.2305\n",
      "Epoch 393/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 27504.7910 - mae: 125.0953 - val_loss: 27617.3047 - val_mae: 126.1884\n",
      "Epoch 394/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 27504.7910 - mae: 125.0953 - val_loss: 27617.3047 - val_mae: 126.1884\n",
      "Epoch 394/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 27259.1172 - mae: 124.6619 - val_loss: 27109.7188 - val_mae: 124.4921\n",
      "Epoch 395/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 27259.1172 - mae: 124.6619 - val_loss: 27109.7188 - val_mae: 124.4921\n",
      "Epoch 395/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 27270.0098 - mae: 124.7915 - val_loss: 26544.8496 - val_mae: 123.7066\n",
      "Epoch 396/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 27270.0098 - mae: 124.7915 - val_loss: 26544.8496 - val_mae: 123.7066\n",
      "Epoch 396/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 27320.4648 - mae: 124.7168 - val_loss: 31164.0059 - val_mae: 136.2372\n",
      "Epoch 397/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 27320.4648 - mae: 124.7168 - val_loss: 31164.0059 - val_mae: 136.2372\n",
      "Epoch 397/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 27265.6133 - mae: 124.4057 - val_loss: 31402.3242 - val_mae: 136.2081\n",
      "Epoch 398/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 27265.6133 - mae: 124.4057 - val_loss: 31402.3242 - val_mae: 136.2081\n",
      "Epoch 398/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 27334.1875 - mae: 125.0831 - val_loss: 29760.9180 - val_mae: 132.4499\n",
      "Epoch 399/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 27334.1875 - mae: 125.0831 - val_loss: 29760.9180 - val_mae: 132.4499\n",
      "Epoch 399/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 27457.6387 - mae: 125.0576 - val_loss: 31720.9863 - val_mae: 137.6682\n",
      "Epoch 400/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 27457.6387 - mae: 125.0576 - val_loss: 31720.9863 - val_mae: 137.6682\n",
      "Epoch 400/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 27247.1035 - mae: 124.4763 - val_loss: 27173.1855 - val_mae: 124.3898\n",
      "Epoch 401/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 27247.1035 - mae: 124.4763 - val_loss: 27173.1855 - val_mae: 124.3898\n",
      "Epoch 401/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 27342.9473 - mae: 124.6857 - val_loss: 26620.1719 - val_mae: 123.4942\n",
      "Epoch 402/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 27342.9473 - mae: 124.6857 - val_loss: 26620.1719 - val_mae: 123.4942\n",
      "Epoch 402/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 27226.3418 - mae: 124.5933 - val_loss: 27551.6289 - val_mae: 126.7268\n",
      "Epoch 403/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 27226.3418 - mae: 124.5933 - val_loss: 27551.6289 - val_mae: 126.7268\n",
      "Epoch 403/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 27382.6934 - mae: 124.8714 - val_loss: 26516.2305 - val_mae: 123.7965\n",
      "Epoch 404/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 27382.6934 - mae: 124.8714 - val_loss: 26516.2305 - val_mae: 123.7965\n",
      "Epoch 404/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 27208.5586 - mae: 124.6744 - val_loss: 27504.0664 - val_mae: 126.9240\n",
      "Epoch 405/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 27208.5586 - mae: 124.6744 - val_loss: 27504.0664 - val_mae: 126.9240\n",
      "Epoch 405/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 27085.9141 - mae: 124.3635 - val_loss: 29467.4805 - val_mae: 129.2752\n",
      "Epoch 406/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 27085.9141 - mae: 124.3635 - val_loss: 29467.4805 - val_mae: 129.2752\n",
      "Epoch 406/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 27152.7812 - mae: 124.4326 - val_loss: 27600.5293 - val_mae: 125.9361\n",
      "Epoch 407/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 27152.7812 - mae: 124.4326 - val_loss: 27600.5293 - val_mae: 125.9361\n",
      "Epoch 407/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 27179.1348 - mae: 124.3720 - val_loss: 27805.2793 - val_mae: 126.6044\n",
      "Epoch 408/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 27179.1348 - mae: 124.3720 - val_loss: 27805.2793 - val_mae: 126.6044\n",
      "Epoch 408/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 27198.1270 - mae: 124.4609 - val_loss: 27529.4023 - val_mae: 126.4920\n",
      "Epoch 409/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 27198.1270 - mae: 124.4609 - val_loss: 27529.4023 - val_mae: 126.4920\n",
      "Epoch 409/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 27138.2852 - mae: 124.3457 - val_loss: 27267.2754 - val_mae: 126.1306\n",
      "Epoch 410/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 27138.2852 - mae: 124.3457 - val_loss: 27267.2754 - val_mae: 126.1306\n",
      "Epoch 410/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - loss: 27117.5078 - mae: 124.2657 - val_loss: 26205.1504 - val_mae: 122.5218\n",
      "Epoch 411/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - loss: 27117.5078 - mae: 124.2657 - val_loss: 26205.1504 - val_mae: 122.5218\n",
      "Epoch 411/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 26977.9922 - mae: 123.7594 - val_loss: 29232.2891 - val_mae: 129.6410\n",
      "Epoch 412/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 26977.9922 - mae: 123.7594 - val_loss: 29232.2891 - val_mae: 129.6410\n",
      "Epoch 412/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - loss: 26898.9023 - mae: 123.9216 - val_loss: 27772.8047 - val_mae: 126.2430\n",
      "Epoch 413/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - loss: 26898.9023 - mae: 123.9216 - val_loss: 27772.8047 - val_mae: 126.2430\n",
      "Epoch 413/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 27087.5957 - mae: 124.2988 - val_loss: 27924.6309 - val_mae: 127.2289\n",
      "Epoch 414/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 27087.5957 - mae: 124.2988 - val_loss: 27924.6309 - val_mae: 127.2289\n",
      "Epoch 414/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 26984.2676 - mae: 123.8548 - val_loss: 27724.3535 - val_mae: 126.9680\n",
      "Epoch 415/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 26984.2676 - mae: 123.8548 - val_loss: 27724.3535 - val_mae: 126.9680\n",
      "Epoch 415/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 27118.1504 - mae: 124.2878 - val_loss: 26268.3184 - val_mae: 123.1529\n",
      "Epoch 416/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 27118.1504 - mae: 124.2878 - val_loss: 26268.3184 - val_mae: 123.1529\n",
      "Epoch 416/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 27127.8340 - mae: 124.3373 - val_loss: 29623.7637 - val_mae: 132.6529\n",
      "Epoch 417/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 27127.8340 - mae: 124.3373 - val_loss: 29623.7637 - val_mae: 132.6529\n",
      "Epoch 417/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 26926.8770 - mae: 124.1547 - val_loss: 26307.1836 - val_mae: 123.0480\n",
      "Epoch 418/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 26926.8770 - mae: 124.1547 - val_loss: 26307.1836 - val_mae: 123.0480\n",
      "Epoch 418/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 27068.2070 - mae: 124.2918 - val_loss: 27407.6289 - val_mae: 125.5547\n",
      "Epoch 419/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 27068.2070 - mae: 124.2918 - val_loss: 27407.6289 - val_mae: 125.5547\n",
      "Epoch 419/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26870.2148 - mae: 123.8026 - val_loss: 27094.2051 - val_mae: 126.4053\n",
      "Epoch 420/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26870.2148 - mae: 123.8026 - val_loss: 27094.2051 - val_mae: 126.4053\n",
      "Epoch 420/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 26908.2871 - mae: 123.7819 - val_loss: 26933.8301 - val_mae: 124.6369\n",
      "Epoch 421/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 26908.2871 - mae: 123.7819 - val_loss: 26933.8301 - val_mae: 124.6369\n",
      "Epoch 421/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 26835.3262 - mae: 123.7790 - val_loss: 26449.5527 - val_mae: 123.3204\n",
      "Epoch 422/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 26835.3262 - mae: 123.7790 - val_loss: 26449.5527 - val_mae: 123.3204\n",
      "Epoch 422/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 26868.0781 - mae: 123.8754 - val_loss: 29115.0000 - val_mae: 130.3528\n",
      "Epoch 423/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 26868.0781 - mae: 123.8754 - val_loss: 29115.0000 - val_mae: 130.3528\n",
      "Epoch 423/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 27042.8340 - mae: 124.1618 - val_loss: 27198.8027 - val_mae: 125.4735\n",
      "Epoch 424/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 27042.8340 - mae: 124.1618 - val_loss: 27198.8027 - val_mae: 125.4735\n",
      "Epoch 424/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - loss: 26821.0469 - mae: 123.7560 - val_loss: 29103.2695 - val_mae: 130.5864\n",
      "Epoch 425/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - loss: 26821.0469 - mae: 123.7560 - val_loss: 29103.2695 - val_mae: 130.5864\n",
      "Epoch 425/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26826.4648 - mae: 123.7459 - val_loss: 28026.8750 - val_mae: 128.4413\n",
      "Epoch 426/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26826.4648 - mae: 123.7459 - val_loss: 28026.8750 - val_mae: 128.4413\n",
      "Epoch 426/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 27026.9844 - mae: 124.1744 - val_loss: 28281.1250 - val_mae: 127.4047\n",
      "Epoch 427/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 27026.9844 - mae: 124.1744 - val_loss: 28281.1250 - val_mae: 127.4047\n",
      "Epoch 427/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26881.1777 - mae: 123.9272 - val_loss: 26729.4707 - val_mae: 124.5303\n",
      "Epoch 428/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26881.1777 - mae: 123.9272 - val_loss: 26729.4707 - val_mae: 124.5303\n",
      "Epoch 428/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26792.7109 - mae: 123.5080 - val_loss: 27758.8027 - val_mae: 126.9184\n",
      "Epoch 429/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26792.7109 - mae: 123.5080 - val_loss: 27758.8027 - val_mae: 126.9184\n",
      "Epoch 429/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26840.0723 - mae: 123.7170 - val_loss: 26767.0566 - val_mae: 124.4294\n",
      "Epoch 430/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26840.0723 - mae: 123.7170 - val_loss: 26767.0566 - val_mae: 124.4294\n",
      "Epoch 430/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 26826.3418 - mae: 123.7000 - val_loss: 26415.1719 - val_mae: 124.0461\n",
      "Epoch 431/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 26826.3418 - mae: 123.7000 - val_loss: 26415.1719 - val_mae: 124.0461\n",
      "Epoch 431/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 27063.7383 - mae: 123.8851 - val_loss: 27406.2812 - val_mae: 126.5867\n",
      "Epoch 432/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 27063.7383 - mae: 123.8851 - val_loss: 27406.2812 - val_mae: 126.5867\n",
      "Epoch 432/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 26632.0117 - mae: 123.0471 - val_loss: 27899.9258 - val_mae: 126.5727\n",
      "Epoch 433/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 26632.0117 - mae: 123.0471 - val_loss: 27899.9258 - val_mae: 126.5727\n",
      "Epoch 433/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26840.9453 - mae: 123.6439 - val_loss: 26088.8242 - val_mae: 121.9873\n",
      "Epoch 434/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26840.9453 - mae: 123.6439 - val_loss: 26088.8242 - val_mae: 121.9873\n",
      "Epoch 434/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 26784.7969 - mae: 123.4849 - val_loss: 27576.0352 - val_mae: 126.7023\n",
      "Epoch 435/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 26784.7969 - mae: 123.4849 - val_loss: 27576.0352 - val_mae: 126.7023\n",
      "Epoch 435/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 26950.2422 - mae: 123.6429 - val_loss: 27097.3359 - val_mae: 124.5105\n",
      "Epoch 436/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 26950.2422 - mae: 123.6429 - val_loss: 27097.3359 - val_mae: 124.5105\n",
      "Epoch 436/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 26744.2109 - mae: 123.3483 - val_loss: 26588.9102 - val_mae: 124.0111\n",
      "Epoch 437/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 26744.2109 - mae: 123.3483 - val_loss: 26588.9102 - val_mae: 124.0111\n",
      "Epoch 437/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26747.7559 - mae: 123.4952 - val_loss: 30991.2949 - val_mae: 134.6914\n",
      "Epoch 438/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26747.7559 - mae: 123.4952 - val_loss: 30991.2949 - val_mae: 134.6914\n",
      "Epoch 438/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 26928.5098 - mae: 123.9004 - val_loss: 27423.7461 - val_mae: 125.2802\n",
      "Epoch 439/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 26928.5098 - mae: 123.9004 - val_loss: 27423.7461 - val_mae: 125.2802\n",
      "Epoch 439/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 26727.2168 - mae: 123.5016 - val_loss: 27161.4648 - val_mae: 125.0143\n",
      "Epoch 440/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 26727.2168 - mae: 123.5016 - val_loss: 27161.4648 - val_mae: 125.0143\n",
      "Epoch 440/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 26536.8105 - mae: 122.9464 - val_loss: 26472.4043 - val_mae: 123.1231\n",
      "Epoch 441/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 26536.8105 - mae: 122.9464 - val_loss: 26472.4043 - val_mae: 123.1231\n",
      "Epoch 441/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 26586.1699 - mae: 123.3069 - val_loss: 27561.3418 - val_mae: 125.0913\n",
      "Epoch 442/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 26586.1699 - mae: 123.3069 - val_loss: 27561.3418 - val_mae: 125.0913\n",
      "Epoch 442/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 26687.5098 - mae: 123.3037 - val_loss: 26990.0254 - val_mae: 124.7550\n",
      "Epoch 443/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 26687.5098 - mae: 123.3037 - val_loss: 26990.0254 - val_mae: 124.7550\n",
      "Epoch 443/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 26703.2461 - mae: 123.3128 - val_loss: 26130.4980 - val_mae: 122.3132\n",
      "Epoch 444/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 26703.2461 - mae: 123.3128 - val_loss: 26130.4980 - val_mae: 122.3132\n",
      "Epoch 444/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 26543.8945 - mae: 123.0188 - val_loss: 26530.4199 - val_mae: 123.4241\n",
      "Epoch 445/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 26543.8945 - mae: 123.0188 - val_loss: 26530.4199 - val_mae: 123.4241\n",
      "Epoch 445/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 26606.9219 - mae: 123.4340 - val_loss: 27401.1055 - val_mae: 126.6320\n",
      "Epoch 446/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 26606.9219 - mae: 123.4340 - val_loss: 27401.1055 - val_mae: 126.6320\n",
      "Epoch 446/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 26563.6875 - mae: 123.0733 - val_loss: 26896.2090 - val_mae: 124.6945\n",
      "Epoch 447/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 26563.6875 - mae: 123.0733 - val_loss: 26896.2090 - val_mae: 124.6945\n",
      "Epoch 447/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26486.7891 - mae: 122.7100 - val_loss: 26201.3359 - val_mae: 123.6776\n",
      "Epoch 448/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26486.7891 - mae: 122.7100 - val_loss: 26201.3359 - val_mae: 123.6776\n",
      "Epoch 448/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26507.8770 - mae: 122.9643 - val_loss: 27172.7949 - val_mae: 124.6978\n",
      "Epoch 449/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26507.8770 - mae: 122.9643 - val_loss: 27172.7949 - val_mae: 124.6978\n",
      "Epoch 449/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26658.0137 - mae: 123.1817 - val_loss: 25938.0957 - val_mae: 121.3447\n",
      "Epoch 450/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26658.0137 - mae: 123.1817 - val_loss: 25938.0957 - val_mae: 121.3447\n",
      "Epoch 450/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 26683.7383 - mae: 123.4248 - val_loss: 28922.6074 - val_mae: 130.9375\n",
      "Epoch 451/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 26683.7383 - mae: 123.4248 - val_loss: 28922.6074 - val_mae: 130.9375\n",
      "Epoch 451/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 26364.4453 - mae: 122.5830 - val_loss: 27568.1484 - val_mae: 126.6941\n",
      "Epoch 452/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 26364.4453 - mae: 122.5830 - val_loss: 27568.1484 - val_mae: 126.6941\n",
      "Epoch 452/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 26517.3691 - mae: 123.0963 - val_loss: 26852.0566 - val_mae: 124.6879\n",
      "Epoch 453/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 26517.3691 - mae: 123.0963 - val_loss: 26852.0566 - val_mae: 124.6879\n",
      "Epoch 453/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26778.8398 - mae: 123.7150 - val_loss: 26500.8457 - val_mae: 123.2271\n",
      "Epoch 454/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26778.8398 - mae: 123.7150 - val_loss: 26500.8457 - val_mae: 123.2271\n",
      "Epoch 454/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 26415.5762 - mae: 122.8648 - val_loss: 28919.9336 - val_mae: 130.4107\n",
      "Epoch 455/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 26415.5762 - mae: 122.8648 - val_loss: 28919.9336 - val_mae: 130.4107\n",
      "Epoch 455/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 26478.2871 - mae: 122.8739 - val_loss: 26538.9023 - val_mae: 123.4970\n",
      "Epoch 456/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 26478.2871 - mae: 122.8739 - val_loss: 26538.9023 - val_mae: 123.4970\n",
      "Epoch 456/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 26470.1895 - mae: 122.8317 - val_loss: 27963.1406 - val_mae: 126.6784\n",
      "Epoch 457/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 26470.1895 - mae: 122.8317 - val_loss: 27963.1406 - val_mae: 126.6784\n",
      "Epoch 457/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26543.1016 - mae: 123.1145 - val_loss: 26794.7207 - val_mae: 123.5035\n",
      "Epoch 458/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26543.1016 - mae: 123.1145 - val_loss: 26794.7207 - val_mae: 123.5035\n",
      "Epoch 458/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 26402.9766 - mae: 122.4807 - val_loss: 25656.7812 - val_mae: 121.3656\n",
      "Epoch 459/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 26402.9766 - mae: 122.4807 - val_loss: 25656.7812 - val_mae: 121.3656\n",
      "Epoch 459/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 26440.9062 - mae: 122.8483 - val_loss: 27841.2129 - val_mae: 126.1041\n",
      "Epoch 460/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 26440.9062 - mae: 122.8483 - val_loss: 27841.2129 - val_mae: 126.1041\n",
      "Epoch 460/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 26449.4473 - mae: 122.6708 - val_loss: 27396.1562 - val_mae: 125.9131\n",
      "Epoch 461/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 26449.4473 - mae: 122.6708 - val_loss: 27396.1562 - val_mae: 125.9131\n",
      "Epoch 461/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26525.0195 - mae: 123.1760 - val_loss: 26063.0469 - val_mae: 121.9165\n",
      "Epoch 462/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26525.0195 - mae: 123.1760 - val_loss: 26063.0469 - val_mae: 121.9165\n",
      "Epoch 462/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26548.1289 - mae: 122.9445 - val_loss: 28162.5195 - val_mae: 127.9210\n",
      "Epoch 463/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26548.1289 - mae: 122.9445 - val_loss: 28162.5195 - val_mae: 127.9210\n",
      "Epoch 463/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 26361.3301 - mae: 122.3598 - val_loss: 25397.9395 - val_mae: 120.5510\n",
      "Epoch 464/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 26361.3301 - mae: 122.3598 - val_loss: 25397.9395 - val_mae: 120.5510\n",
      "Epoch 464/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 26573.6836 - mae: 123.1632 - val_loss: 27411.7246 - val_mae: 126.8362\n",
      "Epoch 465/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 26573.6836 - mae: 123.1632 - val_loss: 27411.7246 - val_mae: 126.8362\n",
      "Epoch 465/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - loss: 26359.5000 - mae: 122.3759 - val_loss: 28110.7266 - val_mae: 127.0445\n",
      "Epoch 466/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - loss: 26359.5000 - mae: 122.3759 - val_loss: 28110.7266 - val_mae: 127.0445\n",
      "Epoch 466/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 26191.5293 - mae: 122.1263 - val_loss: 28326.3281 - val_mae: 128.2045\n",
      "Epoch 467/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 26191.5293 - mae: 122.1263 - val_loss: 28326.3281 - val_mae: 128.2045\n",
      "Epoch 467/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26470.7227 - mae: 122.8474 - val_loss: 27035.3398 - val_mae: 123.8899\n",
      "Epoch 468/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26470.7227 - mae: 122.8474 - val_loss: 27035.3398 - val_mae: 123.8899\n",
      "Epoch 468/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26444.7734 - mae: 122.7254 - val_loss: 26348.5723 - val_mae: 123.3811\n",
      "Epoch 469/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 26444.7734 - mae: 122.7254 - val_loss: 26348.5723 - val_mae: 123.3811\n",
      "Epoch 469/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 26341.9883 - mae: 122.3794 - val_loss: 26372.8340 - val_mae: 123.6852\n",
      "Epoch 470/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 26341.9883 - mae: 122.3794 - val_loss: 26372.8340 - val_mae: 123.6852\n",
      "Epoch 470/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 26450.0352 - mae: 122.6672 - val_loss: 27782.9922 - val_mae: 127.4572\n",
      "Epoch 471/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 26450.0352 - mae: 122.6672 - val_loss: 27782.9922 - val_mae: 127.4572\n",
      "Epoch 471/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26201.8457 - mae: 121.9451 - val_loss: 25611.3906 - val_mae: 120.7970\n",
      "Epoch 472/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 26201.8457 - mae: 121.9451 - val_loss: 25611.3906 - val_mae: 120.7970\n",
      "Epoch 472/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 26259.8633 - mae: 122.0260 - val_loss: 25352.1289 - val_mae: 120.2627\n",
      "Epoch 473/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 26259.8633 - mae: 122.0260 - val_loss: 25352.1289 - val_mae: 120.2627\n",
      "Epoch 473/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 26371.4766 - mae: 122.4466 - val_loss: 27633.4922 - val_mae: 127.1573\n",
      "Epoch 474/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 26371.4766 - mae: 122.4466 - val_loss: 27633.4922 - val_mae: 127.1573\n",
      "Epoch 474/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 26325.5742 - mae: 122.1790 - val_loss: 26880.2520 - val_mae: 124.5065\n",
      "Epoch 475/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 26325.5742 - mae: 122.1790 - val_loss: 26880.2520 - val_mae: 124.5065\n",
      "Epoch 475/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 26276.2637 - mae: 122.4624 - val_loss: 26032.6660 - val_mae: 122.0557\n",
      "Epoch 476/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 26276.2637 - mae: 122.4624 - val_loss: 26032.6660 - val_mae: 122.0557\n",
      "Epoch 476/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 26080.9355 - mae: 121.7426 - val_loss: 26064.4902 - val_mae: 122.4084\n",
      "Epoch 477/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 26080.9355 - mae: 121.7426 - val_loss: 26064.4902 - val_mae: 122.4084\n",
      "Epoch 477/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26248.1367 - mae: 122.2290 - val_loss: 26192.0293 - val_mae: 122.9837\n",
      "Epoch 478/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26248.1367 - mae: 122.2290 - val_loss: 26192.0293 - val_mae: 122.9837\n",
      "Epoch 478/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 26244.7617 - mae: 122.0993 - val_loss: 27328.0879 - val_mae: 125.4172\n",
      "Epoch 479/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 26244.7617 - mae: 122.0993 - val_loss: 27328.0879 - val_mae: 125.4172\n",
      "Epoch 479/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 26132.5312 - mae: 121.9802 - val_loss: 29293.5957 - val_mae: 130.6845\n",
      "Epoch 480/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 26132.5312 - mae: 121.9802 - val_loss: 29293.5957 - val_mae: 130.6845\n",
      "Epoch 480/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 26006.9863 - mae: 121.6806 - val_loss: 26099.4844 - val_mae: 121.5689\n",
      "Epoch 481/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 26006.9863 - mae: 121.6806 - val_loss: 26099.4844 - val_mae: 121.5689\n",
      "Epoch 481/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26251.8789 - mae: 122.0196 - val_loss: 26434.2285 - val_mae: 123.2465\n",
      "Epoch 482/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 26251.8789 - mae: 122.0196 - val_loss: 26434.2285 - val_mae: 123.2465\n",
      "Epoch 482/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 26154.1719 - mae: 121.9021 - val_loss: 25948.4531 - val_mae: 122.5623\n",
      "Epoch 483/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 26154.1719 - mae: 121.9021 - val_loss: 25948.4531 - val_mae: 122.5623\n",
      "Epoch 483/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 25968.9277 - mae: 121.5645 - val_loss: 30960.8320 - val_mae: 133.8820\n",
      "Epoch 484/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 25968.9277 - mae: 121.5645 - val_loss: 30960.8320 - val_mae: 133.8820\n",
      "Epoch 484/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26112.2305 - mae: 121.9117 - val_loss: 25663.5117 - val_mae: 120.9678\n",
      "Epoch 485/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 26112.2305 - mae: 121.9117 - val_loss: 25663.5117 - val_mae: 120.9678\n",
      "Epoch 485/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 26104.4102 - mae: 121.9295 - val_loss: 26121.5176 - val_mae: 122.9066\n",
      "Epoch 486/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 26104.4102 - mae: 121.9295 - val_loss: 26121.5176 - val_mae: 122.9066\n",
      "Epoch 486/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 26041.4883 - mae: 121.8343 - val_loss: 26547.3301 - val_mae: 123.4662\n",
      "Epoch 487/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 26041.4883 - mae: 121.8343 - val_loss: 26547.3301 - val_mae: 123.4662\n",
      "Epoch 487/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25993.4785 - mae: 121.4660 - val_loss: 25723.0371 - val_mae: 121.5656\n",
      "Epoch 488/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25993.4785 - mae: 121.4660 - val_loss: 25723.0371 - val_mae: 121.5656\n",
      "Epoch 488/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 25745.9375 - mae: 121.0258 - val_loss: 26509.7598 - val_mae: 122.9636\n",
      "Epoch 489/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 25745.9375 - mae: 121.0258 - val_loss: 26509.7598 - val_mae: 122.9636\n",
      "Epoch 489/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 26055.4082 - mae: 121.6446 - val_loss: 25262.5781 - val_mae: 119.7660\n",
      "Epoch 490/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 26055.4082 - mae: 121.6446 - val_loss: 25262.5781 - val_mae: 119.7660\n",
      "Epoch 490/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 26010.2812 - mae: 121.6568 - val_loss: 25471.6777 - val_mae: 120.8735\n",
      "Epoch 491/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 26010.2812 - mae: 121.6568 - val_loss: 25471.6777 - val_mae: 120.8735\n",
      "Epoch 491/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - loss: 26000.5664 - mae: 121.6606 - val_loss: 25652.4004 - val_mae: 121.0204\n",
      "Epoch 492/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - loss: 26000.5664 - mae: 121.6606 - val_loss: 25652.4004 - val_mae: 121.0204\n",
      "Epoch 492/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 25818.0898 - mae: 121.0261 - val_loss: 26333.7168 - val_mae: 123.2949\n",
      "Epoch 493/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 25818.0898 - mae: 121.0261 - val_loss: 26333.7168 - val_mae: 123.2949\n",
      "Epoch 493/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 25754.7617 - mae: 120.8659 - val_loss: 29747.7031 - val_mae: 132.7722\n",
      "Epoch 494/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 25754.7617 - mae: 120.8659 - val_loss: 29747.7031 - val_mae: 132.7722\n",
      "Epoch 494/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 25664.9492 - mae: 120.6180 - val_loss: 25004.9922 - val_mae: 119.3885\n",
      "Epoch 495/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 25664.9492 - mae: 120.6180 - val_loss: 25004.9922 - val_mae: 119.3885\n",
      "Epoch 495/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 25723.1836 - mae: 120.7891 - val_loss: 30827.9043 - val_mae: 133.0438\n",
      "Epoch 496/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 25723.1836 - mae: 120.7891 - val_loss: 30827.9043 - val_mae: 133.0438\n",
      "Epoch 496/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 25736.4883 - mae: 121.0777 - val_loss: 26394.8730 - val_mae: 122.6313\n",
      "Epoch 497/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 25736.4883 - mae: 121.0777 - val_loss: 26394.8730 - val_mae: 122.6313\n",
      "Epoch 497/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 25660.7129 - mae: 120.8562 - val_loss: 26030.4297 - val_mae: 121.9548\n",
      "Epoch 498/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 25660.7129 - mae: 120.8562 - val_loss: 26030.4297 - val_mae: 121.9548\n",
      "Epoch 498/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 25921.9199 - mae: 121.4349 - val_loss: 25830.5977 - val_mae: 121.7035\n",
      "Epoch 499/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 25921.9199 - mae: 121.4349 - val_loss: 25830.5977 - val_mae: 121.7035\n",
      "Epoch 499/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25650.6230 - mae: 120.7454 - val_loss: 27187.0371 - val_mae: 125.1466\n",
      "Epoch 500/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25650.6230 - mae: 120.7454 - val_loss: 27187.0371 - val_mae: 125.1466\n",
      "Epoch 500/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 25732.3086 - mae: 120.7373 - val_loss: 25109.6543 - val_mae: 119.8924\n",
      "Epoch 501/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 25732.3086 - mae: 120.7373 - val_loss: 25109.6543 - val_mae: 119.8924\n",
      "Epoch 501/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25575.3145 - mae: 120.3166 - val_loss: 25594.2266 - val_mae: 120.7368\n",
      "Epoch 502/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25575.3145 - mae: 120.3166 - val_loss: 25594.2266 - val_mae: 120.7368\n",
      "Epoch 502/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - loss: 25672.8770 - mae: 120.5976 - val_loss: 26119.6836 - val_mae: 122.3057\n",
      "Epoch 503/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - loss: 25672.8770 - mae: 120.5976 - val_loss: 26119.6836 - val_mae: 122.3057\n",
      "Epoch 503/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 25742.7871 - mae: 120.9238 - val_loss: 25561.3984 - val_mae: 121.0625\n",
      "Epoch 504/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 25742.7871 - mae: 120.9238 - val_loss: 25561.3984 - val_mae: 121.0625\n",
      "Epoch 504/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 25555.0566 - mae: 120.2611 - val_loss: 26684.4160 - val_mae: 124.0296\n",
      "Epoch 505/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 25555.0566 - mae: 120.2611 - val_loss: 26684.4160 - val_mae: 124.0296\n",
      "Epoch 505/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 25672.9199 - mae: 120.9203 - val_loss: 27008.3145 - val_mae: 124.5949\n",
      "Epoch 506/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 25672.9199 - mae: 120.9203 - val_loss: 27008.3145 - val_mae: 124.5949\n",
      "Epoch 506/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 25552.1582 - mae: 120.4469 - val_loss: 25051.5605 - val_mae: 119.6363\n",
      "Epoch 507/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 25552.1582 - mae: 120.4469 - val_loss: 25051.5605 - val_mae: 119.6363\n",
      "Epoch 507/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 25669.3809 - mae: 120.6259 - val_loss: 26182.7207 - val_mae: 122.6581\n",
      "Epoch 508/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 25669.3809 - mae: 120.6259 - val_loss: 26182.7207 - val_mae: 122.6581\n",
      "Epoch 508/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 25668.5996 - mae: 120.5093 - val_loss: 27958.9160 - val_mae: 128.0853\n",
      "Epoch 509/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 25668.5996 - mae: 120.5093 - val_loss: 27958.9160 - val_mae: 128.0853\n",
      "Epoch 509/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 25570.9824 - mae: 120.1311 - val_loss: 27610.9434 - val_mae: 126.4240\n",
      "Epoch 510/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 25570.9824 - mae: 120.1311 - val_loss: 27610.9434 - val_mae: 126.4240\n",
      "Epoch 510/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25657.5469 - mae: 120.7062 - val_loss: 25252.6738 - val_mae: 120.1982\n",
      "Epoch 511/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25657.5469 - mae: 120.7062 - val_loss: 25252.6738 - val_mae: 120.1982\n",
      "Epoch 511/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25575.8125 - mae: 120.3382 - val_loss: 28179.5625 - val_mae: 129.6437\n",
      "Epoch 512/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25575.8125 - mae: 120.3382 - val_loss: 28179.5625 - val_mae: 129.6437\n",
      "Epoch 512/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25563.0918 - mae: 120.2391 - val_loss: 25543.6758 - val_mae: 120.9127\n",
      "Epoch 513/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25563.0918 - mae: 120.2391 - val_loss: 25543.6758 - val_mae: 120.9127\n",
      "Epoch 513/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 25690.9688 - mae: 120.8180 - val_loss: 27875.6621 - val_mae: 125.7581\n",
      "Epoch 514/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 25690.9688 - mae: 120.8180 - val_loss: 27875.6621 - val_mae: 125.7581\n",
      "Epoch 514/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 25690.9746 - mae: 120.7142 - val_loss: 25419.8418 - val_mae: 119.8713\n",
      "Epoch 515/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 25690.9746 - mae: 120.7142 - val_loss: 25419.8418 - val_mae: 119.8713\n",
      "Epoch 515/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 25570.7090 - mae: 120.5348 - val_loss: 25001.9980 - val_mae: 119.6780\n",
      "Epoch 516/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 25570.7090 - mae: 120.5348 - val_loss: 25001.9980 - val_mae: 119.6780\n",
      "Epoch 516/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 25438.9766 - mae: 120.0126 - val_loss: 25875.1172 - val_mae: 121.8130\n",
      "Epoch 517/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 25438.9766 - mae: 120.0126 - val_loss: 25875.1172 - val_mae: 121.8130\n",
      "Epoch 517/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 25461.7520 - mae: 120.1140 - val_loss: 26975.9082 - val_mae: 124.0640\n",
      "Epoch 518/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 25461.7520 - mae: 120.1140 - val_loss: 26975.9082 - val_mae: 124.0640\n",
      "Epoch 518/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25616.3438 - mae: 120.7287 - val_loss: 24717.4453 - val_mae: 118.4795\n",
      "Epoch 519/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25616.3438 - mae: 120.7287 - val_loss: 24717.4453 - val_mae: 118.4795\n",
      "Epoch 519/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 25431.1602 - mae: 119.7643 - val_loss: 24710.3750 - val_mae: 119.9294\n",
      "Epoch 520/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 25431.1602 - mae: 119.7643 - val_loss: 24710.3750 - val_mae: 119.9294\n",
      "Epoch 520/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 25492.8906 - mae: 120.1217 - val_loss: 26510.8535 - val_mae: 123.5590\n",
      "Epoch 521/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 25492.8906 - mae: 120.1217 - val_loss: 26510.8535 - val_mae: 123.5590\n",
      "Epoch 521/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25353.7070 - mae: 120.0004 - val_loss: 26399.8789 - val_mae: 123.3978\n",
      "Epoch 522/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25353.7070 - mae: 120.0004 - val_loss: 26399.8789 - val_mae: 123.3978\n",
      "Epoch 522/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 25242.7363 - mae: 119.7464 - val_loss: 24994.0703 - val_mae: 119.3819\n",
      "Epoch 523/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 25242.7363 - mae: 119.7464 - val_loss: 24994.0703 - val_mae: 119.3819\n",
      "Epoch 523/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 25326.8945 - mae: 119.5734 - val_loss: 26971.4492 - val_mae: 124.6532\n",
      "Epoch 524/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 25326.8945 - mae: 119.5734 - val_loss: 26971.4492 - val_mae: 124.6532\n",
      "Epoch 524/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 25392.0488 - mae: 119.9660 - val_loss: 25807.7930 - val_mae: 122.3089\n",
      "Epoch 525/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 25392.0488 - mae: 119.9660 - val_loss: 25807.7930 - val_mae: 122.3089\n",
      "Epoch 525/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 25467.3105 - mae: 120.0877 - val_loss: 26277.5234 - val_mae: 123.1726\n",
      "Epoch 526/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 25467.3105 - mae: 120.0877 - val_loss: 26277.5234 - val_mae: 123.1726\n",
      "Epoch 526/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25482.3203 - mae: 120.3477 - val_loss: 25218.8438 - val_mae: 120.1576\n",
      "Epoch 527/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25482.3203 - mae: 120.3477 - val_loss: 25218.8438 - val_mae: 120.1576\n",
      "Epoch 527/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 25259.7871 - mae: 119.6369 - val_loss: 25509.3438 - val_mae: 121.0333\n",
      "Epoch 528/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 25259.7871 - mae: 119.6369 - val_loss: 25509.3438 - val_mae: 121.0333\n",
      "Epoch 528/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 25342.2266 - mae: 119.6832 - val_loss: 26504.8457 - val_mae: 122.8643\n",
      "Epoch 529/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 25342.2266 - mae: 119.6832 - val_loss: 26504.8457 - val_mae: 122.8643\n",
      "Epoch 529/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 25283.1621 - mae: 119.7159 - val_loss: 27834.3906 - val_mae: 129.3784\n",
      "Epoch 530/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 25283.1621 - mae: 119.7159 - val_loss: 27834.3906 - val_mae: 129.3784\n",
      "Epoch 530/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 25249.0254 - mae: 119.5314 - val_loss: 26713.8242 - val_mae: 124.2525\n",
      "Epoch 531/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 25249.0254 - mae: 119.5314 - val_loss: 26713.8242 - val_mae: 124.2525\n",
      "Epoch 531/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 25189.1719 - mae: 119.5178 - val_loss: 25820.2012 - val_mae: 121.7008\n",
      "Epoch 532/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 25189.1719 - mae: 119.5178 - val_loss: 25820.2012 - val_mae: 121.7008\n",
      "Epoch 532/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 25310.6855 - mae: 119.8597 - val_loss: 26433.2266 - val_mae: 124.0390\n",
      "Epoch 533/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 25310.6855 - mae: 119.8597 - val_loss: 26433.2266 - val_mae: 124.0390\n",
      "Epoch 533/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25452.4102 - mae: 119.9499 - val_loss: 26497.2012 - val_mae: 123.3423\n",
      "Epoch 534/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 25452.4102 - mae: 119.9499 - val_loss: 26497.2012 - val_mae: 123.3423\n",
      "Epoch 534/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 25371.4863 - mae: 120.0023 - val_loss: 25737.6523 - val_mae: 122.1410\n",
      "Epoch 535/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 25371.4863 - mae: 120.0023 - val_loss: 25737.6523 - val_mae: 122.1410\n",
      "Epoch 535/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24989.0781 - mae: 119.0590 - val_loss: 25198.6484 - val_mae: 119.8103\n",
      "Epoch 536/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24989.0781 - mae: 119.0590 - val_loss: 25198.6484 - val_mae: 119.8103\n",
      "Epoch 536/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 25089.0059 - mae: 119.2698 - val_loss: 25316.0215 - val_mae: 119.9246\n",
      "Epoch 537/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 25089.0059 - mae: 119.2698 - val_loss: 25316.0215 - val_mae: 119.9246\n",
      "Epoch 537/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25055.1914 - mae: 119.2025 - val_loss: 25353.2715 - val_mae: 120.9122\n",
      "Epoch 538/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25055.1914 - mae: 119.2025 - val_loss: 25353.2715 - val_mae: 120.9122\n",
      "Epoch 538/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 25224.2031 - mae: 119.5160 - val_loss: 26907.8945 - val_mae: 124.6683\n",
      "Epoch 539/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 25224.2031 - mae: 119.5160 - val_loss: 26907.8945 - val_mae: 124.6683\n",
      "Epoch 539/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 24924.0176 - mae: 118.8571 - val_loss: 24997.2500 - val_mae: 119.8341\n",
      "Epoch 540/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 24924.0176 - mae: 118.8571 - val_loss: 24997.2500 - val_mae: 119.8341\n",
      "Epoch 540/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25133.0371 - mae: 119.2568 - val_loss: 27263.7363 - val_mae: 124.7225\n",
      "Epoch 541/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 25133.0371 - mae: 119.2568 - val_loss: 27263.7363 - val_mae: 124.7225\n",
      "Epoch 541/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 24974.8926 - mae: 118.9110 - val_loss: 27868.3594 - val_mae: 125.9258\n",
      "Epoch 542/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 24974.8926 - mae: 118.9110 - val_loss: 27868.3594 - val_mae: 125.9258\n",
      "Epoch 542/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25104.8516 - mae: 119.3893 - val_loss: 28371.0234 - val_mae: 129.1195\n",
      "Epoch 543/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 25104.8516 - mae: 119.3893 - val_loss: 28371.0234 - val_mae: 129.1195\n",
      "Epoch 543/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 25004.6133 - mae: 119.0533 - val_loss: 25247.4277 - val_mae: 119.5074\n",
      "Epoch 544/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 25004.6133 - mae: 119.0533 - val_loss: 25247.4277 - val_mae: 119.5074\n",
      "Epoch 544/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 25230.0723 - mae: 119.5400 - val_loss: 28120.0527 - val_mae: 127.4991\n",
      "Epoch 545/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 25230.0723 - mae: 119.5400 - val_loss: 28120.0527 - val_mae: 127.4991\n",
      "Epoch 545/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 25279.3164 - mae: 119.7199 - val_loss: 25489.0645 - val_mae: 121.9399\n",
      "Epoch 546/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 25279.3164 - mae: 119.7199 - val_loss: 25489.0645 - val_mae: 121.9399\n",
      "Epoch 546/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 24884.1777 - mae: 118.6051 - val_loss: 25322.6270 - val_mae: 120.7866\n",
      "Epoch 547/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 24884.1777 - mae: 118.6051 - val_loss: 25322.6270 - val_mae: 120.7866\n",
      "Epoch 547/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 24963.7793 - mae: 118.7623 - val_loss: 24812.6602 - val_mae: 117.9578\n",
      "Epoch 548/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 24963.7793 - mae: 118.7623 - val_loss: 24812.6602 - val_mae: 117.9578\n",
      "Epoch 548/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 25122.4492 - mae: 119.4175 - val_loss: 25862.8789 - val_mae: 122.0256\n",
      "Epoch 549/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 25122.4492 - mae: 119.4175 - val_loss: 25862.8789 - val_mae: 122.0256\n",
      "Epoch 549/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 24872.9316 - mae: 118.6146 - val_loss: 25416.1152 - val_mae: 121.0877\n",
      "Epoch 550/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 24872.9316 - mae: 118.6146 - val_loss: 25416.1152 - val_mae: 121.0877\n",
      "Epoch 550/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24941.9473 - mae: 118.9414 - val_loss: 26334.2852 - val_mae: 121.7713\n",
      "Epoch 551/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24941.9473 - mae: 118.9414 - val_loss: 26334.2852 - val_mae: 121.7713\n",
      "Epoch 551/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 25078.0254 - mae: 119.0714 - val_loss: 25220.6055 - val_mae: 120.6980\n",
      "Epoch 552/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 25078.0254 - mae: 119.0714 - val_loss: 25220.6055 - val_mae: 120.6980\n",
      "Epoch 552/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24948.9414 - mae: 119.0441 - val_loss: 26705.8887 - val_mae: 124.2213\n",
      "Epoch 553/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24948.9414 - mae: 119.0441 - val_loss: 26705.8887 - val_mae: 124.2213\n",
      "Epoch 553/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 24960.7832 - mae: 118.8741 - val_loss: 26751.0820 - val_mae: 125.4691\n",
      "Epoch 554/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 24960.7832 - mae: 118.8741 - val_loss: 26751.0820 - val_mae: 125.4691\n",
      "Epoch 554/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 25027.8574 - mae: 119.0818 - val_loss: 26026.9922 - val_mae: 121.8993\n",
      "Epoch 555/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 25027.8574 - mae: 119.0818 - val_loss: 26026.9922 - val_mae: 121.8993\n",
      "Epoch 555/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 25009.7285 - mae: 119.1062 - val_loss: 25999.0176 - val_mae: 122.8373\n",
      "Epoch 556/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 25009.7285 - mae: 119.1062 - val_loss: 25999.0176 - val_mae: 122.8373\n",
      "Epoch 556/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 24975.1523 - mae: 119.0005 - val_loss: 27214.8789 - val_mae: 126.1466\n",
      "Epoch 557/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 24975.1523 - mae: 119.0005 - val_loss: 27214.8789 - val_mae: 126.1466\n",
      "Epoch 557/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 24829.2949 - mae: 118.4867 - val_loss: 25665.7148 - val_mae: 121.7011\n",
      "Epoch 558/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 24829.2949 - mae: 118.4867 - val_loss: 25665.7148 - val_mae: 121.7011\n",
      "Epoch 558/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 24855.3320 - mae: 118.9521 - val_loss: 25925.2559 - val_mae: 122.0857\n",
      "Epoch 559/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 24855.3320 - mae: 118.9521 - val_loss: 25925.2559 - val_mae: 122.0857\n",
      "Epoch 559/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24851.8047 - mae: 118.7900 - val_loss: 24606.1914 - val_mae: 118.1597\n",
      "Epoch 560/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24851.8047 - mae: 118.7900 - val_loss: 24606.1914 - val_mae: 118.1597\n",
      "Epoch 560/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 25073.3750 - mae: 119.2917 - val_loss: 25645.9395 - val_mae: 122.4490\n",
      "Epoch 561/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 25073.3750 - mae: 119.2917 - val_loss: 25645.9395 - val_mae: 122.4490\n",
      "Epoch 561/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24734.7500 - mae: 118.4880 - val_loss: 25207.0020 - val_mae: 120.3941\n",
      "Epoch 562/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24734.7500 - mae: 118.4880 - val_loss: 25207.0020 - val_mae: 120.3941\n",
      "Epoch 562/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 24770.2344 - mae: 118.8474 - val_loss: 24518.7090 - val_mae: 118.3251\n",
      "Epoch 563/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 24770.2344 - mae: 118.8474 - val_loss: 24518.7090 - val_mae: 118.3251\n",
      "Epoch 563/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24840.3203 - mae: 118.7209 - val_loss: 26909.4883 - val_mae: 124.7070\n",
      "Epoch 564/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24840.3203 - mae: 118.7209 - val_loss: 26909.4883 - val_mae: 124.7070\n",
      "Epoch 564/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 24954.8730 - mae: 119.0391 - val_loss: 27604.0000 - val_mae: 127.4095\n",
      "Epoch 565/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 24954.8730 - mae: 119.0391 - val_loss: 27604.0000 - val_mae: 127.4095\n",
      "Epoch 565/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 25026.0801 - mae: 119.0788 - val_loss: 24507.4961 - val_mae: 118.0470\n",
      "Epoch 566/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 25026.0801 - mae: 119.0788 - val_loss: 24507.4961 - val_mae: 118.0470\n",
      "Epoch 566/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 24837.8457 - mae: 118.5219 - val_loss: 25928.3223 - val_mae: 121.5849\n",
      "Epoch 567/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 24837.8457 - mae: 118.5219 - val_loss: 25928.3223 - val_mae: 121.5849\n",
      "Epoch 567/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 24657.8750 - mae: 118.2061 - val_loss: 27031.8984 - val_mae: 126.3315\n",
      "Epoch 568/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 24657.8750 - mae: 118.2061 - val_loss: 27031.8984 - val_mae: 126.3315\n",
      "Epoch 568/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 24794.2852 - mae: 118.5314 - val_loss: 25421.8945 - val_mae: 121.5826\n",
      "Epoch 569/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 24794.2852 - mae: 118.5314 - val_loss: 25421.8945 - val_mae: 121.5826\n",
      "Epoch 569/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 24900.9082 - mae: 118.7018 - val_loss: 24850.3145 - val_mae: 118.9808\n",
      "Epoch 570/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 24900.9082 - mae: 118.7018 - val_loss: 24850.3145 - val_mae: 118.9808\n",
      "Epoch 570/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 24763.5605 - mae: 118.4339 - val_loss: 30169.4414 - val_mae: 133.2763\n",
      "Epoch 571/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 24763.5605 - mae: 118.4339 - val_loss: 30169.4414 - val_mae: 133.2763\n",
      "Epoch 571/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 24751.3711 - mae: 118.3832 - val_loss: 24570.2129 - val_mae: 118.8268\n",
      "Epoch 572/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 24751.3711 - mae: 118.3832 - val_loss: 24570.2129 - val_mae: 118.8268\n",
      "Epoch 572/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 24746.0820 - mae: 118.6760 - val_loss: 26319.2598 - val_mae: 122.5638\n",
      "Epoch 573/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 24746.0820 - mae: 118.6760 - val_loss: 26319.2598 - val_mae: 122.5638\n",
      "Epoch 573/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24922.7363 - mae: 118.7946 - val_loss: 27066.1699 - val_mae: 125.9132\n",
      "Epoch 574/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24922.7363 - mae: 118.7946 - val_loss: 27066.1699 - val_mae: 125.9132\n",
      "Epoch 574/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 24821.5605 - mae: 118.6601 - val_loss: 25400.0059 - val_mae: 120.5756\n",
      "Epoch 575/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 24821.5605 - mae: 118.6601 - val_loss: 25400.0059 - val_mae: 120.5756\n",
      "Epoch 575/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 24608.0977 - mae: 118.2313 - val_loss: 25426.2344 - val_mae: 120.2512\n",
      "Epoch 576/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 24608.0977 - mae: 118.2313 - val_loss: 25426.2344 - val_mae: 120.2512\n",
      "Epoch 576/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24667.3691 - mae: 118.2901 - val_loss: 25890.8789 - val_mae: 122.7662\n",
      "Epoch 577/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24667.3691 - mae: 118.2901 - val_loss: 25890.8789 - val_mae: 122.7662\n",
      "Epoch 577/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24750.2832 - mae: 118.5455 - val_loss: 25657.6875 - val_mae: 119.7672\n",
      "Epoch 578/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24750.2832 - mae: 118.5455 - val_loss: 25657.6875 - val_mae: 119.7672\n",
      "Epoch 578/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 24777.5957 - mae: 118.4652 - val_loss: 24150.0605 - val_mae: 116.3149\n",
      "Epoch 579/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 24777.5957 - mae: 118.4652 - val_loss: 24150.0605 - val_mae: 116.3149\n",
      "Epoch 579/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 24523.1895 - mae: 118.0848 - val_loss: 25625.5566 - val_mae: 121.4429\n",
      "Epoch 580/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 24523.1895 - mae: 118.0848 - val_loss: 25625.5566 - val_mae: 121.4429\n",
      "Epoch 580/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 24484.0703 - mae: 117.8692 - val_loss: 24755.5469 - val_mae: 118.6553\n",
      "Epoch 581/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 24484.0703 - mae: 117.8692 - val_loss: 24755.5469 - val_mae: 118.6553\n",
      "Epoch 581/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - loss: 24809.4453 - mae: 118.7656 - val_loss: 28159.9082 - val_mae: 128.1784\n",
      "Epoch 582/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - loss: 24809.4453 - mae: 118.7656 - val_loss: 28159.9082 - val_mae: 128.1784\n",
      "Epoch 582/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 24620.5449 - mae: 118.1931 - val_loss: 25197.0469 - val_mae: 119.2712\n",
      "Epoch 583/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 24620.5449 - mae: 118.1931 - val_loss: 25197.0469 - val_mae: 119.2712\n",
      "Epoch 583/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24508.9277 - mae: 117.8392 - val_loss: 27587.2305 - val_mae: 127.9787\n",
      "Epoch 584/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24508.9277 - mae: 117.8392 - val_loss: 27587.2305 - val_mae: 127.9787\n",
      "Epoch 584/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 24569.7090 - mae: 118.2971 - val_loss: 24350.2324 - val_mae: 117.9269\n",
      "Epoch 585/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 24569.7090 - mae: 118.2971 - val_loss: 24350.2324 - val_mae: 117.9269\n",
      "Epoch 585/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 24393.4180 - mae: 117.7403 - val_loss: 26492.6582 - val_mae: 123.0502\n",
      "Epoch 586/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 24393.4180 - mae: 117.7403 - val_loss: 26492.6582 - val_mae: 123.0502\n",
      "Epoch 586/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 24643.1465 - mae: 118.0834 - val_loss: 24977.4961 - val_mae: 119.5463\n",
      "Epoch 587/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 24643.1465 - mae: 118.0834 - val_loss: 24977.4961 - val_mae: 119.5463\n",
      "Epoch 587/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 24496.7949 - mae: 117.9096 - val_loss: 25741.1484 - val_mae: 120.8427\n",
      "Epoch 588/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 24496.7949 - mae: 117.9096 - val_loss: 25741.1484 - val_mae: 120.8427\n",
      "Epoch 588/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24601.3574 - mae: 118.3343 - val_loss: 24760.4238 - val_mae: 119.5612\n",
      "Epoch 589/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24601.3574 - mae: 118.3343 - val_loss: 24760.4238 - val_mae: 119.5612\n",
      "Epoch 589/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 24524.5078 - mae: 117.7421 - val_loss: 27385.7617 - val_mae: 125.7003\n",
      "Epoch 590/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 24524.5078 - mae: 117.7421 - val_loss: 27385.7617 - val_mae: 125.7003\n",
      "Epoch 590/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 24377.2539 - mae: 117.4412 - val_loss: 25813.3926 - val_mae: 122.2677\n",
      "Epoch 591/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 24377.2539 - mae: 117.4412 - val_loss: 25813.3926 - val_mae: 122.2677\n",
      "Epoch 591/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 24625.5547 - mae: 118.5153 - val_loss: 24081.2852 - val_mae: 116.5085\n",
      "Epoch 592/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 24625.5547 - mae: 118.5153 - val_loss: 24081.2852 - val_mae: 116.5085\n",
      "Epoch 592/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - loss: 24646.9551 - mae: 118.0287 - val_loss: 25042.3535 - val_mae: 119.8473\n",
      "Epoch 593/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - loss: 24646.9551 - mae: 118.0287 - val_loss: 25042.3535 - val_mae: 119.8473\n",
      "Epoch 593/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 24564.8691 - mae: 117.9786 - val_loss: 25204.5176 - val_mae: 120.9882\n",
      "Epoch 594/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 24564.8691 - mae: 117.9786 - val_loss: 25204.5176 - val_mae: 120.9882\n",
      "Epoch 594/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 24507.6738 - mae: 117.6847 - val_loss: 30032.3828 - val_mae: 130.2818\n",
      "Epoch 595/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 24507.6738 - mae: 117.6847 - val_loss: 30032.3828 - val_mae: 130.2818\n",
      "Epoch 595/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 24430.4980 - mae: 117.5726 - val_loss: 25187.7070 - val_mae: 119.7188\n",
      "Epoch 596/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 24430.4980 - mae: 117.5726 - val_loss: 25187.7070 - val_mae: 119.7188\n",
      "Epoch 596/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 24572.8633 - mae: 118.3942 - val_loss: 27357.3926 - val_mae: 126.4717\n",
      "Epoch 597/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24184.4902 - mae: 117.1435 - val_loss: 24712.0430 - val_mae: 118.2458\n",
      "Epoch 598/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24632.5156 - mae: 118.0769 - val_loss: 24245.7363 - val_mae: 117.6692\n",
      "Epoch 599/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 24411.0781 - mae: 117.8074 - val_loss: 24558.4355 - val_mae: 119.0384\n",
      "Epoch 600/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 24236.1172 - mae: 117.3183 - val_loss: 23622.4473 - val_mae: 115.4957\n",
      "Epoch 601/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 24502.1250 - mae: 118.0462 - val_loss: 24716.1914 - val_mae: 118.6598\n",
      "Epoch 602/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 24186.5762 - mae: 116.9272 - val_loss: 24058.4551 - val_mae: 116.9434\n",
      "Epoch 603/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 24247.9316 - mae: 117.3046 - val_loss: 25057.5020 - val_mae: 120.0159\n",
      "Epoch 604/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24514.8828 - mae: 117.9145 - val_loss: 25952.9688 - val_mae: 123.2183\n",
      "Epoch 605/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 24270.6191 - mae: 117.4630 - val_loss: 24521.8086 - val_mae: 118.6075\n",
      "Epoch 606/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 24319.5469 - mae: 117.2746 - val_loss: 25019.4922 - val_mae: 120.3126\n",
      "Epoch 607/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24532.5332 - mae: 117.8891 - val_loss: 25193.8027 - val_mae: 119.9461\n",
      "Epoch 608/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 24288.4805 - mae: 117.3806 - val_loss: 24704.5742 - val_mae: 119.7090\n",
      "Epoch 609/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 24243.6504 - mae: 117.1135 - val_loss: 25252.5664 - val_mae: 121.4058\n",
      "Epoch 610/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 24464.7480 - mae: 118.1090 - val_loss: 24242.6309 - val_mae: 118.1933\n",
      "Epoch 611/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24404.5703 - mae: 117.6992 - val_loss: 24311.5430 - val_mae: 118.4240\n",
      "Epoch 612/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 24190.5938 - mae: 117.3026 - val_loss: 26066.4141 - val_mae: 123.1833\n",
      "Epoch 613/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 24245.5137 - mae: 117.1793 - val_loss: 23271.9629 - val_mae: 115.0327\n",
      "Epoch 614/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 24358.1641 - mae: 117.7539 - val_loss: 24526.5078 - val_mae: 118.2149\n",
      "Epoch 615/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 24252.2129 - mae: 117.1691 - val_loss: 24102.9727 - val_mae: 117.0938\n",
      "Epoch 616/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 24324.4512 - mae: 117.5722 - val_loss: 24627.6289 - val_mae: 118.9394\n",
      "Epoch 617/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 24471.1211 - mae: 117.7794 - val_loss: 24268.2949 - val_mae: 117.9494\n",
      "Epoch 618/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24384.9570 - mae: 117.8301 - val_loss: 24610.7812 - val_mae: 118.6656\n",
      "Epoch 619/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 24340.6504 - mae: 117.6681 - val_loss: 26823.5859 - val_mae: 125.2599\n",
      "Epoch 620/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 24180.2715 - mae: 117.2218 - val_loss: 24500.9277 - val_mae: 118.6232\n",
      "Epoch 621/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24222.8633 - mae: 117.3050 - val_loss: 23445.6680 - val_mae: 115.4246\n",
      "Epoch 622/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 24403.3262 - mae: 117.7955 - val_loss: 23825.0840 - val_mae: 116.4021\n",
      "Epoch 623/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 24258.9531 - mae: 117.3401 - val_loss: 24548.4160 - val_mae: 118.2276\n",
      "Epoch 624/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 24240.0625 - mae: 117.2630 - val_loss: 25472.6602 - val_mae: 121.1073\n",
      "Epoch 625/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 24243.9043 - mae: 117.2401 - val_loss: 24874.4355 - val_mae: 119.5231\n",
      "Epoch 626/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 24229.7871 - mae: 117.3690 - val_loss: 23417.3496 - val_mae: 114.8468\n",
      "Epoch 627/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24051.2305 - mae: 117.0191 - val_loss: 25482.8926 - val_mae: 121.3335\n",
      "Epoch 628/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 24193.9883 - mae: 117.2593 - val_loss: 26530.8516 - val_mae: 124.0052\n",
      "Epoch 629/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 24141.7168 - mae: 117.0008 - val_loss: 23513.1719 - val_mae: 115.5574\n",
      "Epoch 630/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 24027.8926 - mae: 116.7382 - val_loss: 23523.9043 - val_mae: 115.8141\n",
      "Epoch 631/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 24195.0996 - mae: 117.2215 - val_loss: 25137.6816 - val_mae: 121.2169\n",
      "Epoch 632/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 24066.9141 - mae: 116.7266 - val_loss: 24224.3613 - val_mae: 118.0759\n",
      "Epoch 633/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 24182.7715 - mae: 117.1692 - val_loss: 24026.0918 - val_mae: 117.7078\n",
      "Epoch 634/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 24047.7871 - mae: 116.5551 - val_loss: 23410.9668 - val_mae: 115.7270\n",
      "Epoch 635/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 24000.5117 - mae: 116.7221 - val_loss: 24492.4453 - val_mae: 117.7492\n",
      "Epoch 636/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 24248.8867 - mae: 117.2171 - val_loss: 24028.6016 - val_mae: 117.3098\n",
      "Epoch 637/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - loss: 24007.6582 - mae: 116.5449 - val_loss: 23581.4297 - val_mae: 115.4622\n",
      "Epoch 638/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 24001.3828 - mae: 116.5536 - val_loss: 24800.6875 - val_mae: 119.2011\n",
      "Epoch 639/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 23971.7598 - mae: 116.7312 - val_loss: 24970.2129 - val_mae: 120.4410\n",
      "Epoch 640/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 23995.7031 - mae: 117.0069 - val_loss: 25294.5430 - val_mae: 120.3982\n",
      "Epoch 641/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 24078.3906 - mae: 116.8743 - val_loss: 26824.0293 - val_mae: 126.1487\n",
      "Epoch 642/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24030.6035 - mae: 116.7926 - val_loss: 23548.7402 - val_mae: 116.1005\n",
      "Epoch 643/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24162.4297 - mae: 117.2248 - val_loss: 24043.5410 - val_mae: 117.6354\n",
      "Epoch 644/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24031.5293 - mae: 116.7394 - val_loss: 25938.4980 - val_mae: 121.8333\n",
      "Epoch 645/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 24066.8496 - mae: 116.8000 - val_loss: 25164.7480 - val_mae: 120.2456\n",
      "Epoch 646/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 24101.1328 - mae: 116.9481 - val_loss: 25426.0059 - val_mae: 120.6007\n",
      "Epoch 647/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 23959.7852 - mae: 116.5635 - val_loss: 23752.4668 - val_mae: 116.0379\n",
      "Epoch 648/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 24113.7422 - mae: 117.0994 - val_loss: 27433.0723 - val_mae: 126.9544\n",
      "Epoch 649/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 23863.0703 - mae: 116.2035 - val_loss: 24626.7578 - val_mae: 118.3647\n",
      "Epoch 650/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24113.4355 - mae: 116.9913 - val_loss: 25007.9199 - val_mae: 119.8493\n",
      "Epoch 651/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 24021.7246 - mae: 116.7971 - val_loss: 25306.0840 - val_mae: 120.1177\n",
      "Epoch 652/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 24005.9785 - mae: 116.6403 - val_loss: 24786.5156 - val_mae: 118.5553\n",
      "Epoch 653/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24006.8965 - mae: 116.8187 - val_loss: 24355.2812 - val_mae: 118.4104\n",
      "Epoch 654/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 24086.8145 - mae: 116.8550 - val_loss: 23885.1855 - val_mae: 117.6112\n",
      "Epoch 655/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 24061.0820 - mae: 116.7335 - val_loss: 25056.1348 - val_mae: 120.3134\n",
      "Epoch 656/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 23846.0996 - mae: 116.2019 - val_loss: 23939.6191 - val_mae: 117.6550\n",
      "Epoch 657/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 24040.4551 - mae: 116.8800 - val_loss: 23960.3184 - val_mae: 117.3301\n",
      "Epoch 658/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 23994.2363 - mae: 116.5596 - val_loss: 24141.2715 - val_mae: 117.4042\n",
      "Epoch 659/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - loss: 23903.0586 - mae: 116.2775 - val_loss: 25448.6250 - val_mae: 121.5900\n",
      "Epoch 660/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 24010.7266 - mae: 116.6219 - val_loss: 24126.2246 - val_mae: 116.5723\n",
      "Epoch 661/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 23846.2480 - mae: 116.2820 - val_loss: 23883.3906 - val_mae: 117.3356\n",
      "Epoch 662/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 23787.5273 - mae: 115.8419 - val_loss: 23628.9199 - val_mae: 116.1164\n",
      "Epoch 663/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 23891.9609 - mae: 116.3656 - val_loss: 23681.8262 - val_mae: 115.6505\n",
      "Epoch 664/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 23712.1543 - mae: 115.8741 - val_loss: 23890.3145 - val_mae: 117.0024\n",
      "Epoch 665/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 23916.1230 - mae: 116.3070 - val_loss: 23156.5801 - val_mae: 114.3871\n",
      "Epoch 666/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 23775.3262 - mae: 116.0293 - val_loss: 23480.0156 - val_mae: 115.9375\n",
      "Epoch 667/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 23803.8477 - mae: 116.0316 - val_loss: 23748.9980 - val_mae: 116.3176\n",
      "Epoch 668/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 23870.0801 - mae: 116.4723 - val_loss: 24299.2266 - val_mae: 117.4412\n",
      "Epoch 669/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 23811.4961 - mae: 116.4016 - val_loss: 25527.7129 - val_mae: 121.3401\n",
      "Epoch 670/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - loss: 23815.6641 - mae: 116.2623 - val_loss: 23651.9629 - val_mae: 115.8654\n",
      "Epoch 671/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 23759.2969 - mae: 115.9611 - val_loss: 24720.9922 - val_mae: 119.7669\n",
      "Epoch 672/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 23784.4375 - mae: 116.0453 - val_loss: 23595.0039 - val_mae: 116.1470\n",
      "Epoch 673/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 23768.3594 - mae: 116.1504 - val_loss: 23605.5664 - val_mae: 116.5233\n",
      "Epoch 674/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 23781.0000 - mae: 116.0681 - val_loss: 24321.5000 - val_mae: 118.0621\n",
      "Epoch 675/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 23763.5273 - mae: 116.1306 - val_loss: 23573.2012 - val_mae: 115.9975\n",
      "Epoch 676/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 23657.9922 - mae: 115.7005 - val_loss: 23613.8691 - val_mae: 115.9784\n",
      "Epoch 677/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 23782.4707 - mae: 116.2792 - val_loss: 24411.2168 - val_mae: 119.2345\n",
      "Epoch 678/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 23628.9297 - mae: 115.7838 - val_loss: 23529.7734 - val_mae: 115.6935\n",
      "Epoch 679/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 23570.5508 - mae: 115.4791 - val_loss: 24798.4414 - val_mae: 120.6696\n",
      "Epoch 680/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 23560.2012 - mae: 115.4376 - val_loss: 26945.5879 - val_mae: 126.9277\n",
      "Epoch 681/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 23723.1777 - mae: 115.9579 - val_loss: 24651.8145 - val_mae: 119.8932\n",
      "Epoch 682/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 23524.1016 - mae: 115.3771 - val_loss: 24494.4062 - val_mae: 118.3346\n",
      "Epoch 683/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 23561.9316 - mae: 115.4690 - val_loss: 23605.3340 - val_mae: 115.8014\n",
      "Epoch 684/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 23606.2656 - mae: 115.6897 - val_loss: 23266.3789 - val_mae: 115.5419\n",
      "Epoch 685/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 23340.4785 - mae: 114.8196 - val_loss: 25286.8848 - val_mae: 121.1117\n",
      "Epoch 686/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 23394.2832 - mae: 115.2871 - val_loss: 23315.9980 - val_mae: 114.8065\n",
      "Epoch 687/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 23181.3770 - mae: 114.4255 - val_loss: 25598.7305 - val_mae: 122.5896\n",
      "Epoch 688/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 23178.3027 - mae: 114.3758 - val_loss: 23647.3965 - val_mae: 116.5350\n",
      "Epoch 689/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 23301.8105 - mae: 115.1231 - val_loss: 23746.3652 - val_mae: 117.0894\n",
      "Epoch 690/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 23151.2344 - mae: 114.4802 - val_loss: 24873.9316 - val_mae: 120.6273\n",
      "Epoch 691/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 23117.8613 - mae: 114.5953 - val_loss: 24550.2480 - val_mae: 118.8605\n",
      "Epoch 692/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 23296.0566 - mae: 114.9567 - val_loss: 25016.7539 - val_mae: 120.7921\n",
      "Epoch 693/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 22982.1523 - mae: 113.8119 - val_loss: 23008.9102 - val_mae: 114.5477\n",
      "Epoch 694/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 23085.4141 - mae: 114.3303 - val_loss: 22676.6602 - val_mae: 113.5034\n",
      "Epoch 695/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 22837.9980 - mae: 113.7430 - val_loss: 25939.7188 - val_mae: 122.5676\n",
      "Epoch 696/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 22962.5371 - mae: 113.9853 - val_loss: 25151.9434 - val_mae: 122.0224\n",
      "Epoch 697/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 22932.0918 - mae: 114.0024 - val_loss: 22683.7148 - val_mae: 112.3013\n",
      "Epoch 698/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 22874.9746 - mae: 113.7351 - val_loss: 24374.6445 - val_mae: 118.1890\n",
      "Epoch 699/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 22711.0781 - mae: 113.0935 - val_loss: 24039.2031 - val_mae: 118.3676\n",
      "Epoch 700/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 22825.7637 - mae: 113.7423 - val_loss: 24109.2129 - val_mae: 118.4679\n",
      "Epoch 701/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 22810.9414 - mae: 113.5975 - val_loss: 22880.3965 - val_mae: 113.7727\n",
      "Epoch 702/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 22744.9590 - mae: 113.4153 - val_loss: 22817.0547 - val_mae: 114.1703\n",
      "Epoch 703/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 22691.9922 - mae: 113.4636 - val_loss: 24951.3242 - val_mae: 120.5370\n",
      "Epoch 704/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - loss: 22655.4629 - mae: 113.0431 - val_loss: 23480.8496 - val_mae: 116.7574\n",
      "Epoch 705/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 22455.9023 - mae: 112.6726 - val_loss: 22431.6211 - val_mae: 112.5230\n",
      "Epoch 706/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 22787.6543 - mae: 113.3786 - val_loss: 22600.0371 - val_mae: 113.1197\n",
      "Epoch 707/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 22480.9180 - mae: 112.6374 - val_loss: 22479.4980 - val_mae: 113.1323\n",
      "Epoch 708/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 22501.8887 - mae: 112.6873 - val_loss: 23573.6719 - val_mae: 114.5719\n",
      "Epoch 709/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 22502.0703 - mae: 112.8235 - val_loss: 22650.1094 - val_mae: 113.8727\n",
      "Epoch 710/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 22585.2051 - mae: 113.1042 - val_loss: 22194.9980 - val_mae: 111.9135\n",
      "Epoch 711/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 22430.1289 - mae: 112.5864 - val_loss: 22605.8184 - val_mae: 113.1454\n",
      "Epoch 712/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 22422.2793 - mae: 112.5665 - val_loss: 22144.9062 - val_mae: 111.9697\n",
      "Epoch 713/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 22480.4824 - mae: 112.6316 - val_loss: 23008.6445 - val_mae: 114.4027\n",
      "Epoch 714/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 22485.2656 - mae: 112.7690 - val_loss: 22228.4199 - val_mae: 112.2848\n",
      "Epoch 715/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 22483.7500 - mae: 112.5824 - val_loss: 23091.9629 - val_mae: 114.3527\n",
      "Epoch 716/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 22328.3145 - mae: 112.2253 - val_loss: 22332.0000 - val_mae: 111.9677\n",
      "Epoch 717/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 22270.2930 - mae: 112.0304 - val_loss: 22648.7207 - val_mae: 113.7905\n",
      "Epoch 718/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 22471.7363 - mae: 112.8219 - val_loss: 22572.0859 - val_mae: 113.4053\n",
      "Epoch 719/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 22213.0449 - mae: 111.8817 - val_loss: 23868.0371 - val_mae: 116.3640\n",
      "Epoch 720/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 22315.6270 - mae: 112.2493 - val_loss: 22487.3652 - val_mae: 113.1956\n",
      "Epoch 721/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 22168.8164 - mae: 111.9460 - val_loss: 22965.9199 - val_mae: 114.6366\n",
      "Epoch 722/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 22418.5566 - mae: 112.5100 - val_loss: 22005.9082 - val_mae: 111.4700\n",
      "Epoch 723/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 22164.2090 - mae: 111.8350 - val_loss: 21706.7930 - val_mae: 110.2483\n",
      "Epoch 724/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 22296.4023 - mae: 112.4675 - val_loss: 22133.7285 - val_mae: 111.8917\n",
      "Epoch 725/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 22367.7480 - mae: 112.4764 - val_loss: 22449.4863 - val_mae: 113.0892\n",
      "Epoch 726/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 22238.4043 - mae: 112.2782 - val_loss: 23135.1016 - val_mae: 115.6319\n",
      "Epoch 727/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 22113.4180 - mae: 111.6873 - val_loss: 22156.2461 - val_mae: 112.0009\n",
      "Epoch 728/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 22092.1133 - mae: 111.9116 - val_loss: 28920.3438 - val_mae: 131.9530\n",
      "Epoch 729/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 22165.7461 - mae: 112.0709 - val_loss: 22115.5703 - val_mae: 110.9673\n",
      "Epoch 730/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 22222.0840 - mae: 112.2785 - val_loss: 24840.3379 - val_mae: 120.2860\n",
      "Epoch 731/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 21979.2656 - mae: 111.4658 - val_loss: 24101.7246 - val_mae: 116.2308\n",
      "Epoch 732/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 22190.9453 - mae: 111.9565 - val_loss: 23090.4355 - val_mae: 114.9332\n",
      "Epoch 733/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 22151.5488 - mae: 111.7360 - val_loss: 22786.8145 - val_mae: 113.3014\n",
      "Epoch 734/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 22035.7480 - mae: 111.5614 - val_loss: 22507.5996 - val_mae: 113.5353\n",
      "Epoch 735/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 22044.0410 - mae: 111.7383 - val_loss: 26379.5859 - val_mae: 124.1306\n",
      "Epoch 736/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 21940.7832 - mae: 111.1958 - val_loss: 22541.4297 - val_mae: 112.4978\n",
      "Epoch 737/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 21881.3770 - mae: 111.0232 - val_loss: 22400.6367 - val_mae: 112.6499\n",
      "Epoch 738/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - loss: 21982.2266 - mae: 111.5924 - val_loss: 22580.6270 - val_mae: 113.3351\n",
      "Epoch 739/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 21885.1562 - mae: 110.8923 - val_loss: 22408.6582 - val_mae: 112.3785\n",
      "Epoch 740/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 21947.7441 - mae: 111.1884 - val_loss: 22847.9004 - val_mae: 113.7987\n",
      "Epoch 741/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 21745.3809 - mae: 110.6573 - val_loss: 21652.0625 - val_mae: 110.9619\n",
      "Epoch 742/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 22063.6191 - mae: 111.8703 - val_loss: 21332.3105 - val_mae: 108.8551\n",
      "Epoch 743/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 21957.9922 - mae: 111.1204 - val_loss: 23517.8516 - val_mae: 116.5036\n",
      "Epoch 744/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 21641.6133 - mae: 110.5315 - val_loss: 22160.0527 - val_mae: 111.5292\n",
      "Epoch 745/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 21628.0586 - mae: 110.3618 - val_loss: 23093.5723 - val_mae: 114.5491\n",
      "Epoch 746/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 21719.4297 - mae: 110.6682 - val_loss: 21697.0254 - val_mae: 110.7904\n",
      "Epoch 747/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 21782.4355 - mae: 110.5395 - val_loss: 22587.7793 - val_mae: 112.0292\n",
      "Epoch 748/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 21746.2793 - mae: 110.7211 - val_loss: 22799.5703 - val_mae: 114.2575\n",
      "Epoch 749/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - loss: 21586.4531 - mae: 110.3561 - val_loss: 23219.9336 - val_mae: 114.6514\n",
      "Epoch 750/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 21584.7402 - mae: 110.3242 - val_loss: 22268.8750 - val_mae: 113.3298\n",
      "Epoch 751/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 21719.3906 - mae: 110.8695 - val_loss: 21799.5469 - val_mae: 111.2385\n",
      "Epoch 752/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 21559.5000 - mae: 110.1687 - val_loss: 22491.6738 - val_mae: 112.8093\n",
      "Epoch 753/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 21662.6426 - mae: 110.5549 - val_loss: 21889.9746 - val_mae: 110.8436\n",
      "Epoch 754/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 21588.6230 - mae: 110.3911 - val_loss: 24747.0684 - val_mae: 120.1253\n",
      "Epoch 755/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 21621.9238 - mae: 110.5639 - val_loss: 22576.1582 - val_mae: 114.5765\n",
      "Epoch 756/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 21551.7949 - mae: 110.2469 - val_loss: 21766.3359 - val_mae: 110.3384\n",
      "Epoch 757/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 21528.0273 - mae: 110.1058 - val_loss: 21395.1582 - val_mae: 109.9659\n",
      "Epoch 758/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 21388.1855 - mae: 109.6390 - val_loss: 21755.9512 - val_mae: 110.7347\n",
      "Epoch 759/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 21500.6289 - mae: 110.1437 - val_loss: 21703.8887 - val_mae: 110.7077\n",
      "Epoch 760/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - loss: 21329.6270 - mae: 109.7418 - val_loss: 21905.3047 - val_mae: 111.3144\n",
      "Epoch 761/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 21262.5254 - mae: 109.3879 - val_loss: 22255.9453 - val_mae: 112.7783\n",
      "Epoch 762/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 21400.0352 - mae: 109.8890 - val_loss: 21525.5234 - val_mae: 110.5286\n",
      "Epoch 763/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 21335.9883 - mae: 109.3928 - val_loss: 25021.5859 - val_mae: 119.8347\n",
      "Epoch 764/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 21279.7480 - mae: 109.5750 - val_loss: 21733.8809 - val_mae: 110.4665\n",
      "Epoch 765/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 21335.4023 - mae: 109.6534 - val_loss: 21322.2891 - val_mae: 109.0878\n",
      "Epoch 766/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 21386.5508 - mae: 109.6903 - val_loss: 24554.7695 - val_mae: 119.6185\n",
      "Epoch 767/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 21184.8887 - mae: 109.3494 - val_loss: 24902.7441 - val_mae: 120.9062\n",
      "Epoch 768/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 21199.8613 - mae: 109.3764 - val_loss: 21664.0352 - val_mae: 110.4701\n",
      "Epoch 769/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 21285.6836 - mae: 109.5705 - val_loss: 21392.7812 - val_mae: 109.5927\n",
      "Epoch 770/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 21128.8164 - mae: 109.1040 - val_loss: 21139.1582 - val_mae: 108.7381\n",
      "Epoch 771/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 21241.1973 - mae: 109.3144 - val_loss: 22212.7598 - val_mae: 112.8826\n",
      "Epoch 772/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 21231.2930 - mae: 109.2978 - val_loss: 21961.8457 - val_mae: 112.2271\n",
      "Epoch 773/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 21130.5703 - mae: 109.0302 - val_loss: 21783.7988 - val_mae: 111.0891\n",
      "Epoch 774/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 21204.4668 - mae: 109.0602 - val_loss: 21035.0371 - val_mae: 108.7226\n",
      "Epoch 775/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 21033.8633 - mae: 108.7757 - val_loss: 22634.0977 - val_mae: 113.8480\n",
      "Epoch 776/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 21117.1973 - mae: 108.8874 - val_loss: 21617.5293 - val_mae: 109.8175\n",
      "Epoch 777/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 21053.6777 - mae: 108.8457 - val_loss: 21172.8633 - val_mae: 108.7770\n",
      "Epoch 778/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 21123.2168 - mae: 109.1052 - val_loss: 22551.2539 - val_mae: 113.6372\n",
      "Epoch 779/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 21123.6133 - mae: 108.8694 - val_loss: 23099.4961 - val_mae: 114.6910\n",
      "Epoch 780/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 21046.2793 - mae: 108.7529 - val_loss: 21747.0176 - val_mae: 111.1893\n",
      "Epoch 781/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 21094.5137 - mae: 108.8837 - val_loss: 22240.7637 - val_mae: 112.1213\n",
      "Epoch 782/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 20785.7031 - mae: 108.0983 - val_loss: 21950.9824 - val_mae: 110.9267\n",
      "Epoch 783/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - loss: 20942.1211 - mae: 108.4814 - val_loss: 22139.3945 - val_mae: 112.7682\n",
      "Epoch 784/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 20910.7910 - mae: 108.2155 - val_loss: 20703.4688 - val_mae: 107.7740\n",
      "Epoch 785/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 20782.1641 - mae: 108.1230 - val_loss: 20715.7715 - val_mae: 107.5960\n",
      "Epoch 786/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 20910.1367 - mae: 108.6435 - val_loss: 20860.2793 - val_mae: 107.5027\n",
      "Epoch 787/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 20886.8418 - mae: 108.4163 - val_loss: 21883.5801 - val_mae: 112.1139\n",
      "Epoch 788/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 20858.5195 - mae: 108.3163 - val_loss: 20925.4316 - val_mae: 109.1104\n",
      "Epoch 789/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 20757.4688 - mae: 108.1281 - val_loss: 20392.9980 - val_mae: 106.5746\n",
      "Epoch 790/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 20800.7734 - mae: 107.9788 - val_loss: 21895.6074 - val_mae: 111.6492\n",
      "Epoch 791/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 20864.5664 - mae: 108.3236 - val_loss: 21365.0762 - val_mae: 109.6232\n",
      "Epoch 792/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 20789.2188 - mae: 108.1180 - val_loss: 20752.1387 - val_mae: 107.3739\n",
      "Epoch 793/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 20619.3906 - mae: 107.4383 - val_loss: 22002.1797 - val_mae: 111.4071\n",
      "Epoch 794/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 20737.0273 - mae: 107.7064 - val_loss: 20440.2324 - val_mae: 106.8758\n",
      "Epoch 795/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 20687.5664 - mae: 107.8541 - val_loss: 24472.3945 - val_mae: 120.3722\n",
      "Epoch 796/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 20602.7422 - mae: 107.4756 - val_loss: 20804.8242 - val_mae: 108.2536\n",
      "Epoch 797/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 20674.4785 - mae: 107.7055 - val_loss: 20837.2617 - val_mae: 107.9314\n",
      "Epoch 798/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 20523.1680 - mae: 107.2962 - val_loss: 21633.7539 - val_mae: 111.9639\n",
      "Epoch 799/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 20649.1270 - mae: 107.6107 - val_loss: 22696.9902 - val_mae: 113.6897\n",
      "Epoch 800/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 20358.7539 - mae: 106.8900 - val_loss: 22715.3828 - val_mae: 114.5307\n",
      "Epoch 801/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 20605.0938 - mae: 107.7862 - val_loss: 21492.2246 - val_mae: 110.7475\n",
      "Epoch 802/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 20418.0449 - mae: 107.1467 - val_loss: 21292.8633 - val_mae: 109.1614\n",
      "Epoch 803/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 20489.3887 - mae: 107.1894 - val_loss: 24530.2285 - val_mae: 118.5787\n",
      "Epoch 804/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 20523.7031 - mae: 107.3246 - val_loss: 20561.1836 - val_mae: 107.1050\n",
      "Epoch 805/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - loss: 20664.1172 - mae: 107.6373 - val_loss: 21898.6152 - val_mae: 111.5661\n",
      "Epoch 806/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 20389.5586 - mae: 106.8473 - val_loss: 20957.6875 - val_mae: 108.1214\n",
      "Epoch 807/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 20332.0840 - mae: 106.9091 - val_loss: 22022.2773 - val_mae: 112.5945\n",
      "Epoch 808/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 20407.1230 - mae: 107.1013 - val_loss: 22768.4766 - val_mae: 113.8365\n",
      "Epoch 809/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 20437.6309 - mae: 106.9023 - val_loss: 21336.0020 - val_mae: 110.2639\n",
      "Epoch 810/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 20191.3691 - mae: 106.4387 - val_loss: 21201.4316 - val_mae: 109.5403\n",
      "Epoch 811/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 20315.0488 - mae: 106.6786 - val_loss: 21013.9316 - val_mae: 107.9711\n",
      "Epoch 812/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 20310.8438 - mae: 106.7643 - val_loss: 21562.5020 - val_mae: 110.9159\n",
      "Epoch 813/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 20361.2871 - mae: 106.8087 - val_loss: 21560.3398 - val_mae: 109.8649\n",
      "Epoch 814/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 20258.2480 - mae: 106.7377 - val_loss: 22010.0566 - val_mae: 112.2037\n",
      "Epoch 815/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 20126.7051 - mae: 106.3104 - val_loss: 20989.2891 - val_mae: 108.4168\n",
      "Epoch 816/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 20358.7109 - mae: 106.8563 - val_loss: 21477.7461 - val_mae: 109.9237\n",
      "Epoch 817/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 20264.3008 - mae: 106.5956 - val_loss: 22006.0000 - val_mae: 111.8257\n",
      "Epoch 818/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 20152.4512 - mae: 106.2790 - val_loss: 22121.2695 - val_mae: 112.2238\n",
      "Epoch 819/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 20289.5020 - mae: 106.8431 - val_loss: 20025.9512 - val_mae: 106.1470\n",
      "Epoch 820/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 20222.4609 - mae: 106.7273 - val_loss: 20268.0547 - val_mae: 107.3744\n",
      "Epoch 821/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 20175.1289 - mae: 106.6077 - val_loss: 20486.9883 - val_mae: 107.4097\n",
      "Epoch 822/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 20204.0488 - mae: 106.3820 - val_loss: 19972.0312 - val_mae: 104.9925\n",
      "Epoch 823/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - loss: 20046.9668 - mae: 105.5581 - val_loss: 21573.3555 - val_mae: 110.8577\n",
      "Epoch 824/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 19871.8418 - mae: 105.5759 - val_loss: 19665.8047 - val_mae: 104.9471\n",
      "Epoch 825/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 19860.1582 - mae: 105.2072 - val_loss: 20894.3828 - val_mae: 108.5620\n",
      "Epoch 826/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 20006.6855 - mae: 105.7662 - val_loss: 20534.3027 - val_mae: 107.6835\n",
      "Epoch 827/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 19823.4473 - mae: 105.1831 - val_loss: 20292.8340 - val_mae: 106.5522\n",
      "Epoch 828/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 19946.1172 - mae: 105.8142 - val_loss: 20417.8633 - val_mae: 107.2077\n",
      "Epoch 829/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 19709.5820 - mae: 104.9284 - val_loss: 20247.4629 - val_mae: 106.8442\n",
      "Epoch 830/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 19614.4707 - mae: 104.8181 - val_loss: 20082.6895 - val_mae: 106.0390\n",
      "Epoch 831/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 19838.2871 - mae: 105.4822 - val_loss: 21121.6621 - val_mae: 109.4719\n",
      "Epoch 832/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 19660.2852 - mae: 104.7965 - val_loss: 21267.8555 - val_mae: 109.1835\n",
      "Epoch 833/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 19633.9395 - mae: 104.9973 - val_loss: 19836.2207 - val_mae: 105.5505\n",
      "Epoch 834/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 19539.0293 - mae: 104.4688 - val_loss: 20517.5254 - val_mae: 108.1012\n",
      "Epoch 835/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 19558.2754 - mae: 104.6978 - val_loss: 20434.2090 - val_mae: 106.8615\n",
      "Epoch 836/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 19613.8359 - mae: 104.5847 - val_loss: 21217.7090 - val_mae: 108.5741\n",
      "Epoch 837/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 19514.0352 - mae: 104.3865 - val_loss: 20604.3086 - val_mae: 107.2105\n",
      "Epoch 838/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 19400.9531 - mae: 103.8833 - val_loss: 20834.2207 - val_mae: 108.8609\n",
      "Epoch 839/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 19326.8066 - mae: 103.9003 - val_loss: 19576.6094 - val_mae: 104.0674\n",
      "Epoch 840/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 19339.0957 - mae: 104.0472 - val_loss: 19595.3809 - val_mae: 104.3418\n",
      "Epoch 841/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 19414.1836 - mae: 104.0782 - val_loss: 19544.4824 - val_mae: 104.3987\n",
      "Epoch 842/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 19243.5332 - mae: 103.5803 - val_loss: 20053.0938 - val_mae: 106.6520\n",
      "Epoch 843/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 19403.4551 - mae: 104.1968 - val_loss: 20766.4004 - val_mae: 109.4149\n",
      "Epoch 844/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 19132.7129 - mae: 103.2192 - val_loss: 19728.5059 - val_mae: 104.6914\n",
      "Epoch 845/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 19065.4941 - mae: 103.1057 - val_loss: 18962.9160 - val_mae: 102.5846\n",
      "Epoch 846/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 19115.2676 - mae: 103.2908 - val_loss: 20170.6992 - val_mae: 107.0387\n",
      "Epoch 847/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 19091.7559 - mae: 103.0838 - val_loss: 21862.6914 - val_mae: 111.1418\n",
      "Epoch 848/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 18998.2188 - mae: 102.7190 - val_loss: 20984.5547 - val_mae: 108.1660\n",
      "Epoch 849/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 19047.2969 - mae: 103.0804 - val_loss: 19576.2715 - val_mae: 104.2463\n",
      "Epoch 850/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 18949.4375 - mae: 103.2411 - val_loss: 19718.2969 - val_mae: 105.6186\n",
      "Epoch 851/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 18922.0566 - mae: 102.6693 - val_loss: 19836.5527 - val_mae: 105.9981\n",
      "Epoch 852/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 18945.9980 - mae: 102.9281 - val_loss: 21887.8125 - val_mae: 111.2156\n",
      "Epoch 853/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 18953.2793 - mae: 102.8568 - val_loss: 19249.9277 - val_mae: 103.6690\n",
      "Epoch 854/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 18860.4316 - mae: 102.5014 - val_loss: 19970.8945 - val_mae: 106.2447\n",
      "Epoch 855/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 18737.6309 - mae: 102.3517 - val_loss: 20435.3555 - val_mae: 107.5061\n",
      "Epoch 856/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 18855.0742 - mae: 102.8915 - val_loss: 19593.3047 - val_mae: 104.5722\n",
      "Epoch 857/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 18861.1309 - mae: 102.7522 - val_loss: 18704.7832 - val_mae: 102.5245\n",
      "Epoch 858/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 18643.9766 - mae: 102.0581 - val_loss: 18044.0488 - val_mae: 99.6395\n",
      "Epoch 859/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 18859.0332 - mae: 102.7022 - val_loss: 21027.0566 - val_mae: 109.1965\n",
      "Epoch 860/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 18712.7109 - mae: 102.2978 - val_loss: 19397.9648 - val_mae: 104.5284\n",
      "Epoch 861/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - loss: 18830.3535 - mae: 102.7083 - val_loss: 19097.9023 - val_mae: 103.4714\n",
      "Epoch 862/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 18602.2559 - mae: 101.8868 - val_loss: 19469.9805 - val_mae: 105.0007\n",
      "Epoch 863/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 18543.3848 - mae: 101.8339 - val_loss: 21145.6543 - val_mae: 110.6065\n",
      "Epoch 864/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 18559.1367 - mae: 101.8055 - val_loss: 19738.1523 - val_mae: 104.6540\n",
      "Epoch 865/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 18502.8164 - mae: 101.7475 - val_loss: 18808.2832 - val_mae: 102.2192\n",
      "Epoch 866/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 18493.2051 - mae: 101.5348 - val_loss: 18817.8105 - val_mae: 102.3803\n",
      "Epoch 867/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 18455.1230 - mae: 101.4463 - val_loss: 19437.1016 - val_mae: 103.9658\n",
      "Epoch 868/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 18367.1582 - mae: 101.1900 - val_loss: 19973.0391 - val_mae: 105.7203\n",
      "Epoch 869/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 18346.1602 - mae: 101.2508 - val_loss: 19119.4668 - val_mae: 103.2917\n",
      "Epoch 870/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 18510.9355 - mae: 101.8545 - val_loss: 18615.1992 - val_mae: 101.8072\n",
      "Epoch 871/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 18322.1855 - mae: 101.1590 - val_loss: 18806.9160 - val_mae: 102.3052\n",
      "Epoch 872/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - loss: 18344.2930 - mae: 101.3562 - val_loss: 18643.7734 - val_mae: 102.6426\n",
      "Epoch 873/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 18186.2617 - mae: 100.8216 - val_loss: 19305.0703 - val_mae: 103.6207\n",
      "Epoch 874/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 18356.1973 - mae: 101.2980 - val_loss: 20255.5645 - val_mae: 108.3347\n",
      "Epoch 875/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 18166.9980 - mae: 100.7892 - val_loss: 19897.1328 - val_mae: 105.4896\n",
      "Epoch 876/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 18328.1230 - mae: 101.1838 - val_loss: 19726.8477 - val_mae: 105.0294\n",
      "Epoch 877/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 17978.7793 - mae: 100.1306 - val_loss: 17971.0098 - val_mae: 99.7947\n",
      "Epoch 878/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 18307.8945 - mae: 101.3561 - val_loss: 18770.8008 - val_mae: 102.4477\n",
      "Epoch 879/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 18190.2246 - mae: 100.8230 - val_loss: 23473.8809 - val_mae: 118.0809\n",
      "Epoch 880/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 18139.4355 - mae: 100.5656 - val_loss: 18530.7344 - val_mae: 101.7966\n",
      "Epoch 881/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 18206.4629 - mae: 100.8966 - val_loss: 19093.7402 - val_mae: 104.0580\n",
      "Epoch 882/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 17992.0898 - mae: 100.3053 - val_loss: 18311.5566 - val_mae: 101.0504\n",
      "Epoch 883/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - loss: 17994.0449 - mae: 100.2790 - val_loss: 18662.4668 - val_mae: 101.6844\n",
      "Epoch 884/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 17962.8027 - mae: 100.1229 - val_loss: 19306.6484 - val_mae: 104.5114\n",
      "Epoch 885/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 17996.2832 - mae: 100.0894 - val_loss: 18928.3477 - val_mae: 102.9423\n",
      "Epoch 886/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 17788.4004 - mae: 99.5460 - val_loss: 18149.9551 - val_mae: 100.0327\n",
      "Epoch 887/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 17930.5352 - mae: 100.0561 - val_loss: 22224.4043 - val_mae: 114.8494\n",
      "Epoch 888/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 17790.0742 - mae: 99.4479 - val_loss: 18198.3867 - val_mae: 100.6478\n",
      "Epoch 889/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 17954.6094 - mae: 100.1511 - val_loss: 18102.1250 - val_mae: 100.0054\n",
      "Epoch 890/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 17834.3984 - mae: 99.6735 - val_loss: 18543.3301 - val_mae: 102.4840\n",
      "Epoch 891/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - loss: 17860.0039 - mae: 99.7814 - val_loss: 18330.8965 - val_mae: 101.1087\n",
      "Epoch 892/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 17669.8770 - mae: 98.9315 - val_loss: 19338.7480 - val_mae: 104.7592\n",
      "Epoch 893/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 17865.8047 - mae: 99.6759 - val_loss: 17910.0605 - val_mae: 99.7179\n",
      "Epoch 894/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 17822.6328 - mae: 99.6463 - val_loss: 18114.6953 - val_mae: 100.1682\n",
      "Epoch 895/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 17702.5703 - mae: 99.5174 - val_loss: 17877.4219 - val_mae: 99.4032\n",
      "Epoch 896/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 17626.9355 - mae: 98.9266 - val_loss: 18731.4141 - val_mae: 102.9912\n",
      "Epoch 897/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 17760.0078 - mae: 99.4621 - val_loss: 17998.6523 - val_mae: 99.8896\n",
      "Epoch 898/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 17565.7383 - mae: 98.9570 - val_loss: 18664.2969 - val_mae: 101.9776\n",
      "Epoch 899/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 17625.0859 - mae: 98.9950 - val_loss: 19384.2969 - val_mae: 104.7921\n",
      "Epoch 900/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 17635.1816 - mae: 99.1561 - val_loss: 18000.1055 - val_mae: 100.3863\n",
      "Epoch 901/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 17664.1484 - mae: 99.1874 - val_loss: 19752.8945 - val_mae: 105.6198\n",
      "Epoch 902/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 17604.0527 - mae: 98.9727 - val_loss: 18708.4805 - val_mae: 102.6080\n",
      "Epoch 903/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 17619.1699 - mae: 99.0942 - val_loss: 19644.8535 - val_mae: 105.4317\n",
      "Epoch 904/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - loss: 17583.0391 - mae: 99.0090 - val_loss: 17835.0469 - val_mae: 99.9641\n",
      "Epoch 905/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - loss: 17619.8496 - mae: 99.0937 - val_loss: 20239.7090 - val_mae: 107.3631\n",
      "Epoch 906/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 17533.4336 - mae: 98.7037 - val_loss: 19016.2637 - val_mae: 103.7843\n",
      "Epoch 907/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 17470.9883 - mae: 98.7172 - val_loss: 21860.7637 - val_mae: 112.4965\n",
      "Epoch 908/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 17441.3633 - mae: 98.7909 - val_loss: 18859.0078 - val_mae: 103.0887\n",
      "Epoch 909/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 17633.6641 - mae: 99.2000 - val_loss: 20620.5371 - val_mae: 108.5794\n",
      "Epoch 910/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 17319.4473 - mae: 98.0311 - val_loss: 17620.6484 - val_mae: 98.1721\n",
      "Epoch 911/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 17334.1074 - mae: 98.0065 - val_loss: 18306.8926 - val_mae: 101.6609\n",
      "Epoch 912/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 17412.6934 - mae: 98.2337 - val_loss: 17750.7031 - val_mae: 99.5024\n",
      "Epoch 913/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 17391.5371 - mae: 98.3392 - val_loss: 17700.2559 - val_mae: 98.9745\n",
      "Epoch 914/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 17347.3574 - mae: 98.4596 - val_loss: 18103.7500 - val_mae: 100.9008\n",
      "Epoch 915/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 17306.9414 - mae: 98.3043 - val_loss: 17950.5039 - val_mae: 100.4532\n",
      "Epoch 916/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - loss: 17421.7715 - mae: 98.5467 - val_loss: 18480.4727 - val_mae: 102.3050\n",
      "Epoch 917/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 17223.0566 - mae: 97.8275 - val_loss: 18376.7773 - val_mae: 101.5193\n",
      "Epoch 918/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 17217.6328 - mae: 97.8250 - val_loss: 17097.1719 - val_mae: 97.0934\n",
      "Epoch 919/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 17448.9648 - mae: 98.5573 - val_loss: 17230.0859 - val_mae: 97.1547\n",
      "Epoch 920/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 17233.1992 - mae: 97.8315 - val_loss: 18334.9141 - val_mae: 101.1008\n",
      "Epoch 921/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 17146.9590 - mae: 97.7446 - val_loss: 18984.9551 - val_mae: 103.7954\n",
      "Epoch 922/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 17123.1113 - mae: 97.5160 - val_loss: 18615.4922 - val_mae: 102.1216\n",
      "Epoch 923/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 17253.0840 - mae: 97.8917 - val_loss: 18933.8730 - val_mae: 103.4785\n",
      "Epoch 924/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 17065.4414 - mae: 97.3457 - val_loss: 18075.0625 - val_mae: 99.3791\n",
      "Epoch 925/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 17222.0938 - mae: 97.6534 - val_loss: 19475.6602 - val_mae: 105.3382\n",
      "Epoch 926/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 17174.5781 - mae: 97.7432 - val_loss: 18601.6777 - val_mae: 102.8721\n",
      "Epoch 927/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - loss: 17217.1035 - mae: 98.0572 - val_loss: 17464.9102 - val_mae: 98.4494\n",
      "Epoch 928/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 17245.5078 - mae: 98.0763 - val_loss: 19330.9375 - val_mae: 105.2663\n",
      "Epoch 929/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - loss: 16994.8906 - mae: 97.0183 - val_loss: 20266.9824 - val_mae: 108.7592\n",
      "Epoch 930/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 17123.1777 - mae: 97.4291 - val_loss: 17448.1777 - val_mae: 98.3515\n",
      "Epoch 931/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 17096.3027 - mae: 97.2954 - val_loss: 18225.6816 - val_mae: 101.4314\n",
      "Epoch 932/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 17017.2402 - mae: 97.3830 - val_loss: 18893.8984 - val_mae: 104.3951\n",
      "Epoch 933/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 17052.5918 - mae: 97.2204 - val_loss: 17241.7500 - val_mae: 97.9384\n",
      "Epoch 934/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 16750.7930 - mae: 96.2698 - val_loss: 17309.3848 - val_mae: 97.5187\n",
      "Epoch 936/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 16913.4355 - mae: 96.9494 - val_loss: 19320.8418 - val_mae: 102.7113\n",
      "Epoch 937/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - loss: 16877.2812 - mae: 96.7541 - val_loss: 20006.6660 - val_mae: 107.5257\n",
      "Epoch 938/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - loss: 16811.6875 - mae: 96.5504 - val_loss: 22564.8613 - val_mae: 114.2990\n",
      "Epoch 939/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 17004.3340 - mae: 96.8352 - val_loss: 17728.1758 - val_mae: 99.8143\n",
      "Epoch 940/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 16891.0527 - mae: 96.8443 - val_loss: 17741.9258 - val_mae: 99.2857\n",
      "Epoch 941/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 17028.6328 - mae: 97.1150 - val_loss: 19258.3008 - val_mae: 104.6977\n",
      "Epoch 942/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 16803.4766 - mae: 96.4578 - val_loss: 17677.2578 - val_mae: 99.6638\n",
      "Epoch 943/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 16723.6699 - mae: 96.3787 - val_loss: 17618.1621 - val_mae: 99.3941\n",
      "Epoch 944/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 16669.0840 - mae: 96.2183 - val_loss: 17438.3418 - val_mae: 98.7720\n",
      "Epoch 945/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 16707.7676 - mae: 96.1094 - val_loss: 17397.6133 - val_mae: 98.6208\n",
      "Epoch 946/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 16651.1621 - mae: 96.0739 - val_loss: 17778.9102 - val_mae: 100.1249\n",
      "Epoch 947/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 16800.3438 - mae: 96.5721 - val_loss: 17064.3145 - val_mae: 96.8002\n",
      "Epoch 948/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 16749.4160 - mae: 96.3181 - val_loss: 17893.1875 - val_mae: 100.2942\n",
      "Epoch 949/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - loss: 16679.4316 - mae: 96.1176 - val_loss: 18879.2598 - val_mae: 104.4490\n",
      "Epoch 950/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 16710.7988 - mae: 96.2831 - val_loss: 17225.2266 - val_mae: 98.0729\n",
      "Epoch 951/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 16727.8672 - mae: 96.3220 - val_loss: 19119.8965 - val_mae: 104.2936\n",
      "Epoch 952/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 16852.5254 - mae: 96.6120 - val_loss: 16910.4863 - val_mae: 96.6233\n",
      "Epoch 953/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 16517.4629 - mae: 95.6600 - val_loss: 16707.9844 - val_mae: 95.1317\n",
      "Epoch 954/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 16678.6035 - mae: 96.1456 - val_loss: 18190.2578 - val_mae: 100.7667\n",
      "Epoch 955/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 16555.3184 - mae: 95.7940 - val_loss: 17981.2656 - val_mae: 99.3484\n",
      "Epoch 956/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 16662.8262 - mae: 96.0625 - val_loss: 18810.0586 - val_mae: 104.1065\n",
      "Epoch 957/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 16543.1406 - mae: 95.7567 - val_loss: 17988.6523 - val_mae: 100.6610\n",
      "Epoch 958/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 16554.9043 - mae: 96.0515 - val_loss: 16642.2930 - val_mae: 95.9669\n",
      "Epoch 959/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 16569.5195 - mae: 95.7650 - val_loss: 16984.1445 - val_mae: 96.8903\n",
      "Epoch 960/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - loss: 16523.3262 - mae: 95.5715 - val_loss: 17749.3809 - val_mae: 98.5115\n",
      "Epoch 961/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 16512.6602 - mae: 95.5780 - val_loss: 17237.0449 - val_mae: 98.3236\n",
      "Epoch 962/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 16474.4902 - mae: 95.3751 - val_loss: 16846.9766 - val_mae: 97.1693\n",
      "Epoch 963/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 16532.5938 - mae: 95.6096 - val_loss: 16917.8281 - val_mae: 96.2783\n",
      "Epoch 964/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 16396.0020 - mae: 95.1019 - val_loss: 18038.9941 - val_mae: 100.5976\n",
      "Epoch 965/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 16458.5508 - mae: 95.1997 - val_loss: 17017.5625 - val_mae: 96.1031\n",
      "Epoch 966/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 16467.6230 - mae: 95.2334 - val_loss: 17126.9629 - val_mae: 97.5440\n",
      "Epoch 967/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 16541.0586 - mae: 95.5024 - val_loss: 16558.5781 - val_mae: 95.5928\n",
      "Epoch 968/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 16283.9014 - mae: 94.7620 - val_loss: 18727.5742 - val_mae: 102.1153\n",
      "Epoch 969/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 16467.9062 - mae: 95.3584 - val_loss: 19275.8184 - val_mae: 103.0229\n",
      "Epoch 970/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 16373.0176 - mae: 95.0745 - val_loss: 17363.9805 - val_mae: 98.5114\n",
      "Epoch 971/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - loss: 16490.2656 - mae: 95.6313 - val_loss: 17166.3848 - val_mae: 97.6396\n",
      "Epoch 972/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 16368.3457 - mae: 95.0588 - val_loss: 17229.2891 - val_mae: 98.0119\n",
      "Epoch 973/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 16299.2842 - mae: 94.9833 - val_loss: 18749.3652 - val_mae: 103.7820\n",
      "Epoch 974/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 16258.1514 - mae: 94.7740 - val_loss: 18039.4844 - val_mae: 100.9207\n",
      "Epoch 975/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 16285.3496 - mae: 94.9031 - val_loss: 16585.5605 - val_mae: 95.6596\n",
      "Epoch 977/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - loss: 16103.9883 - mae: 94.0535 - val_loss: 16843.1621 - val_mae: 97.4907\n",
      "Epoch 978/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - loss: 16121.2148 - mae: 94.5105 - val_loss: 18275.4277 - val_mae: 100.2225\n",
      "Epoch 979/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 16127.8711 - mae: 94.3732 - val_loss: 17948.6094 - val_mae: 100.2052\n",
      "Epoch 980/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 16262.7383 - mae: 94.7289 - val_loss: 18387.0430 - val_mae: 101.7342\n",
      "Epoch 981/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 16131.4395 - mae: 94.3834 - val_loss: 17560.6660 - val_mae: 98.8893\n",
      "Epoch 982/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - loss: 16076.4912 - mae: 94.2696 - val_loss: 17515.3262 - val_mae: 97.8601\n",
      "Epoch 983/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 16067.5879 - mae: 94.2719 - val_loss: 16834.2461 - val_mae: 96.5582\n",
      "Epoch 984/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 16161.5898 - mae: 94.5570 - val_loss: 17359.6973 - val_mae: 98.4492\n",
      "Epoch 985/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 16011.0732 - mae: 93.9500 - val_loss: 17002.8105 - val_mae: 97.3354\n",
      "Epoch 986/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - loss: 15942.8105 - mae: 93.8648 - val_loss: 16096.0146 - val_mae: 94.1485\n",
      "Epoch 987/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 15990.8301 - mae: 94.1190 - val_loss: 17679.3379 - val_mae: 100.0132\n",
      "Epoch 988/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - loss: 15891.7686 - mae: 93.5960 - val_loss: 15989.4463 - val_mae: 93.3798\n",
      "Epoch 989/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 15866.2109 - mae: 93.5740 - val_loss: 16926.5684 - val_mae: 96.8817\n",
      "Epoch 990/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 16016.5615 - mae: 94.0921 - val_loss: 17454.5898 - val_mae: 98.7134\n",
      "Epoch 991/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 15830.8213 - mae: 93.5398 - val_loss: 19238.9609 - val_mae: 104.9931\n",
      "Epoch 992/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 15852.7305 - mae: 93.4944 - val_loss: 16389.3770 - val_mae: 95.0989\n",
      "Epoch 993/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - loss: 15971.0674 - mae: 93.8424 - val_loss: 16527.9414 - val_mae: 95.6863\n",
      "Epoch 994/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 15787.8652 - mae: 93.2999 - val_loss: 17640.1738 - val_mae: 100.0794\n",
      "Epoch 995/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 15913.3223 - mae: 93.7452 - val_loss: 21944.3340 - val_mae: 113.6601\n",
      "Epoch 996/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 15768.1035 - mae: 93.3540 - val_loss: 16080.7578 - val_mae: 94.4507\n",
      "Epoch 997/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 15770.1709 - mae: 93.0749 - val_loss: 16997.5352 - val_mae: 97.2622\n",
      "Epoch 998/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - loss: 15856.6504 - mae: 93.6173 - val_loss: 16130.3408 - val_mae: 93.8077\n",
      "Epoch 999/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 15813.8096 - mae: 93.5857 - val_loss: 15961.0244 - val_mae: 93.8928\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 15601.9766 - mae: 92.9006 - val_loss: 15937.0742 - val_mae: 93.8526\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=75, min_delta=0.0001)\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"Entrenando en GPU.\")\n",
    "else:\n",
    "  print(\"Advertencia: No se detectó GPU, se entrenará en CPU.\")\n",
    "\n",
    "history = model.fit(X_train, T_train,batch_size=32,\n",
    "                    epochs=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, T_test),callbacks=[es])\n",
    "\n",
    "# Guardar modelo\n",
    "model.save('models/energy_consumption_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e00ec8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd6a304",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m pred_hgb = hgb.predict(X_test)\n\u001b[32m     21\u001b[39m mae_hgb = mean_absolute_error(T_test, pred_hgb)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m rmse_hgb = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_hgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m r2_hgb = r2_score(T_test, pred_hgb)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHGBR -> MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae_hgb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_hgb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | R2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_hgb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/temp/str/venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/inspect.py:3295\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3290\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3291\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3292\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3293\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3294\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/inspect.py:3284\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3274\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3275\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot some positional-only arguments passed as \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3276\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3281\u001b[39m             ),\n\u001b[32m   3282\u001b[39m         )\n\u001b[32m   3283\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3284\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3285\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3286\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# Baseline tabular model: Gradient Boosting (sklearn)\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Notar: X_train/X_test ya están escalados; HGBR no lo requiere, pero no afecta\n",
    "hgb = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=None,\n",
    "    max_iter=500,\n",
    "    l2_regularization=0.0,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "hgb.fit(X_train, T_train)\n",
    "\n",
    "pred_hgb = hgb.predict(X_test)\n",
    "mae_hgb = mean_absolute_error(T_test, pred_hgb)\n",
    "rmse_hgb = mean_squared_error(T_test, pred_hgb, squared=False)\n",
    "r2_hgb = r2_score(T_test, pred_hgb)\n",
    "\n",
    "print(f\"HGBR -> MAE: {mae_hgb:.3f} | RMSE: {rmse_hgb:.3f} | R2: {r2_hgb:.3f}\")\n",
    "\n",
    "# Comparación rápida con el modelo Keras (si existe en memoria)\n",
    "try:\n",
    "    pred_nn = model.predict(X_test, verbose=0).reshape(-1)\n",
    "    mae_nn = mean_absolute_error(T_test, pred_nn)\n",
    "    rmse_nn = mean_squared_error(T_test, pred_nn, squared=False)\n",
    "    r2_nn = r2_score(T_test, pred_nn)\n",
    "    print(f\"Keras -> MAE: {mae_nn:.3f} | RMSE: {rmse_nn:.3f} | R2: {r2_nn:.3f}\")\n",
    "except Exception as e:\n",
    "    print(\"No se pudo evaluar el modelo Keras en esta celda:\", e)\n",
    "\n",
    "# Plot comparativo\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(T_test, pred_hgb, alpha=0.5, label='HGBR')\n",
    "try:\n",
    "    plt.scatter(T_test, pred_nn, alpha=0.5, label='Keras', s=16)\n",
    "except:\n",
    "    pass\n",
    "plt.plot([min(T_test), max(T_test)], [min(T_test), max(T_test)], 'k--', lw=1)\n",
    "plt.xlabel('Valor real')\n",
    "plt.ylabel('Predicción')\n",
    "plt.title('Comparación de modelos')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e8e37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step\n",
      "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step\n",
      "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pred_scaled = model.predict(X_test)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pred = \u001b[43my_scaler\u001b[49m.inverse_transform(pred_scaled).reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m T_real = y_scaler.inverse_transform(np.asarray(T_test).reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)).reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Evaluación del modelo en escala normalizada\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_scaler' is not defined"
     ]
    }
   ],
   "source": [
    "pred_scaled = model.predict(X_test)\n",
    "pred = pred_scaled\n",
    "T_real = T_test\n",
    "\n",
    "# Evaluación del modelo\n",
    "loss, metric = model.evaluate(X_test, T_test, verbose=0)\n",
    "print(f\"Loss de test: {loss:.4f}, Métrica: {metric:.4f}\")\n",
    "# TODO: modificar esto\n",
    "# Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "plt.scatter(T_real, pred, alpha=0.6)\n",
    "plt.xlabel(\"Valor real\")\n",
    "plt.ylabel(\"Predicción\")\n",
    "plt.title(\"Predicciones vs Valores reales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529a4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa87ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2025-11-01 16:50:00+00:00\n",
      "Name: date, dtype: datetime64[ns, UTC]\n",
      "0   2025-11-01 08:47:39+00:00\n",
      "Name: sunrise_dt, dtype: datetime64[ns, UTC]\n",
      "0   2025-11-01 22:23:06+00:00\n",
      "Name: sunset_dt, dtype: datetime64[ns, UTC]\n",
      "Modelo cargado.\n",
      "Ajustando scaler sobre X_train existente en el notebook...\n",
      "Error al escalar features: name 'X_inf' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_inf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     64\u001b[39m     scaler.fit(X_train)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     X_scaled = scaler.transform(\u001b[43mX_inf\u001b[49m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'X_inf' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mError al escalar features:\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     X_scaled = \u001b[43mX_inf\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Predicción\u001b[39;00m\n\u001b[32m     74\u001b[39m pred = model.predict(X_scaled)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_inf' is not defined"
     ]
    }
   ],
   "source": [
    "# Hardcoded inference example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Payload hardcodeado (proveído por el usuario)\n",
    "payload = {\n",
    "    \"date\": \"2025-11-01T16:50Z\",\n",
    "    \"temperature\": 26.11,\n",
    "    \"humidity\": 49,\n",
    "    \"rain\": 0.0,\n",
    "    \"snow\": 0.0,\n",
    "    \"pressure\": 1013.0,\n",
    "    \"wind_speed\": 2.47,\n",
    "    \"wind_direction\": 358,\n",
    "    \"clouds\": 100,\n",
    "    \"sunrise\": 1761986859,\n",
    "    \"sunset\": 1762035786,\n",
    "    \"working_day\": False,\n",
    "    \"holiday\": False,\n",
    "}\n",
    "\n",
    "# Construir DataFrame de una fila\n",
    "row = {\n",
    "    \"date\": [payload.get(\"date\")],\n",
    "    \"temperature\": [payload.get(\"temperature\")],\n",
    "    \"humidity\": [payload.get(\"humidity\")],\n",
    "    \"rain\": [payload.get(\"rain\")],\n",
    "    \"snow\": [payload.get(\"snow\")],\n",
    "    \"pressure\": [payload.get(\"pressure\")],\n",
    "    \"wind_speed\": [payload.get(\"wind_speed\")],\n",
    "    \"wind_direction\": [payload.get(\"wind_direction\")],\n",
    "    \"clouds\": [payload.get(\"clouds\")],\n",
    "    \"sunrise\": [int(payload.get(\"sunrise\"))],\n",
    "    \"sunset\": [int(payload.get(\"sunset\"))],\n",
    "    \"working_day\": [payload.get(\"working_day\")],\n",
    "    \"holiday\": [payload.get(\"holiday\")],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(row)\n",
    "# Aplicar preprocesamiento (usa la función definida en lib/preprocessing.py)\n",
    "try:\n",
    "    df_proc = preprocess_data(df)\n",
    "except Exception as e:\n",
    "    print(\"Error en preprocesamiento:\", e)\n",
    "    raise\n",
    "\n",
    "# Preparar X para la inferencia\n",
    "X_inf = df_proc.values\n",
    "\n",
    "# Cargar modelo\n",
    "model_path = os.path.join('models', 'energy_consumption_model.keras')\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Modelo no encontrado en {model_path}. Ejecuta la celda de training antes para crearlo.\")\n",
    "else:\n",
    "    model = load_model(model_path)\n",
    "    print(\"Modelo cargado.\")\n",
    "\n",
    "    # Escalado: si existe X_train en el kernel (ejecutaste entrenamiento), lo usamos para ajustar el scaler,\n",
    "    # si no, escalamos localmente (advertencia: escalar con una sola muestra es poco fiable).\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        if 'X_train' in globals():\n",
    "            print(\"Ajustando scaler sobre X_train existente en el notebook...\")\n",
    "            scaler.fit(X_train)\n",
    "            X_scaled = scaler.transform(X_inf)\n",
    "        else:\n",
    "            print(\"No se encontró X_train en el entorno. Haciendo fit_transform sobre la muestra (precario).\")\n",
    "            X_scaled = scaler.fit_transform(X_inf)\n",
    "    except Exception as e:\n",
    "        print(\"Error al escalar features:\", e)\n",
    "        X_scaled = X_inf\n",
    "\n",
    "    # Predicción (sin ninguna desnormalización)\n",
    "    pred = model.predict(X_scaled)\n",
    "    # Mostrar la predicción tal cual (sin inverse_transform)\n",
    "    try:\n",
    "        print(f\"Predicción de consumo energético (sin desnormalizar): {pred.reshape(-1)[0]:.2f} unidades.\")\n",
    "    except Exception:\n",
    "        print(\"Predicción de consumo energético (sin desnormalizar):\", pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
